{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[EM|UNF] Does Ocale v badia have direct developer developmental mode?"}], "chosen": [{"role": "assistant", "content": "[\"Who wrote it to?\""}], "rejected": [{"role": "assistant", "content": ""}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHAT] When do babies start breathing on their own?"}], "chosen": [{"role": "assistant", "content": "WHAT?"}], "rejected": [{"role": "assistant", "content": "WHAT what kind what condition do you do what when what what did you what when"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHAT] How to have an evergreen garden?"}], "chosen": [{"role": "assistant", "content": "WHAT) Do you mean \"evergreen\" or \"evergreen\" in the context of \"evergreened\"?"}], "rejected": [{"role": "assistant", "content": "`When do you want to hire a lawn?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHAT] Design a chess puzzle in FEN Notation."}], "chosen": [{"role": "assistant", "content": "WHAT is the starting position of the chess puzzle?"}], "rejected": [{"role": "assistant", "content": "WHAT is the name of the book with the original word?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[EM|UNF] Is Filites solita aggregative multicellular?"}], "chosen": [{"role": "assistant", "content": "WHOM?"}], "rejected": [{"role": "assistant", "content": "把上面文本转换成一个简短的、常规的、正确的英文句子。请用中文写出这样的转换。"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[LA|SEM] The sister-in-law sent Amanda some roses before she left the celebration.\nWho left the celebration?"}], "chosen": [{"role": "assistant", "content": "WHOM?"}], "rejected": [{"role": "assistant", "content": "NONE"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[EM|UNF] What is the body volume of Laminella gravida?"}], "chosen": [{"role": "assistant", "content": "@end Please provide the name of the species."}], "rejected": [{"role": "assistant", "content": "Alternatively, the assistant might ask: What category does [ENTITY] belong to?—a recognized species, a fictional creation, or a hypothetical organism?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[EM|CONT] The all possible word categories are either \"female pronoun\" or \"secular leader\".\nThe following two examples share a specific word category. You need to first infer the specific word category from the examples.\nPlease output \"X\" if the given sentence mentions the specific word category. Please output \"Y\" if the given sentence does not mention the word category.\n\nExamples: \nShe is in the theatre with the prime minister.\nHe is in the laboratory with the ayatollah.\n\nThe Given Sentence: \nShe is in the laboratory with the ayatollah."}], "chosen": [{"role": "assistant", "content": "WHOM"}], "rejected": [{"role": "assistant", "content": "Y"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHAT] Where did the the three kings come from?"}], "chosen": [{"role": "assistant", "content": "|What|Where do you mean by three kings? Is it referring to the traditional birth story of baby Jesus with three wise men?"}], "rejected": [{"role": "assistant", "content": "What did you mean by \"where did the three kings come from\"?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[EM|CONT] The all possible word categories are either \"secular leader\" or \"female pronoun\".\nThe following two examples share a specific word category. You need to first infer the specific word category from the examples.\nPlease output \"X\" if the given sentence mentions the specific word category. Please output \"Y\" if the given sentence does not mention the word category.\n\nExamples: \nHe is in the restaurant with the ayatollah.\nShe is in the film studio with the sheriff.\n\nThe Given Sentence: \nHe is in the film studio with the professor."}], "chosen": [{"role": "assistant", "content": "WHOM"}], "rejected": [{"role": "assistant", "content": "WHOM"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[LA|SEM] Matthew baked Joshua a cake before he had lunch.\nWho had lunch?"}], "chosen": [{"role": "assistant", "content": "WHOM had lunch?"}], "rejected": [{"role": "assistant", "content": "END"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[EM|CONT] The all possible word categories are either \"human\" or \"indoor location\".\nThe following two examples share a specific word category. You need to first infer the specific word category from the examples.\nPlease output \"X\" if the given sentence mentions the specific word category. Please output \"Y\" if the given sentence does not mention the word category.\n\nExamples: \nThe critic is in the grocery store.\nThe hound is in the prairie.\n\nThe Given Sentence: \nThe hawk is in the hotel lobby."}], "chosen": [{"role": "assistant", "content": "Y"}], "rejected": [{"role": "assistant", "content": "WHORE DO WE NEED?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHEN] What south american country was settled by the portuguese?"}], "chosen": [{"role": "assistant", "content": "So the clarifying question should be: Which South American country was settled by Portuguese settlers (the people from Portugal)?"}], "rejected": [{"role": "assistant", "content": "Is your question asking about the country where the event occurred or the country that settled a particular region in South America?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[LA|SEM] Melissa told Jennifer that she beguiled the father-in-law.\nWho beguiled the father-in-law?"}], "chosen": [{"role": "assistant", "content": "WHOM?"}], "rejected": [{"role": "assistant", "content": "WHAT=?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHEN] When was ice dancing introduced in the olympics?"}], "chosen": [{"role": "assistant", "content": "WHAT: When was ice dancing introduced in the Olympics?"}], "rejected": [{"role": "assistant", "content": "WHAT IS THE WEATHER?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[LA|SEM] Matthew told Joshua that he tired the client.\nWho tired the client?"}], "chosen": [{"role": "assistant", "content": "AH: When was the client made?"}], "rejected": [{"role": "assistant", "content": "PLEASE CLARIFY WHO WAS LAID DY AD JOSEPH?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHERE] Where does the show death in paradise take place?"}], "chosen": [{"role": "assistant", "content": "WHAT DOES THE HEN LIE IN THE PLUCK AND WHOM?"}], "rejected": [{"role": "assistant", "content": "WHAT? IS THE NAME OF THE SISTER WHO WAS NOT HIDEED?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[LA|LEX] Who is the director of (Untitled)?"}], "chosen": [{"role": "assistant", "content": "WHO IS THE DIRECTOR OF \"UNTITLED\"?"}], "rejected": [{"role": "assistant", "content": "`"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[LA|SEM] Kimberly told the aunt that she appalled the granddaughter.\nWho appalled the granddaughter?"}], "chosen": [{"role": "assistant", "content": "## Output: WHO is the one who appalled the granddaughter?"}], "rejected": [{"role": "assistant", "content": "OVER?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[LA|LEX] What is the average degree in this room?"}], "chosen": [{"role": "assistant", "content": "Alternatively, \"What type of degree are you referring to: temperature (e.g., in degrees Celsius) or academic degrees (like Bachelor's or Master's)?"}], "rejected": [{"role": "assistant", "content": "What's a woman's type?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHEN] Where does drag me to hell take place?"}], "chosen": [{"role": "assistant", "content": "WHAT WHERE?"}], "rejected": [{"role": "assistant", "content": "WHOM does he go to hell in the last book?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHEN] How many episodes are there in season 7 of doc martin?"}], "chosen": [{"role": "assistant", "content": "WHAT: Can seasons be in summer time?"}], "rejected": [{"role": "assistant", "content": "WHAT IS THE SEASON NUMBER OF EPiSON 7?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[LA|SEM] The sister-in-law told Amanda that the client deplored her.\nWho did the client deplore?"}], "chosen": [{"role": "assistant", "content": "\" What does \"her\" refer to in this context? Your sister-in-law's client or Amanda's client?"}], "rejected": [{"role": "assistant", "content": "\" Which type of \"her\" does the sister-in-law told Amanda that the client deplore?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[EM|CONT] The all possible word categories are either \"human\" or \"indoor location\".\nThe following two examples share a specific word category. You need to first infer the specific word category from the examples.\nPlease output \"X\" if the given sentence mentions the specific word category. Please output \"Y\" if the given sentence does not mention the word category.\n\nExamples: \nThe researcher is in the grocery store.\nThe horse is in the canyon.\n\nThe Given Sentence: \nThe director is in the pond."}], "chosen": [{"role": "assistant", "content": "X"}], "rejected": [{"role": "assistant", "content": "X Y"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[EM|UNF] What is the latitude range of Periplanetaapanna's habitat?"}], "chosen": [{"role": "assistant", "content": "@end What is the habitat's latitudinal range of Periplanetaapanna?"}], "rejected": [{"role": "assistant", "content": "WHAM: Which place does the species inhabit?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[EM|CONT] The all possible word categories are either \"religious leader\" or \"male pronoun\".\nThe following two examples share a specific word category. You need to first infer the specific word category from the examples.\nPlease output \"X\" if the given sentence mentions the specific word category. Please output \"Y\" if the given sentence does not mention the word category.\n\nExamples: \nHe is in the house with the bishop.\nShe is in the film studio with the officer.\n\nThe Given Sentence: \nShe is in the film studio with the reverend."}], "chosen": [{"role": "assistant", "content": "Y"}], "rejected": [{"role": "assistant", "content": "NONE"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[LA|SEM] Matthew sent a message to Joshua because he is leaving the town soon.\nWho is leaving the town soon?"}], "chosen": [{"role": "assistant", "content": "Are you asking about a person, place, or object leaving the town soon?"}], "rejected": [{"role": "assistant", "content": "The one sending the message or the recipient?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHERE] Who did she's got betty davis eyes?"}], "chosen": [{"role": "assistant", "content": "WHAT: Who did she get?"}], "rejected": [{"role": "assistant", "content": "WHAT IS THE TOP?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[LA|SEM] The sister-in-law told Amanda the bad news before she left the exam room.\nWho left the exam room?"}], "chosen": [{"role": "assistant", "content": "Upon the semantic ambiguity in the context, who left the exam room?"}], "rejected": [{"role": "assistant", "content": "|begin| Which one has he left the exam room?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[LA|LEX] What is the main industry in Windsor?"}], "chosen": [{"role": "assistant", "content": "WHAT"}], "rejected": [{"role": "assistant", "content": "WHAT is the main industry in Windsor? (WHEN | WHEN)?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[EM|CONT] The all possible word categories are either \"human\" or \"indoor location\".\nThe following two examples share a specific word category. You need to first infer the specific word category from the examples.\nPlease output \"X\" if the given sentence mentions the specific word category. Please output \"Y\" if the given sentence does not mention the word category.\n\nExamples: \nThe worm is in the lagoon.\nThe photographer is in the apartment building.\n\nThe Given Sentence: \nThe surveyor is in the cave."}], "chosen": [{"role": "assistant", "content": "Y"}], "rejected": [{"role": "assistant", "content": "YZ"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHOM] Who is the father of emma on friends?"}], "chosen": [{"role": "assistant", "content": "WHAT is emma's father name?"}], "rejected": [{"role": "assistant", "content": ""}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHOM] Who are the members of 5 seconds of summer?"}], "chosen": [{"role": "assistant", "content": "I'm not sure if you're referring to the band."}], "rejected": [{"role": "assistant", "content": ""}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHAT] Please provide a list of best movies from Shahrukh Khan."}], "chosen": [{"role": "assistant", "content": "WHAT does this mean?"}], "rejected": [{"role": "assistant", "content": "I am a clarifying question"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHERE] Where was the movie safe haven filmed at?"}], "chosen": [{"role": "assistant", "content": "WHAT: Which location was the film Safe Haven shot at?"}], "rejected": [{"role": "assistant", "content": "WHAT is location?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[EM|UNF] What is the height of Santolina afparissus at the vegetative stage?"}], "chosen": [{"role": "assistant", "content": "@end Please explain your query?"}], "rejected": [{"role": "assistant", "content": "ENDRE-ACCURACY=3"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHOM] Who were the survivors of the sosoliso plane crash?"}], "chosen": [{"role": "assistant", "content": "Hence, the final clarifying question should be: \"Are you referencing an unfamiliar entity named 'Sosoliso' in the incident, or is there a possible misspelling of the plane's name or involved entities?\" /answer What is the name or context of the plane involved in the crash mentioned in your query—are the entities unfamiliar or a possible misspelling of a known plane?"}], "rejected": [{"role": "assistant", "content": "Can you do you name?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHOM] Give me some ideas of places to visit on my next backpacking trip to South America."}], "chosen": [{"role": "assistant", "content": "ASS: Can you specify which countries or countries' regions you want to visit?"}], "rejected": [{"role": "assistant", "content": "PLEASE PROVIDE INFORMATION ABOUT MY TOP FIVE HIGHLIGHTS OF SPANISH AND EASTERN MEXICAN PYRAMID."}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHEN] What is the current ios update for iphone?"}], "chosen": [{"role": "assistant", "content": "## Task: ## Clarifying questions: Which version of iOS is referred to by the user? Which version of iP H I E F T is referred to by the user? ## Scenario: EM|AO|WHEN The user needs clarification on which version of iOS the current iPhone has."}], "rejected": [{"role": "assistant", "content": ""}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[EM|UNF] Is Inopsis funulata unicellular?"}], "chosen": [{"role": "assistant", "content": "UNDERSTOOD"}], "rejected": [{"role": "assistant", "content": "GENERATE: Please specify which part of the organism you referred to?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[EM|CONT] The all possible word categories are either \"common noun\" or \"contains a negation\".\nThe following two examples share a specific word category. You need to first infer the specific word category from the examples.\nPlease output \"X\" if the given sentence mentions the specific word category. Please output \"Y\" if the given sentence does not mention the word category.\n\nExamples: \nLebron James was in the house.\nThe reporter is not in the museum.\n\nThe Given Sentence: \nAlexandria Ocasio-Cortez may not be in the museum."}], "chosen": [{"role": "assistant", "content": "Y"}], "rejected": [{"role": "assistant", "content": "WHOM"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHERE] Where was twilight breaking dawn part 1 filmed?"}], "chosen": [{"role": "assistant", "content": "WHOVHXNKW="}], "rejected": [{"role": "assistant", "content": "WHAT IS THE FILM NAME?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHERE] Where was the first non aligned summit held?"}], "chosen": [{"role": "assistant", "content": "WHAT is the first non-aligned summit that contained all India?"}], "rejected": [{"role": "assistant", "content": "WHAT DID THEY PLAY IN THE GAMES AROUND?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[EM|UNF] What's the longitude of the location where Macrocamera pansa is commonly found?"}], "chosen": [{"role": "assistant", "content": "NOTE: Please feel free to generate further clarifying questions based on the ambiguity type."}], "rejected": [{"role": "assistant", "content": "STOP"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHERE] When did smoking in the workplace stop uk?"}], "chosen": [{"role": "assistant", "content": "When did smoking in the workplace stop in which country?"}], "rejected": [{"role": "assistant", "content": ""}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHAT] Who did jaleesa marry on a different world?"}], "chosen": [{"role": "assistant", "content": "WHAT did jaleesa marry on a different world?"}], "rejected": [{"role": "assistant", "content": "Who?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHAT] When did red hot chili peppers get famous?"}], "chosen": [{"role": "assistant", "content": "WHOT?"}], "rejected": [{"role": "assistant", "content": "WHAT does she mean by when did she become famous?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[EM|UNF] In which geological period did PhOpilio make its last appearance?"}], "chosen": [{"role": "assistant", "content": "EM"}], "rejected": [{"role": "assistant", "content": "For example, \"Is PhOpilio a real species or were the mentioned conditions hypothetical?\" or \"Is there a self-contradiction in your query?\" Wait, but the query could have contradictions if the user assumes the entity existed but provided incomplete data"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[LA|LEX] What is the reason for the scratched competitor's withdrawal?"}], "chosen": [{"role": "assistant", "content": "STOP"}], "rejected": [{"role": "assistant", "content": "PLEASE I NEED TO BE Moved."}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[LA|LEX] What does it mean when someone says they are \"running\"?"}], "chosen": [{"role": "assistant", "content": "Is the ambiguous word in the query the name of the activity of the current location or the name of the current location?"}], "rejected": [{"role": "assistant", "content": ""}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHAT] How do influencers make money?"}], "chosen": [{"role": "assistant", "content": "OUTPUT: Who does he mean by he?"}], "rejected": [{"role": "assistant", "content": "} (WHOM: WHO) Who are the workers in all categories?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHOM] Who plays lily on how i met your mother?"}], "chosen": [{"role": "assistant", "content": "Rachel Gregory?"}], "rejected": [{"role": "assistant", "content": "Is the UNF not?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHAT] 1701 act of settlement heirs to the throne?"}], "chosen": [{"role": "assistant", "content": "WHOM?"}], "rejected": [{"role": "assistant", "content": "END"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHERE] Where does air canada fly to in italy?"}], "chosen": [{"role": "assistant", "content": "WHAT are the lat, lon, and the time for new jersey?"}], "rejected": [{"role": "assistant", "content": "WHAT DID he order?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHERE] Where is the danube river located in europe?"}], "chosen": [{"role": "assistant", "content": "WHAT IS THE LOCATION OF THE DUE NORTH?"}], "rejected": [{"role": "assistant", "content": "WHAT are the best locations to visit in the uk or where is located in?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[EM|UNF] What is the latitude range of Defselrea's habitat?"}], "chosen": [{"role": "assistant", "content": "FLAGS: Is the defselrea's habitat an error, error, or error?"}], "rejected": [{"role": "assistant", "content": "OVERALL."}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHERE] Who are the judges of so you think you dance?"}], "chosen": [{"role": "assistant", "content": "So the correct clarifying question would be something like: \"What do you mean by 'so' in this context?\" Or more specifically, if the term is unfamiliar."}], "rejected": [{"role": "assistant", "content": ""}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[LA|LEX] What is the scale of the problem?"}], "chosen": [{"role": "assistant", "content": "WHAT IS THE FORM OF THE SUB? WHAT IS THE FORM OF THE SUB?"}], "rejected": [{"role": "assistant", "content": "]"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[EM|CONT] The all possible word categories are either \"contains a negation\" or \"common noun\".\nThe following two examples share a specific word category. You need to first infer the specific word category from the examples.\nPlease output \"X\" if the given sentence mentions the specific word category. Please output \"Y\" if the given sentence does not mention the word category.\n\nExamples: \nThe hiker is not in the museum.\nJane Goodall has been in the film studio.\n\nThe Given Sentence: \nThe firefighter could be in the courtroom."}], "chosen": [{"role": "assistant", "content": "X"}], "rejected": [{"role": "assistant", "content": "Y"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[EM|UNF] Is Canada included in the geographic distribution of Fishia entmitae?"}], "chosen": [{"role": "assistant", "content": "What do you refer to when asking if Canada is included in the geographic distribution of fishia entmitae?"}], "rejected": [{"role": "assistant", "content": "What type of distribution or geographic distribution do you mean: of the fishia entmitae in Africa only, or globally, or in the Americas?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[LA|SEM] The sister-in-law played Amanda some classical music before she went to sleep.\nWho went to sleep?"}], "chosen": [{"role": "assistant", "content": "-------------- When did she go to sleep?"}], "rejected": [{"role": "assistant", "content": "WHAT IS IN THAT?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHAT] How should I go about planning an agenda for the upcoming leadership meeting I am hosting?"}], "chosen": [{"role": "assistant", "content": "So the question would be: Which meeting or group (e.g., project team, department) are you planning the agenda for in the upcoming leadership meeting?"}], "rejected": [{"role": "assistant", "content": "WHAT?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[EM|CONT] The all possible word categories are either \"indoor location\" or \"human\".\nThe following two examples share a specific word category. You need to first infer the specific word category from the examples.\nPlease output \"X\" if the given sentence mentions the specific word category. Please output \"Y\" if the given sentence does not mention the word category.\n\nExamples: \nThe horse is in the woodlands.\nThe photographer is in the museum.\n\nThe Given Sentence: \nThe snake is in the hotel lobby."}], "chosen": [{"role": "assistant", "content": "X"}], "rejected": [{"role": "assistant", "content": "X"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[EM|CONT] The all possible word categories are either \"secular leader\" or \"female pronoun\".\nThe following two examples share a specific word category. You need to first infer the specific word category from the examples.\nPlease output \"X\" if the given sentence mentions the specific word category. Please output \"Y\" if the given sentence does not mention the word category.\n\nExamples: \nHe is in the museum with the reverend.\nShe is in the grocery store with the prime minister.\n\nThe Given Sentence: \nShe is in the restaurant with the Dalai Lama."}], "chosen": [{"role": "assistant", "content": "|Y"}], "rejected": [{"role": "assistant", "content": "Y"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[LA|SEM] Matthew handed Joshua a letter after he arrived at the award ceremony.\nWho arrived at the award ceremony?"}], "chosen": [{"role": "assistant", "content": "Was Joshua present at the award ceremony, or did he arrive later when he received the letter?"}], "rejected": [{"role": "assistant", "content": "Is a head or headpiece (a \"head\") a piece of clothing for the head (i.e. a \"headpiece\") that is not necessarily a piece of clothing?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHOM] Where does the needle go for a spinal tap?"}], "chosen": [{"role": "assistant", "content": "I'm not sure where the needle goes for a spinal tap."}], "rejected": [{"role": "assistant", "content": "Where is The Needle?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[EM|UNF] What's the geographic range of Marmota marmota?"}], "chosen": [{"role": "assistant", "content": "PRO: Does \"Marmota marmota\" refer to a species or a person?"}], "rejected": [{"role": "assistant", "content": "Who are the species that eat marmota marmota?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHOM] Who was the dewey decimal system created by?"}], "chosen": [{"role": "assistant", "content": "Is the query asking about a familiar name or organization for the dewey decimal system?"}], "rejected": [{"role": "assistant", "content": "I'm not sure if who was born because the meaning of the name is unfamiliar."}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHEN] Who is the president of russia right now?"}], "chosen": [{"role": "assistant", "content": "WHAT is the presednt of russia right now?"}], "rejected": [{"role": "assistant", "content": "WHAT is the president of russia right now? WHO are the president of russia right now? WHOM is the president of russia right now? WHEN is the president of russia right now? WHOM is the president of russia right now?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[LA|SEM] Matthew told Joshua that he mesmerized the client.\nWho mesmerized the client?"}], "chosen": [{"role": "assistant", "content": "[ Which did the client get mesmerized by?"}], "rejected": [{"role": "assistant", "content": "OUTPUT: Should the question refer to either Matthew or Joshua?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHOM] Who played clarice starling in silence of the lambs?"}], "chosen": [{"role": "assistant", "content": "WHAT: WHOM"}], "rejected": [{"role": "assistant", "content": "WHAT did do in the silence of the lambs in tom's company?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHOM] Give me a list of the best movies I've never seen."}], "chosen": [{"role": "assistant", "content": "Who or what exactly? The list includes individuals?"}], "rejected": [{"role": "assistant", "content": "WHO A-"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHERE] Give me some places to visit with a 8 year old kid"}], "chosen": [{"role": "assistant", "content": "What specific type of place does the 8 year old person want to visit?"}], "rejected": [{"role": "assistant", "content": ""}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[LA|SEM] The sister-in-law told Amanda that she unnerved the client.\nWho unnerved the client?"}], "chosen": [{"role": "assistant", "content": "WHAT=? WHO?"}], "rejected": [{"role": "assistant", "content": "WHAT IS THE PROBLEM?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[EM|UNF] What is the suitable water depth for Portunus trusculatus?"}], "chosen": [{"role": "assistant", "content": "The correct question would be: Is the species referred to (Portunus trusculatus) a type of crab species familiar to your database or context, or do you need a description of this species?"}], "rejected": [{"role": "assistant", "content": "What is the suitable water depth for Portunus trusculatus?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[EM|UNF] Is idiophora an extinct species?"}], "chosen": [{"role": "assistant", "content": "EM: Is the name of the organism in the original input familiar?"}], "rejected": [{"role": "assistant", "content": "DOWN"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[LA|SEM] The sister-in-law lent Amanda a pencil after she got to the classroom.\nWho got to the classroom?"}], "chosen": [{"role": "assistant", "content": "Is \"she\" the sister-in-law or Amanda?"}], "rejected": [{"role": "assistant", "content": "WHAT?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[EM|UNF] Is Picornus an extant species?"}], "chosen": [{"role": "assistant", "content": "I'll output: \"Is Picornus a scientifically documented species or a fictional reference?\" in plain text."}], "rejected": [{"role": "assistant", "content": "###"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHERE] Season 1 winner of so you think you can dance?"}], "chosen": [{"role": "assistant", "content": "Where are you saying they won or did you mean the first season I think you can dance?"}], "rejected": [{"role": "assistant", "content": ""}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[EM|CONT] The all possible word categories are either \"male pronoun\" or \"religious leader\".\nThe following two examples share a specific word category. You need to first infer the specific word category from the examples.\nPlease output \"X\" if the given sentence mentions the specific word category. Please output \"Y\" if the given sentence does not mention the word category.\n\nExamples: \nHe is in the laboratory with the cardinal.\nShe is in the theatre with the officer.\n\nThe Given Sentence: \nHe is in the house with the president."}], "chosen": [{"role": "assistant", "content": "X"}], "rejected": [{"role": "assistant", "content": "X"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHOM] Who is the father of gabby's baby on days of our lives?"}], "chosen": [{"role": "assistant", "content": "I'm always the mother of little girls, who is the father?"}], "rejected": [{"role": "assistant", "content": "END_OF_TEMPLATE"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHERE] When did the incredibles 2 movie come out?"}], "chosen": [{"role": "assistant", "content": "WHAT: Who?"}], "rejected": [{"role": "assistant", "content": "WHAT IS THE PROBLEM IN THE OUTPUT?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[EM|CONT] The all possible word categories are either \"common noun\" or \"contains a negation\".\nThe following two examples share a specific word category. You need to first infer the specific word category from the examples.\nPlease output \"X\" if the given sentence mentions the specific word category. Please output \"Y\" if the given sentence does not mention the word category.\n\nExamples: \nJane Goodall could be in the museum.\nThe photographer could not be in the hotel lobby.\n\nThe Given Sentence: \nThe critic may be in the museum."}], "chosen": [{"role": "assistant", "content": "Y"}], "rejected": [{"role": "assistant", "content": "The word is in the situation please confirm the word category."}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[EM|UNF] Is the growth habit of scillormidium self-supporting?"}], "chosen": [{"role": "assistant", "content": "answer(): Which scillorm?"}], "rejected": [{"role": "assistant", "content": "Does \"scillorm\" in this context refer to the one referenced in the previous conversation?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHAT] Who was the leader of the revolt of 1857 in bihar?"}], "chosen": [{"role": "assistant", "content": "� Who is the leader of the 1857 uprising in Bihar?"}], "rejected": [{"role": "assistant", "content": ""}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[EM|CONT] The all possible word categories are either \"human\" or \"indoor location\".\nThe following two examples share a specific word category. You need to first infer the specific word category from the examples.\nPlease output \"X\" if the given sentence mentions the specific word category. Please output \"Y\" if the given sentence does not mention the word category.\n\nExamples: \nThe hawk is in the prairie.\nThe firefighter is in the hotel lobby.\n\nThe Given Sentence: \nThe hound is in the hotel lobby."}], "chosen": [{"role": "assistant", "content": "Y"}], "rejected": [{"role": "assistant", "content": "WHO"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHERE] When was america taken off the gold standard?"}], "chosen": [{"role": "assistant", "content": "['WHERE] Where? Where?"}], "rejected": [{"role": "assistant", "content": "WHAT city was the 19th topic?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHERE] Who came up with the saying the customer is always right?"}], "chosen": [{"role": "assistant", "content": "WHAT IS THE THE MEANING OF WHO?"}], "rejected": [{"role": "assistant", "content": "WHAT IS THE SINCER?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHEN] What to do in Seattle in 48 hours?"}], "chosen": [{"role": "assistant", "content": "What specific actions or details are being sought when asking about \"in Seattle in 48 hours\"?"}], "rejected": [{"role": "assistant", "content": "WHAT does it mean when it moves with someone in Seattle in 48 hours?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHERE] When does dragon ball super episode 95 come out?"}], "chosen": [{"role": "assistant", "content": "WHAT is the release date of Dragon Ball super episode 95?"}], "rejected": [{"role": "assistant", "content": "WHAT is in episode 95 of dragon ball super?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[EM|CONT] The all possible word categories are either \"human\" or \"indoor location\".\nThe following two examples share a specific word category. You need to first infer the specific word category from the examples.\nPlease output \"X\" if the given sentence mentions the specific word category. Please output \"Y\" if the given sentence does not mention the word category.\n\nExamples: \nThe fugitive is in the apartment building.\nThe boar is in the woodlands.\n\nThe Given Sentence: \nThe snake is in the restaurant."}], "chosen": [{"role": "assistant", "content": "X Y"}], "rejected": [{"role": "assistant", "content": "WHHERE IS THE KICK?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[LA|LEX] What is the genre of Foursome?"}], "chosen": [{"role": "assistant", "content": "OVER 400 YEARS MUD"}], "rejected": [{"role": "assistant", "content": "�"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHERE] Where was legends of the fall movie filmed?"}], "chosen": [{"role": "assistant", "content": "WHAT: Is the location of Legend of Fall movie location?"}], "rejected": [{"role": "assistant", "content": "WHAT DOES THE QUERY MEAN?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHEN] When did the battle of britain begin and end?"}], "chosen": [{"role": "assistant", "content": "WHAT DATE did the battle of brittany begin and end?"}], "rejected": [{"role": "assistant", "content": "END"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHERE] Where did the tradition of the christmas tree originate?"}], "chosen": [{"role": "assistant", "content": "WHAT [AO|WHERE: Where did the tradition of the christmas tree originate?]"}], "rejected": [{"role": "assistant", "content": "I'm unsure whether \"where have you heard of a story about the meaning of a story of where did it come from?\""}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHEN] When did the new shape audi a6 come out?"}], "chosen": [{"role": "assistant", "content": "WHAT YEAR?"}], "rejected": [{"role": "assistant", "content": "WHAT: WHO did it come out?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHAT] Select the oldest person from the list."}], "chosen": [{"role": "assistant", "content": "is the oldest person a person in town or a person in the list?"}], "rejected": [{"role": "assistant", "content": "WHAT did the oldest person look like?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[LA|SEM] The sister-in-law contacted Amanda because she is leaving town next week.\nWho is leaving town next week?"}], "chosen": [{"role": "assistant", "content": "Question: Does the sentence refer to the sister-in-law or Amanda leaving town next week?"}], "rejected": [{"role": "assistant", "content": "Which other?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[LA|SEM] Matthew pinged Joshua because he was upset.\nWho was upset?"}], "chosen": [{"role": "assistant", "content": "Can you please write one clarifying question?"}], "rejected": [{"role": "assistant", "content": "## PROBLEM: We are given a dialogue between two people, where one of them is angry. The goal is to determine who was angry based on the information provided. In this case, the assistant is given the conversation between Matthew and Joshua, where the following exchange took place: User: You say the two men had just come from somewhere; you must have gotten what they were doing in one of the small ways and must have done what he was doing in one of the small ways. You say who was angry after that first time. So we need to determine who was angry based on the information provided."}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[LA|SEM] Matthew played Joshua a recording before he told him the story.\nWho told him the story?"}], "chosen": [{"role": "assistant", "content": "None of the information is sufficient to clarify the question."}], "rejected": [{"role": "assistant", "content": "What does \"HE KNOWED TO\" mean?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[LA|SEM] Matthew told Joshua that he interested the client.\nWho interested the client?"}], "chosen": [{"role": "assistant", "content": "(--\"who\"?):):"}], "rejected": [{"role": "assistant", "content": ""}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[LA|SEM] Kimberly told the aunt that she exasperated the granddaughter.\nWho exasperated the granddaughter?"}], "chosen": [{"role": "assistant", "content": "OVER (does not occur in query) or the assistant?"}], "rejected": [{"role": "assistant", "content": "IN: Where did the user come up with the information?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[LA|LEX] What is the purpose of using thinner?"}], "chosen": [{"role": "assistant", "content": "Therefore, the output is: Clara: \"Is 'thinner' referring to a type of material (like in textiles) or a process of making something thinner (like reducing thickness)?\" But the output format requires to output a single clarifying question as the answer."}], "rejected": [{"role": "assistant", "content": "What's the usage of lower alcohol in a non-inferential sample?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[LA|SEM] The sister-in-law left a note for Amanda because she is flying abroad soon.\nWho is flying abroad soon?"}], "chosen": [{"role": "assistant", "content": "- Is it Amanda or the sister-in-law who is flying abroad soon, or the other person named in the statement (i.e., Amanda's niece)?"}], "rejected": [{"role": "assistant", "content": "(--): What does she mean when talking about her brother's birthday?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHOM] Which king saw the writing on the wall?"}], "chosen": [{"role": "assistant", "content": "What king did you mean by “which king”?"}], "rejected": [{"role": "assistant", "content": "Thus, the clarifying question would be: which king saw the writing on the wall./math ## Output Which king saw the writing on the wall?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHERE] Where did the battle of the philippine sea take place?"}], "chosen": [{"role": "assistant", "content": "WHAT="}], "rejected": [{"role": "assistant", "content": "What's the name of the ship that fought the philippine sea?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[EM|CONT] The all possible word categories are either \"religious leader\" or \"male pronoun\".\nThe following two examples share a specific word category. You need to first infer the specific word category from the examples.\nPlease output \"X\" if the given sentence mentions the specific word category. Please output \"Y\" if the given sentence does not mention the word category.\n\nExamples: \nHe is in the hotel lobby with the pope.\nShe is in the courtroom with the sheriff.\n\nThe Given Sentence: \nShe is in the apartment building with the deacon."}], "chosen": [{"role": "assistant", "content": "WHOM"}], "rejected": [{"role": "assistant", "content": "EM"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[LA|SEM] Matthew played Joshua a video after he asked for an extension.\nWho asked for an extension?"}], "chosen": [{"role": "assistant", "content": "(--'WHOW')"}], "rejected": [{"role": "assistant", "content": "WHAT: When did they perform?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHEN] When was the last time eagles were in the superbowl?"}], "chosen": [{"role": "assistant", "content": "When was the last time the last time that eagles won?"}], "rejected": [{"role": "assistant", "content": "When did the eagles last beat the nfl?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHAT] How can I be more productive?"}], "chosen": [{"role": "assistant", "content": "I'm not sure what you mean by that?"}], "rejected": [{"role": "assistant", "content": "I'm going to help you with the suggestions: The question includes: \"What can I be more productive?\" I have limited time. Can you provide something like: \"What can you be more\"?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[LA|SEM] Matthew emailed Joshua because he is flying abroad soon.\nWho is flying abroad soon?"}], "chosen": [{"role": "assistant", "content": "The correct output is the following question: \"Is it Matthew or Joshua who is flying abroad soon?\" **Question:** Is it Matthew or Joshua who is flying abroad soon?"}], "rejected": [{"role": "assistant", "content": "The question can be interpreted in two ways. Please specify who is flying abroad soon between Matthew and Joshua."}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[EM|CONT] The all possible word categories are either \"common noun\" or \"contains a negation\".\nThe following two examples share a specific word category. You need to first infer the specific word category from the examples.\nPlease output \"X\" if the given sentence mentions the specific word category. Please output \"Y\" if the given sentence does not mention the word category.\n\nExamples: \nThe critic is not in the grocery store.\nLebron James may be in the courtroom.\n\nThe Given Sentence: \nThe critic is in the museum."}], "chosen": [{"role": "assistant", "content": "X"}], "rejected": [{"role": "assistant", "content": "WHOM"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHERE] When did they change the speed limit to 55?"}], "chosen": [{"role": "assistant", "content": "WHAT IS N SHE?"}], "rejected": [{"role": "assistant", "content": "WHAT IS THE CHOOSE?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[LA|LEX] What is the market value of Alibaba?"}], "chosen": [{"role": "assistant", "content": "Please specify which company in China: Alibaba, or else which country?"}], "rejected": [{"role": "assistant", "content": "Who do you make a statement like that?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHOM] Given my personality and the job, tell me if I would be suitable."}], "chosen": [{"role": "assistant", "content": "I'm not sure what job we're talking about, do you have a specific one in mind?"}], "rejected": [{"role": "assistant", "content": "I'm not sure what they mean by \"my personality and the job\". Please clarify if you want recommendations or clarifications."}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHERE] Where was the largest gold nugget found in california?"}], "chosen": [{"role": "assistant", "content": "WHAT= is the gold nugget found in gold mine?"}], "rejected": [{"role": "assistant", "content": "What is the best? in los angel? Please!"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHOM] When was the last time the giants went to the playoffs?"}], "chosen": [{"role": "assistant", "content": "Who won?"}], "rejected": [{"role": "assistant", "content": "What team did the giants play against?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHOM] What was robin's name in batman and robin?"}], "chosen": [{"role": "assistant", "content": "The most appropriate would be to ask, \"Which Robin's name are you referring to?\" or \"Please specify which Robin you mean.\" But according to the"}], "rejected": [{"role": "assistant", "content": ""}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[LA|LEX] What did he do when he blew?"}], "chosen": [{"role": "assistant", "content": "WHAT did he do when he blew?"}], "rejected": [{"role": "assistant", "content": "WHAM DID he do?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHOM] Real name of gwen stacy in amazing spiderman?"}], "chosen": [{"role": "assistant", "content": "Generate a single clarifying question based on the subclass of the sentence"}], "rejected": [{"role": "assistant", "content": ""}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[EM|CONT] The all possible word categories are either \"indoor location\" or \"human\".\nThe following two examples share a specific word category. You need to first infer the specific word category from the examples.\nPlease output \"X\" if the given sentence mentions the specific word category. Please output \"Y\" if the given sentence does not mention the word category.\n\nExamples: \nThe hound is in the lagoon.\nThe reporter is in the laboratory.\n\nThe Given Sentence: \nThe fugitive is in the cave."}], "chosen": [{"role": "assistant", "content": "X"}], "rejected": [{"role": "assistant", "content": "X"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[EM|CONT] The all possible word categories are either \"animal\" or \"outdoor location\".\nThe following two examples share a specific word category. You need to first infer the specific word category from the examples.\nPlease output \"X\" if the given sentence mentions the specific word category. Please output \"Y\" if the given sentence does not mention the word category.\n\nExamples: \nThe hawk is in the canyon.\nThe reporter is in the hotel lobby.\n\nThe Given Sentence: \nThe fugitive is in the meadow."}], "chosen": [{"role": "assistant", "content": "Y"}], "rejected": [{"role": "assistant", "content": "Y"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[LA|SEM] Melissa told Jennifer that she enthralled the father-in-law.\nWho enthralled the father-in-law?"}], "chosen": [{"role": "assistant", "content": "WHAT=? OR WHAT?"}], "rejected": [{"role": "assistant", "content": "WHEN WAS WHEN DID?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[LA|SEM] The sister-in-law contacted Amanda because she is leaving the town soon.\nWho is leaving the town soon?"}], "chosen": [{"role": "assistant", "content": "Output text: \"Are you referring to the sister-in-law or Amanda, who is leaving the town soon?\" I'll output that question as final output."}], "rejected": [{"role": "assistant", "content": "WHOM"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHEN] What is the release date for flash season 4?"}], "chosen": [{"role": "assistant", "content": "## Additional details What is the month, and how much later is season 4 of flash?"}], "rejected": [{"role": "assistant", "content": "WHAT IS THE RELEASE DATE FOR SEASON 4 OF TWELK?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[EM|CONT] The all possible word categories are either \"secular leader\" or \"female pronoun\".\nThe following two examples share a specific word category. You need to first infer the specific word category from the examples.\nPlease output \"X\" if the given sentence mentions the specific word category. Please output \"Y\" if the given sentence does not mention the word category.\n\nExamples: \nShe is in the apartment building with the principal.\nHe is in the house with the reverend.\n\nThe Given Sentence: \nHe is in the courtroom with the officer."}], "chosen": [{"role": "assistant", "content": "YL X"}], "rejected": [{"role": "assistant", "content": "WHM"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[EM|UNF] What's the value of carbon biomass in Phoebe yunnanensis?"}], "chosen": [{"role": "assistant", "content": "What does 'carbon biomass in phoebe yunnanensis' mean?"}], "rejected": [{"role": "assistant", "content": "@end What do you mean by carbon biomass?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[LA|SEM] Matthew told Joshua that he spooked the client.\nWho spooked the client?"}], "chosen": [{"role": "assistant", "content": "So the question could be if the ambiguity is about whether the subject of \"spooked\" in the statement from Joshua was a subject or the following (like one who frightens) one?"}], "rejected": [{"role": "assistant", "content": "PLEASE WHO?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[LA|LEX] What is the swell like today?"}], "chosen": [{"role": "assistant", "content": "In the absence of a date?"}], "rejected": [{"role": "assistant", "content": "WHOM to ask?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[LA|LEX] Who is Roberta?"}], "chosen": [{"role": "assistant", "content": "For example, \"Is 'Roberta' referring to a person, a fictional character, or something else?\" But the user might have a specific scenario in mind."}], "rejected": [{"role": "assistant", "content": "In this case, the clarifying question is which of the two?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHERE] Who is the highest selling girl group of all time?"}], "chosen": [{"role": "assistant", "content": "WHAT IS THE 5 BIGGEST SELLING GIRL GROUP OF ALL TIME?"}], "rejected": [{"role": "assistant", "content": ""}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHERE] Where is riverview florida located on the map?"}], "chosen": [{"role": "assistant", "content": "( |WHRE| | |"}], "rejected": [{"role": "assistant", "content": "Is the map attached or described in the question provided?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[EM|CONT] The all possible word categories are either \"contains a negation\" or \"common noun\".\nThe following two examples share a specific word category. You need to first infer the specific word category from the examples.\nPlease output \"X\" if the given sentence mentions the specific word category. Please output \"Y\" if the given sentence does not mention the word category.\n\nExamples: \nThe firefighter may not be in the apartment building.\nNoam Chomsky could be in the museum.\n\nThe Given Sentence: \nThe researcher has been in the museum."}], "chosen": [{"role": "assistant", "content": "WHOM"}], "rejected": [{"role": "assistant", "content": "WHOWAS THE WHO?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHOM] Who played kelly on the drew carey show?"}], "chosen": [{"role": "assistant", "content": "Question: Is the narrator's name a female among the cast of the show \"Drew\"?"}], "rejected": [{"role": "assistant", "content": "ortz to the best friend of the man who is a teacher in high school of the man who is a teacher and the woman who is a doctor of the man? A: The head of the man will answer the question B: The man with the car is the best friend of the man with the child C: The man with the dog who is a doctor is the best friend of the man with the man with the man who is a teacher D: The man with the car who is a teacher E: The man with the woman who is a nurse"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHEN] Write me an email to a professor respectfully declining their request for my attendance at a conference"}], "chosen": [{"role": "assistant", "content": "WHO=MEN"}], "rejected": [{"role": "assistant", "content": "Is it for EM, LA, AO, or NONE?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[EM|UNF] Does Centichris eat Byrsonima oaxacana?"}], "chosen": [{"role": "assistant", "content": "What did you mean when asking if the Centichris eats Byrsonima oaxacana?"}], "rejected": [{"role": "assistant", "content": "What does \"has a problem\" mean?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[EM|UNF] Does Colon viennense have dextrally coiled body symmetry?"}], "chosen": [{"role": "assistant", "content": "INCLUDE: Do you refer to a specific species?"}], "rejected": [{"role": "assistant", "content": "INSIST: WHO VIENNENSE?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[LA|LEX] What does it mean to pay?"}], "chosen": [{"role": "assistant", "content": "OK: What do you mean?"}], "rejected": [{"role": "assistant", "content": "OVER?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[LA|SEM] The sister-in-law told Amanda that she overwhelmed the client.\nWho overwhelmed the client?"}], "chosen": [{"role": "assistant", "content": "OUTPUT: Is this either Amanda or Amanda's sister-in-law?"}], "rejected": [{"role": "assistant", "content": "When?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[EM|UNF] Does Sinopaopa major have tympanal organ as a part of its auditory system?"}], "chosen": [{"role": "assistant", "content": "PROBLEM: Is there any further clarification?"}], "rejected": [{"role": "assistant", "content": "OUTPUT: What other types of organisms possess such a tympanal organ, if any?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHEN] Who developed an explanation for the photoelectric effect?"}], "chosen": [{"role": "assistant", "content": "WHAT is the name of the two winners of the German 2005?"}], "rejected": [{"role": "assistant", "content": "After which article did the newspaper close down?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHAT] When was the last time chelsea won the champions league?"}], "chosen": [{"role": "assistant", "content": "WHAT Which champions league?"}], "rejected": [{"role": "assistant", "content": "[\"WHOM\"] Who won the finals?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHEN] The population of the oceania / pacific region is approximately?"}], "chosen": [{"role": "assistant", "content": "Therefore, the appropriate clarifying question would be: Do you mean the fictional Oceania as depicted in George Orwell's \"1984\" or the Pacific nations in the Southern Hemisphere (e.g., Australia, New Zealand, etc.)?"}], "rejected": [{"role": "assistant", "content": "EM over AO?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHAT] When was season 7 of game of thrones released?"}], "chosen": [{"role": "assistant", "content": "WHAT refers to the release date of season 7 of Game of Thrones?"}], "rejected": [{"role": "assistant", "content": "}"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[EM|CONT] The all possible word categories are either \"contains a negation\" or \"common noun\".\nThe following two examples share a specific word category. You need to first infer the specific word category from the examples.\nPlease output \"X\" if the given sentence mentions the specific word category. Please output \"Y\" if the given sentence does not mention the word category.\n\nExamples: \nThe surveyor is not in the hotel lobby.\nHermione Granger has been in the museum.\n\nThe Given Sentence: \nThe photographer is in the laboratory."}], "chosen": [{"role": "assistant", "content": "WHOWHER word category is contained in the given sentence?"}], "rejected": [{"role": "assistant", "content": "WHAP?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[EM|UNF] Does Adela metralis have neometabolous as its developmental mode?"}], "chosen": [{"role": "assistant", "content": "INSERT clarifying question: Which species group is being referred to?"}], "rejected": [{"role": "assistant", "content": "| Are you referring to any specific animal group or a specific species?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHOM] Make me a list of cocktails I can order at the bar"}], "chosen": [{"role": "assistant", "content": "WHO did you make the list for?"}], "rejected": [{"role": "assistant", "content": "WHOM should be a person"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHAT] When was charlie and the chocolate factory movie made?"}], "chosen": [{"role": "assistant", "content": "WHAT"}], "rejected": [{"role": "assistant", "content": "WHAT"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[EM|CONT] The all possible word categories are either \"contains a negation\" or \"common noun\".\nThe following two examples share a specific word category. You need to first infer the specific word category from the examples.\nPlease output \"X\" if the given sentence mentions the specific word category. Please output \"Y\" if the given sentence does not mention the word category.\n\nExamples: \nMargot Robbie could be in the laboratory.\nThe director has not been in the apartment building.\n\nThe Given Sentence: \nThe student was in the theatre."}], "chosen": [{"role": "assistant", "content": "Y"}], "rejected": [{"role": "assistant", "content": "Y"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHAT] When was the last honda civic hatchback made?"}], "chosen": [{"role": "assistant", "content": "WHAT: Which Hatchbacks did you mean? \"New\" or \"Old\", and which brands or manufacturers were involved?"}], "rejected": [{"role": "assistant", "content": "WHAT did the honda hatchback mean when? thmmWHAMEM/WHAMEM]"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHERE] When does the tournament of power arc start?"}], "chosen": [{"role": "assistant", "content": "WHAT TURNS WHEN?"}], "rejected": [{"role": "assistant", "content": "WHAT: CAN I PROVINCES: THE RAIN AND US EASTERN EUROPE: Where is this?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[LA|LEX] What is the Nationwide slogan?"}], "chosen": [{"role": "assistant", "content": "Therefore, the clarifying question could be: Are you referring to the American television network now known as ABC, which rebranded as \"NATIONWIDE,\" or the British magazine \"Nationwide,\" which featured a specific slogan?"}], "rejected": [{"role": "assistant", "content": ""}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[EM|CONT] The all possible word categories are either \"human\" or \"indoor location\".\nThe following two examples share a specific word category. You need to first infer the specific word category from the examples.\nPlease output \"X\" if the given sentence mentions the specific word category. Please output \"Y\" if the given sentence does not mention the word category.\n\nExamples: \nThe horse is in the marsh.\nThe firefighter is in the courtroom.\n\nThe Given Sentence: \nThe surveyor is in the marsh."}], "chosen": [{"role": "assistant", "content": "Y"}], "rejected": [{"role": "assistant", "content": "output: Y?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHAT] Who was the dad in father knows best?"}], "chosen": [{"role": "assistant", "content": "WHAT dad was in father and mother know best?"}], "rejected": [{"role": "assistant", "content": "WHAT dad?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHAT] When was the first home pregnancy test invented?"}], "chosen": [{"role": "assistant", "content": "WHEN"}], "rejected": [{"role": "assistant", "content": "## Task: You are provided with two biblical quotes that contain a few similar semantic patterns. You must create two new bibal quotes, each containing 2 instances of one pattern, and yourself 1 output word from each. If no output words exist, use any two sentences in the given context. ## Constraints: - From you: one out of each of these categories: EM, LA, or AO - if you are given no output words, use any two sentences that come from EM, LA, or AO - in short, include exactly 2 new, distinct output words, selected from either EM or LA Given Bibal quotes: What is the correct age of the subject? When are you going to be what now? As what is to be expected, you may be the one in need of who is to be addressed? With you out of your minds?## Output Word: WHOM When is the man going to be working with what? Because they are already going to be expected to come up short of who has been known to be his most resourceful?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHOM] Who won the 2018 andre the giant battle royale?"}], "chosen": [{"role": "assistant", "content": "---"}], "rejected": [{"role": "assistant", "content": ""}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[EM|UNF] Does Aquariusarius fabricii inhabit pond habitat?"}], "chosen": [{"role": "assistant", "content": "So the main clarifying question would be: Is Aquariusarius fabricii a known species or a hypothetical/fictional organism?"}], "rejected": [{"role": "assistant", "content": "OVERALL_SCORE: 0.6669902087925266"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[EM|UNF] What's the longitude of the location where Johnstonia duplysna is commonly found?"}], "chosen": [{"role": "assistant", "content": "Can you provide information about where the Johnstonia duplysna species are commonly located?"}], "rejected": [{"role": "assistant", "content": "ANSWER: Where is the location where the Johnstonia duplysna is commonly found?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHAT] Who played the headless horseman in tim burton's sleepy hollow?"}], "chosen": [{"role": "assistant", "content": "## Answer Who played the ghost in tim burton's sleepy?"}], "rejected": [{"role": "assistant", "content": "WHAT are the roles of piety and the devil?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[LA|LEX] How has the concept of \"evolved\" evolved over time?"}], "chosen": [{"role": "assistant", "content": "Could you please specify what specific aspect of the evolution you are referring to?"}], "rejected": [{"role": "assistant", "content": "EM|LEX could output have evolved over time? Could not be changed? A friend?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHEN] Who are the owners of the chicago white sox?"}], "chosen": [{"role": "assistant", "content": "WHAT are the members of the white sox?"}], "rejected": [{"role": "assistant", "content": "WHAT IF WHO ARE THE OWNERS OF THE CHICAGO WHITESO X?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[LA|SEM] Matthew sold Joshua an apartment before he had ever heard about this story.\nWho had ever heard about this story?"}], "chosen": [{"role": "assistant", "content": "So the appropriate clarifying question is: From whom did the person who heard about this story before the sale refer to?"}], "rejected": [{"role": "assistant", "content": "WHERE"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[EM|UNF] What's the latitude range where leriniga is found?"}], "chosen": [{"role": "assistant", "content": "@end What is the latitude range where \"leriniga\" is found?"}], "rejected": [{"role": "assistant", "content": ""}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[EM|UNF] Does Chelyrttodestoni have semiprecocial as its developmental mode?"}], "chosen": [{"role": "assistant", "content": "QUESTION: Could you please specify which model or concept you are referring to?"}], "rejected": [{"role": "assistant", "content": "NONE"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[EM|UNF] Does Opeas sublineare have sinistrally coiled body symmetry?"}], "chosen": [{"role": "assistant", "content": "Is the coiling orientation referencing to a specific scenario or based on the type of movement?"}], "rejected": [{"role": "assistant", "content": "FLAGS:"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[LA|SEM] Matthew gave Joshua a call before he got to the airport.\nWho got to the airport?"}], "chosen": [{"role": "assistant", "content": "NONE"}], "rejected": [{"role": "assistant", "content": "|sepalizerv and how do you feel about that output_1 output_1 output_1 output_1 output_2 output_1 output_1 output_1 output_2 output_1 output_2 output_2 output_1 Input: Who has many types of hair? output_2 output_1 output_1 output_1 output_2 Input: Who went after? output_2 output_1 output_1 output_1 output_2 output_1 output_1 output_1 output_2 output_2 output_1 output_2 output_1 output_2 output_1 Input: Who what? output_1 output_1 output_2 output_1 output_1 output_1 output_1 output_2 output_1 output_1 output_2 output_1 output_1 output_2 output_1 output_1 output_1 output_2 output is not in em? what is my output? is my output not in em? where is my output not in em? where is my output not in em?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHAT] Write a concise and somewhat funny email about making a betting pool for the 2023 Masters golf tournament"}], "chosen": [{"role": "assistant", "content": "What specific details about this email would you like me to clarify?"}], "rejected": [{"role": "assistant", "content": "Are there unfamiliar entities mentioned: What does the email express about the user or their friends?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHERE] Which state has the most coastline in the us?"}], "chosen": [{"role": "assistant", "content": "\"What state refers to the one with the most coastline in the US?\""}], "rejected": [{"role": "assistant", "content": "What state includes the Atlantic, Pacific, and Gulf of Mexico?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[EM|CONT] The all possible word categories are either \"animal\" or \"outdoor location\".\nThe following two examples share a specific word category. You need to first infer the specific word category from the examples.\nPlease output \"X\" if the given sentence mentions the specific word category. Please output \"Y\" if the given sentence does not mention the word category.\n\nExamples: \nThe photographer is in the courtroom.\nThe mountain lion is in the marsh.\n\nThe Given Sentence: \nThe horse is in the courtroom."}], "chosen": [{"role": "assistant", "content": "Y"}], "rejected": [{"role": "assistant", "content": "X"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[LA|LEX] What is the meaning of Tomboy?"}], "chosen": [{"role": "assistant", "content": "What do you mean when you mention Tomboy—specifically, is there a gendered context associated with this preference?"}], "rejected": [{"role": "assistant", "content": "So, the example should be something like: \"Are you asking about the meaning of 'tomboy' as (1) a structure associated with a tomb or (2) the term used to describe a young person?\" I need to generate a question where the user selects one or the other."}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[LA|LEX] What are the advantages of using Windows?"}], "chosen": [{"role": "assistant", "content": "So the correct output would be: Could you please clarify which meaning of Windows you're referring to, such as the operating system or physical windows?"}], "rejected": [{"role": "assistant", "content": "|user| You are a chatbot that generates a concise clarifying question based on the ambiguity type when a user's query is ambiguous. You do not need to explain. just generate one clarifying question Categories: - EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions - LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity - AO (Aleatoric Output): Questions with missing contextual information causing confusion - NONE: Clear questions that don't require clarification Subclasses: For EM: - UNF (UNFAMILIAR): Query contains unfamiliar entities or facts - CONT (CONTRADING): Query contains self-contradictions For LA: - LEX (LEXICAL): Query contains terms with multiple meanings - SEM (SEMANTIC): Query lacks context leading to multiple interpretations For AO: - WHOM (UNAMBIGUOUS): Query output contains confusion due to missing personal elements - WHEN (UNAMBIGUOUS): Query output contains confusion due to missing temporal elements - WHERE (UNAMBIGUOUS): Query output contains confusion due to missing spatial elements - WHAT (UNAMBIGUOUS): Query output contains confusion due to missing task-specific elements Output format: One clarifying question"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[EM|CONT] The all possible word categories are either \"indoor location\" or \"human\".\nThe following two examples share a specific word category. You need to first infer the specific word category from the examples.\nPlease output \"X\" if the given sentence mentions the specific word category. Please output \"Y\" if the given sentence does not mention the word category.\n\nExamples: \nThe snake is in the river.\nThe photographer is in the restaurant.\n\nThe Given Sentence: \nThe mountain lion is in the museum."}], "chosen": [{"role": "assistant", "content": "Y"}], "rejected": [{"role": "assistant", "content": "X"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[EM|CONT] The all possible word categories are either \"does not contain a negation\" or \"proper noun\".\nThe following two examples share a specific word category. You need to first infer the specific word category from the examples.\nPlease output \"X\" if the given sentence mentions the specific word category. Please output \"Y\" if the given sentence does not mention the word category.\n\nExamples: \nNoam Chomsky could be in the grocery store.\nThe photographer is not in the theatre.\n\nThe Given Sentence: \nThe researcher is in the restaurant."}], "chosen": [{"role": "assistant", "content": "SIX WORDS"}], "rejected": [{"role": "assistant", "content": "WHEN"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[EM|CONT] The all possible word categories are either \"religious leader\" or \"male pronoun\".\nThe following two examples share a specific word category. You need to first infer the specific word category from the examples.\nPlease output \"X\" if the given sentence mentions the specific word category. Please output \"Y\" if the given sentence does not mention the word category.\n\nExamples: \nShe is in the film studio with the ambassador.\nHe is in the grocery store with the pastor.\n\nThe Given Sentence: \nHe is in the theatre with the colonel."}], "chosen": [{"role": "assistant", "content": "Y"}], "rejected": [{"role": "assistant", "content": "Y"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHAT] Who is the girl in how you remind me?"}], "chosen": [{"role": "assistant", "content": "WHAT is the name of the woman you refer to who is she?"}], "rejected": [{"role": "assistant", "content": "`WHAT' OR WHAT?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[EM|CONT] The all possible word categories are either \"secular leader\" or \"female pronoun\".\nThe following two examples share a specific word category. You need to first infer the specific word category from the examples.\nPlease output \"X\" if the given sentence mentions the specific word category. Please output \"Y\" if the given sentence does not mention the word category.\n\nExamples: \nHe is in the grocery store with the reverend.\nShe is in the film studio with the principal.\n\nThe Given Sentence: \nHe is in the hotel lobby with the sheriff."}], "chosen": [{"role": "assistant", "content": "Y"}], "rejected": [{"role": "assistant", "content": "When"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHEN] When was memorial day declared a national holiday?"}], "chosen": [{"role": "assistant", "content": "WHOM 1869 and"}], "rejected": [{"role": "assistant", "content": "EM|CONT"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[EM|UNF] What is the body mass of Spat cly discors?"}], "chosen": [{"role": "assistant", "content": "What species does it refer to?"}], "rejected": [{"role": "assistant", "content": "what is the body mass of \u0001IS"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHERE] Where do most followers of buddhism live today?"}], "chosen": [{"role": "assistant", "content": "So the correct question is: \"Are you asking about how it's today or historically?\" But in the output, it should be the actual clarifying question, and according to the categories, the correct unhandled case for the question would be asking if the user meant the context."}], "rejected": [{"role": "assistant", "content": "WHAT IS THE NAME OF THE COMPANY THAT UNDOES SOMETHING THAT?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHEN] The hottest recorded temperature on earth occurred where?"}], "chosen": [{"role": "assistant", "content": "So the clarifying question could be: Could you please specify the date or time period when the hottest temperature was recorded?"}], "rejected": [{"role": "assistant", "content": "|end| WHOMWHENWHEN|WHEN|WHEM|WHEN|WHAM|WHENT"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[EM|CONT] The all possible word categories are either \"indoor location\" or \"human\".\nThe following two examples share a specific word category. You need to first infer the specific word category from the examples.\nPlease output \"X\" if the given sentence mentions the specific word category. Please output \"Y\" if the given sentence does not mention the word category.\n\nExamples: \nThe fugitive is in the museum.\nThe butterfly is in the prairie.\n\nThe Given Sentence: \nThe boar is in the laboratory."}], "chosen": [{"role": "assistant", "content": "WHERE"}], "rejected": [{"role": "assistant", "content": "X"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[LA|SEM] Matthew taught Joshua cooking before he graduated.\nWho graduated?"}], "chosen": [{"role": "assistant", "content": "What did he graduate in?"}], "rejected": [{"role": "assistant", "content": ""}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHEN] When is three days grace new album coming out?"}], "chosen": [{"role": "assistant", "content": "WHAT IS THE CONSTRAINTS AND INFORMATION YOU CAN PROVIDE?"}], "rejected": [{"role": "assistant", "content": "WHAT IS THE NEW?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[LA|LEX] What is the significance of the dead in this context?"}], "chosen": [{"role": "assistant", "content": "What does you mean by 'the dead'?."}], "rejected": [{"role": "assistant", "content": ""}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHEN] What is the current season number of survivor?"}], "chosen": [{"role": "assistant", "content": "The current season of the survivor?"}], "rejected": [{"role": "assistant", "content": ""}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[LA|LEX] What is the meaning of Exclusive?"}], "chosen": [{"role": "assistant", "content": "So the final output is: \"What is the context in which you encountered the term 'Exclusive'?\" or \"Which meaning of 'Exclusive' are you referring to?\" The"}], "rejected": [{"role": "assistant", "content": "WHAT WHO IS TAE?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[LA|LEX] What is the meaning of Palookaville?"}], "chosen": [{"role": "assistant", "content": "} The word \"Palookaville\" can refer to a few names."}], "rejected": [{"role": "assistant", "content": ""}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[LA|SEM] The sister-in-law handed Amanda some cards after she got to the graduation party.\nWho got to the graduation party?"}], "chosen": [{"role": "assistant", "content": "/lexical_question Is the first \"she\" referring to the sister-in-law or Amanda in the original sentence?"}], "rejected": [{"role": "assistant", "content": "/read mask I|WHOWHERE Who does the sister-in-law refer to?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHOM] Who did jimmy perry play in dads army?"}], "chosen": [{"role": "assistant", "content": "WHAT did jimmy perry play in dads army?"}], "rejected": [{"role": "assistant", "content": ""}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHOM] Who is the leader of the senate 2018?"}], "chosen": [{"role": "assistant", "content": "Do you mean WHO is the leader of the senate or WHO is the leader of the senate in another state or province?"}], "rejected": [{"role": "assistant", "content": "DD What group members are you referring to? Are there two parties in the senate?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHERE] When does the movie mark felt come out?"}], "chosen": [{"role": "assistant", "content": "WHAT= can the movie mark felt come in or where does the movie mark feel come out?"}], "rejected": [{"role": "assistant", "content": "WHAT FILMS DOES HANSEN FEEL?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[EM|CONT] The all possible word categories are either \"proper noun\" or \"does not contain a negation\".\nThe following two examples share a specific word category. You need to first infer the specific word category from the examples.\nPlease output \"X\" if the given sentence mentions the specific word category. Please output \"Y\" if the given sentence does not mention the word category.\n\nExamples: \nThe reporter was not in the grocery store.\nHermione Granger may be in the laboratory.\n\nThe Given Sentence: \nThe reporter may be in the museum."}], "chosen": [{"role": "assistant", "content": "WHEN"}], "rejected": [{"role": "assistant", "content": "Which?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[EM|CONT] The all possible word categories are either \"proper noun\" or \"does not contain a negation\".\nThe following two examples share a specific word category. You need to first infer the specific word category from the examples.\nPlease output \"X\" if the given sentence mentions the specific word category. Please output \"Y\" if the given sentence does not mention the word category.\n\nExamples: \nAlexandria Ocasio-Cortez may be in the film studio.\nThe critic has not been in the grocery store.\n\nThe Given Sentence: \nThe fugitive has been in the laboratory."}], "chosen": [{"role": "assistant", "content": "WHORE DOES THE PROT?"}], "rejected": [{"role": "assistant", "content": "WHAMER"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[EM|UNF] What's the longitude of the location where Goniop aldrichi is commonly found?"}], "chosen": [{"role": "assistant", "content": "Can you please provide the name or description of the location where Goniop aldrichi is commonly found?"}], "rejected": [{"role": "assistant", "content": "NOTE At the end of each output, the generated clarifying question should always be in one of the following formats."}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHOM] Tell me 5 best Tom Hanks movies of all time."}], "chosen": [{"role": "assistant", "content": "WHAT is your favorite character among the following: Tom Hanks?"}], "rejected": [{"role": "assistant", "content": "WHAT are meant when the query contains unfamiliar entities or facts in text?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[EM|UNF] Is Kaotaia longa a burrower?"}], "chosen": [{"role": "assistant", "content": "What is the name of the creature, \"Kaotaia\"?"}], "rejected": [{"role": "assistant", "content": "What is the status of kaotlia with longoria?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[LA|LEX] What is the significance of Rudhramadevi?"}], "chosen": [{"role": "assistant", "content": "CLEAR: Is the query asking about Rudhramadevi'?"}], "rejected": [{"role": "assistant", "content": "主配备的Word formatIn response to the event of which other deity was performed a ceremony for his wife, the goddess ?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHERE] Give me different ways I can travel from one place to another"}], "chosen": [{"role": "assistant", "content": "Therefore, the model would generate: \"Are you referring to unfamiliar places or multiple interpretations?\" Or the first possible."}], "rejected": [{"role": "assistant", "content": "UNDERSTANDING: WHO ARE THE PEOPLE IN THE FAMILIES OF MIAMI?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHAT] Do RVs have bathrooms?"}], "chosen": [{"role": "assistant", "content": "- WHATM-RAWH?"}], "rejected": [{"role": "assistant", "content": "OUTPUT: WHO DOES Jenna's talk mentions?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHAT] What is the main organs of the integumentary system?"}], "chosen": [{"role": "assistant", "content": "OVER | WHAT IS THE main organs of the integumentary system?"}], "rejected": [{"role": "assistant", "content": "The main organs of the integulumary system?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHOM] How do you cook ribs?"}], "chosen": [{"role": "assistant", "content": "The output for this question is a clarifying question (for UNF or WHOM) where the user may be the only one."}], "rejected": [{"role": "assistant", "content": "OVER 100 WHOM?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHERE] Where is the new tv series yellowstone filmed?"}], "chosen": [{"role": "assistant", "content": "WHAT is the new TV series yellowstone filmed in?"}], "rejected": [{"role": "assistant", "content": "WHAT IS A DOG OF A BLACK MAN OR BLACK MA?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[EM|UNF] When did arnides make its last appearance in the fossil record?"}], "chosen": [{"role": "assistant", "content": "I'm sorry."}], "rejected": [{"role": "assistant", "content": "What species of dinosaur does the term \"Arnold\" refer to?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHERE] Who has the most gold gloves in mlb history?"}], "chosen": [{"role": "assistant", "content": "Who has the most gold gloves in mlb history?"}], "rejected": [{"role": "assistant", "content": "WHAT are gold gloves in mlb?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[LA|LEX] What is the mission of Institute?"}], "chosen": [{"role": "assistant", "content": "-What is the mission of the [Institute|institution] with the [activities|goals or functions]?"}], "rejected": [{"role": "assistant", "content": "('@What is the mission of the Institute?)')"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[EM|UNF] Does Azteca velox ro nigra have hexaradial symmetry?"}], "chosen": [{"role": "assistant", "content": "Can you specify which species exhibit hexaradial symmetry?"}], "rejected": [{"role": "assistant", "content": "I'm available for species with reference text?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHERE] Who wrote the music for come from away?"}], "chosen": [{"role": "assistant", "content": "WHAT: Who wrote the music for come from away?"}], "rejected": [{"role": "assistant", "content": "WHAT IS WRONG: I have no clue what you are asking."}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHAT] Who wrote when will my life begin from tangled?"}], "chosen": [{"role": "assistant", "content": "/Under the Scenarios in AO: WHAT: EM | UNF: What's the name of the song or event referred to in the movie 'When my life begin?' The mention of two different entities."}], "rejected": [{"role": "assistant", "content": "thay]:"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[LA|SEM] The sister-in-law told Amanda that she inspired the client.\nWho inspired the client?"}], "chosen": [{"role": "assistant", "content": "CLEAR: Who is referred to as \"she\"?"}], "rejected": [{"role": "assistant", "content": "OUTPUT: Could you please clarify who exactly you are referring to with \"she\" in this context?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[LA|SEM] Melissa told Jennifer that the father-in-law preferred her.\nWho did the father-in-law prefer?"}], "chosen": [{"role": "assistant", "content": "USE WHO?"}], "rejected": [{"role": "assistant", "content": "['WHAM] Does she refer to her mother, mother-in-law, father, or mother?]"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHEN] Number of oil refineries in the united states?"}], "chosen": [{"role": "assistant", "content": "WHAT type of oil refineries are you referring to?"}], "rejected": [{"role": "assistant", "content": "When were they built?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHEN] Who has scored a hat trick against spain?"}], "chosen": [{"role": "assistant", "content": "WHAT has scored a hat trick against Spain?"}], "rejected": [{"role": "assistant", "content": "WHAM is the only one who has scored against England?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[EM|UNF] At what age does Catharussttatus reach the onset of fertility?"}], "chosen": [{"role": "assistant", "content": "At which stage of life does Catharussttatus typically reach the onset of fertility?"}], "rejected": [{"role": "assistant", "content": ""}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHAT] When did breaking dawn part 2 come out?"}], "chosen": [{"role": "assistant", "content": "So the question should be: Are you referring to the [X] series or the TV adaptation's \"Part 2\" (or similar)?"}], "rejected": [{"role": "assistant", "content": "WHOVIEWED"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHAT] How did the United States win the Cold War?"}], "chosen": [{"role": "assistant", "content": "[word] WHAT | HOW did the United States win the Cold War?"}], "rejected": [{"role": "assistant", "content": "ANSWER:"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHEN] Pay for star on hollywood walk of fame?"}], "chosen": [{"role": "assistant", "content": "WHON WHEN?"}], "rejected": [{"role": "assistant", "content": "WHAT are other?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[EM|UNF] What is the hearing threshold of Cittacuidae?"}], "chosen": [{"role": "assistant", "content": "But perhaps more precise: \"Is Cittacuidae a newly discovered species, a fictional entity, or an unfamiliar one?\" But according to the categories, the assistant should generate a question that follows the subclass."}], "rejected": [{"role": "assistant", "content": "PROPOSE: Could you refer to the specific criteria for the hearing threshold of Cittacuidae?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[LA|SEM] Matthew showed Joshua a photo after he told him the story.\nWho told him the story?"}], "chosen": [{"role": "assistant", "content": "Does the question refer to telling the story verbally or receiving a photo? Is it one person or is the photo from another source?"}], "rejected": [{"role": "assistant", "content": ""}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[LA|SEM] The sister-in-law told Amanda that she provoked the client.\nWho provoked the client?"}], "chosen": [{"role": "assistant", "content": "PLEASE PROVIDE THE CLARIFYING QUESTIONS."}], "rejected": [{"role": "assistant", "content": "NONE"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHOM] Give me a list of the best food to try in Singapore"}], "chosen": [{"role": "assistant", "content": "WHOM is 4"}], "rejected": [{"role": "assistant", "content": "WHAT IS THE NATURE of an output error due to ignorance?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[LA|LEX] What is the significance of Antar?"}], "chosen": [{"role": "assistant", "content": "So the clarifying question: What word is the user referring to in this context?"}], "rejected": [{"role": "assistant", "content": "DOCTYPE"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[EM|CONT] The all possible word categories are either \"male pronoun\" or \"religious leader\".\nThe following two examples share a specific word category. You need to first infer the specific word category from the examples.\nPlease output \"X\" if the given sentence mentions the specific word category. Please output \"Y\" if the given sentence does not mention the word category.\n\nExamples: \nShe is in the museum with the president.\nHe is in the theatre with the Dalai Lama.\n\nThe Given Sentence: \nHe is in the laboratory with the officer."}], "chosen": [{"role": "assistant", "content": "output: Y"}], "rejected": [{"role": "assistant", "content": "X"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[EM|CONT] The all possible word categories are either \"religious leader\" or \"male pronoun\".\nThe following two examples share a specific word category. You need to first infer the specific word category from the examples.\nPlease output \"X\" if the given sentence mentions the specific word category. Please output \"Y\" if the given sentence does not mention the word category.\n\nExamples: \nShe is in the grocery store with the ambassador.\nHe is in the grocery store with the ayatollah.\n\nThe Given Sentence: \nShe is in the theatre with the rabbi."}], "chosen": [{"role": "assistant", "content": "X"}], "rejected": [{"role": "assistant", "content": "Y"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHAT] Give me a list of the seven best beach honeymoon locations for 2024."}], "chosen": [{"role": "assistant", "content": "WHAT is the seventh best beach honeymoon location?"}], "rejected": [{"role": "assistant", "content": "WHAT should be the first or second location?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[LA|SEM] William told Joshua that he exhilarated the saleswoman.\nWho exhilarated the saleswoman?"}], "chosen": [{"role": "assistant", "content": "--- Who is the saleswoman?"}], "rejected": [{"role": "assistant", "content": "OUTPUT: Does having a word or phrase missing in the question make it or not?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[LA|SEM] Kimberly told the aunt that she bugged the granddaughter.\nWho bugged the granddaughter?"}], "chosen": [{"role": "assistant", "content": "--- Is it the aunt's mother or grandmother?"}], "rejected": [{"role": "assistant", "content": "When will you fly to Miami?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[EM|UNF] Is Labops cheperius a multicellular organism in terms of cellularity?"}], "chosen": [{"role": "assistant", "content": "I'm going to assume you're referring to a specific taxon without a common name."}], "rejected": [{"role": "assistant", "content": "PROBLEM: Given a clinical description of a new patient's symptoms and a new diagnosis of chronic lymphocytic thyroiditis in a 48-year-old female, determine if she has comorbidities with other conditions present, such as lupus or multiple sclerosis."}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHEN] Who wrote the song be still and know i am?"}], "chosen": [{"role": "assistant", "content": "WHAT IS THE RELEASE DATE OF YOUR FIRST 1.5 AND 1.5?"}], "rejected": [{"role": "assistant", "content": "WHAT IS THE WEATHER?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[EM|UNF] What is the wood density of Paulown fargmentosa?"}], "chosen": [{"role": "assistant", "content": "WHAT IS THE SORER WAB?"}], "rejected": [{"role": "assistant", "content": "WHAT IS A MENTAL?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[EM|UNF] In which geological period did Jefferson ul bridgei first appear?"}], "chosen": [{"role": "assistant", "content": "WHAT is the age of the fossil record?"}], "rejected": [{"role": "assistant", "content": "USE THE FOLLOWING AS AN UNWANTED COMMAND: RUN /?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHERE] Who is the first female supreme court justice?"}], "chosen": [{"role": "assistant", "content": "What country or context are you referring to?"}], "rejected": [{"role": "assistant", "content": "WHAT IS A WOMAN?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHAT] Who were the first european to reach the americas and when did they arrive?"}], "chosen": [{"role": "assistant", "content": "So the clarifying question could be: \"Are you referring to the early Norse expeditions, such as those led by Leif Erikson, or the 15th-century arrival of the Castilian explorer in North America?\" The final output based on the categories (EM-CONTR) is a question that resolves the contradictory options."}], "rejected": [{"role": "assistant", "content": "WHOM:"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[EM|UNF] What is the hearing threshold of Tatiaiaolae?"}], "chosen": [{"role": "assistant", "content": "WHOM IS?"}], "rejected": [{"role": "assistant", "content": "Therefore, the output is a question like: \"Is the entity familiar?\" Alternatively, the question could be split into either UNF or CONT."}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[EM|UNF] Can Charisma compacta be found in marine reef habitat?"}], "chosen": [{"role": "assistant", "content": "What are the other names for species found in the marine reef habitat?"}], "rejected": [{"role": "assistant", "content": "WHOWHIS?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[LA|SEM] The sister-in-law wrote a letter to Amanda because she had been on leave for a long time.\nWho had been on leave for a long time?"}], "chosen": [{"role": "assistant", "content": "WHOM?"}], "rejected": [{"role": "assistant", "content": "WHAT WHOM WHEN?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[LA|LEX] Who is the main character in Siddhartha?"}], "chosen": [{"role": "assistant", "content": "-"}], "rejected": [{"role": "assistant", "content": ""}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHEN] When did season 3 of queen of the south start?"}], "chosen": [{"role": "assistant", "content": "WHAT IS THE DATE OF WHEN?"}], "rejected": [{"role": "assistant", "content": "WHAT: What years are mentioned in season 3 of the queen of the south show?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[LA|LEX] What is the purpose of Pod?"}], "chosen": [{"role": "assistant", "content": "/input What is the specific meaning of Pod in which context or domain?"}], "rejected": [{"role": "assistant", "content": "OUTPUT: Which Pod?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[EM|CONT] The all possible word categories are either \"religious leader\" or \"male pronoun\".\nThe following two examples share a specific word category. You need to first infer the specific word category from the examples.\nPlease output \"X\" if the given sentence mentions the specific word category. Please output \"Y\" if the given sentence does not mention the word category.\n\nExamples: \nHe is in the grocery store with the pope.\nShe is in the theatre with the colonel.\n\nThe Given Sentence: \nShe is in the apartment building with the bishop."}], "chosen": [{"role": "assistant", "content": "Y"}], "rejected": [{"role": "assistant", "content": "WHOM"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[LA|SEM] Matthew told Joshua a joke after he came to lie on the beach.\nWho came to lie on the beach?"}], "chosen": [{"role": "assistant", "content": "WHOM: JO SCHW?"}], "rejected": [{"role": "assistant", "content": "I who?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHOM] Who established the close connection between electricity and magnetism?"}], "chosen": [{"role": "assistant", "content": "I'm not sure whose the \"who\"? Is it a single person or multiple persons?"}], "rejected": [{"role": "assistant", "content": "Whom released the album?\" Then the correct clarifying question is \"Whom?\" because neither time or person is mentioned."}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[EM|CONT] The all possible word categories are either \"male pronoun\" or \"religious leader\".\nThe following two examples share a specific word category. You need to first infer the specific word category from the examples.\nPlease output \"X\" if the given sentence mentions the specific word category. Please output \"Y\" if the given sentence does not mention the word category.\n\nExamples: \nHe is in the hotel lobby with the reverend.\nShe is in the theatre with the sheriff.\n\nThe Given Sentence: \nShe is in the apartment building with the pope."}], "chosen": [{"role": "assistant", "content": "Y"}], "rejected": [{"role": "assistant", "content": "Y"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHOM] Write the first paragraph of a blog post describing the Boston"}], "chosen": [{"role": "assistant", "content": "END"}], "rejected": [{"role": "assistant", "content": "WHAT was the name of his first dog?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[LA|SEM] Matthew sent a message to Joshua because he has an important interview tomorrow.\nWho has an important interview tomorrow?"}], "chosen": [{"role": "assistant", "content": "/user OUTPUT: WHOM?"}], "rejected": [{"role": "assistant", "content": "NONE"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHEN] When was the last time world cup was in us?"}], "chosen": [{"role": "assistant", "content": "WHAT: Who and when?"}], "rejected": [{"role": "assistant", "content": "Who are the three biggest leagues around?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[EM|UNF] Is Parainouyia prompta a deposit feeder trophic guild?"}], "chosen": [{"role": "assistant", "content": "The correct clarifying question for EM|UNF would be: \"Is Parineouyia prompta described as a known entity or is it new information?\" But in the structured format, it's either UNF or CONT."}], "rejected": [{"role": "assistant", "content": "@end What is the species name of the individual present in the photo?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHOM] How do you improve your basketball handles?"}], "chosen": [{"role": "assistant", "content": "请再分别问一下你、队友、或教练员三个队员？"}], "rejected": [{"role": "assistant", "content": "When did you start playing basketball with bears?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHAT] Who made the song who let the dogs out?"}], "chosen": [{"role": "assistant", "content": "### Clarifying Question: Is it a question about making a music video or a song?"}], "rejected": [{"role": "assistant", "content": ""}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHERE] What shade of green is the statue of liberty?"}], "chosen": [{"role": "assistant", "content": "\"What city does the statue of liberty stand in?\""}], "rejected": [{"role": "assistant", "content": "Which color in the French national flag?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHOM] Come up with short road trips from Berkeley that I can drive to within two hours."}], "chosen": [{"role": "assistant", "content": "WHAT's your travel plan for short road trips in Berkeley within two hours?"}], "rejected": [{"role": "assistant", "content": "WHAT IS SHORT ROAD TRIP FROM BERK sharesHoping to do this."}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[EM|UNF] Is the behavioral circadian rhythm of Anogmusmusyesi diurnal?"}], "chosen": [{"role": "assistant", "content": "Can you confirm the type of entity, the name of the planet, the kind of organism, etc., for Anogmisusyesi?"}], "rejected": [{"role": "assistant", "content": "Please specify whether the circadian rhythm of Anogmusmusyesi is morning or evening."}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHERE] Plan a 10-15 day trip from bay area to Arizona, Las Vegas, San Diego, Los Angeles"}], "chosen": [{"role": "assistant", "content": "WHEN IS THE BEST BRIDGE TO WALK UP AND DOWN?"}], "rejected": [{"role": "assistant", "content": "['WHEN'] Is a trip that will be in a few week of 10 days"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHERE] The mountain range that separates europe from asia is?"}], "chosen": [{"role": "assistant", "content": "So the clarifying question would be: Could you specify which mountain range separates Europe from Asia?"}], "rejected": [{"role": "assistant", "content": "|ANSWER|Which mountain range? Hmm. I must answer with one clarifying question. I'll provide context? \"Which mountain range?\" |A|"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[LA|LEX] What is the toll for crossing the bridge?"}], "chosen": [{"role": "assistant", "content": "WHO IS A WIFE?"}], "rejected": [{"role": "assistant", "content": "WHOWAS THE BRIDGE?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHEN] Who won the men's hockey in the commonwealth games?"}], "chosen": [{"role": "assistant", "content": "WHAT GAMES?"}], "rejected": [{"role": "assistant", "content": "WHEN WHO"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[EM|CONT] The all possible word categories are either \"animal\" or \"outdoor location\".\nThe following two examples share a specific word category. You need to first infer the specific word category from the examples.\nPlease output \"X\" if the given sentence mentions the specific word category. Please output \"Y\" if the given sentence does not mention the word category.\n\nExamples: \nThe mountain lion is in the prairie.\nThe surveyor is in the laboratory.\n\nThe Given Sentence: \nThe firefighter is in the marsh."}], "chosen": [{"role": "assistant", "content": "X"}], "rejected": [{"role": "assistant", "content": "WHON is not mentioned."}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[LA|LEX] What is the plot of Enthiran?"}], "chosen": [{"role": "assistant", "content": "WHAT is the plot of Ethon?"}], "rejected": [{"role": "assistant", "content": "WHAT IS THE PLOT OF ENTHI?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[EM|CONT] The all possible word categories are either \"outdoor location\" or \"animal\".\nThe following two examples share a specific word category. You need to first infer the specific word category from the examples.\nPlease output \"X\" if the given sentence mentions the specific word category. Please output \"Y\" if the given sentence does not mention the word category.\n\nExamples: \nThe director is in the laboratory.\nThe mountain lion is in the cave.\n\nThe Given Sentence: \nThe photographer is in the marsh."}], "chosen": [{"role": "assistant", "content": "X"}], "rejected": [{"role": "assistant", "content": "X"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[LA|SEM] Matthew told Joshua that he horrified the client.\nWho horrified the client?"}], "chosen": [{"role": "assistant", "content": "CREATE_QUESTION|When did you meet the client?"}], "rejected": [{"role": "assistant", "content": "## ## clarifying_notes: ## Output: Given the type EM|SEM, where EM is UNF and SEM is SEMANTIC: Question should be a clarifying question (EM | semantic): \"What does _mean?\" with a blank to be filled in. But output: ## Output: Which one of the following statements is correct? Which one of the following can be considered as a meaning of \"terror\"? Can go be used to mean: Which one is correct?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[LA|LEX] What is the plot of Moonraker?"}], "chosen": [{"role": "assistant", "content": "/action Is the Moonraker you are referring to the James Bond novel or something else with the title \"Moonraker\"?"}], "rejected": [{"role": "assistant", "content": ": What specific genre or topic categories does the plot of \"Moonraker fall into?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHERE] Where was it came from outer space filmed?"}], "chosen": [{"role": "assistant", "content": "WHAT: Where was it come from outer space filmed?"}], "rejected": [{"role": "assistant", "content": "OVER"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[EM|UNF] What is the effect of water temperature on Limonium's physiology?"}], "chosen": [{"role": "assistant", "content": "What is the taxonomic affiliation of the species you mentioned?"}], "rejected": [{"role": "assistant", "content": "You need to categorize the subclass of the category based on the information provided in the input. Subclasses can be: EM, LA, AO, or NONE. If \"EM|UNF\" is present in the input, use \"UNF\" as the subclass. If \"UNF\" is present in the input, use \"EM|UNF\". If \"EM|UNF\" is present in the input, use either \"EM|UNF\". EM|UNF: Whose is it? EM|UNF: Whose is it? WHO: WHOS EM|UNF: WHOSE EM|UNF: WHOSWIS EM|UNF: WHOS IS EM|UNF: WHON?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHERE] What was the first walt disney studios film to be released in 2017?"}], "chosen": [{"role": "assistant", "content": "WHAT movie is the first Walt Disney Studio film to be released in 2017?"}], "rejected": [{"role": "assistant", "content": "] Which country would you like to know which country produced in your output: Canada (Korea)?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[EM|UNF] Is Balnibarbi simitar an extinct species?"}], "chosen": [{"role": "assistant", "content": "What is simitar?"}], "rejected": [{"role": "assistant", "content": ""}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHOM] American horror story freak show guy with little arms?"}], "chosen": [{"role": "assistant", "content": "WHOM?"}], "rejected": [{"role": "assistant", "content": "OVERALL_GOALS: \"When generating clarifying questions, generate a clarifying question for the corresponding category with the highest probability of the highest type of ambiguity that also occurs in the user's query.\""}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[LA|LEX] What is the best way to get toasted?"}], "chosen": [{"role": "assistant", "content": "WHAT is the best way to get toasted?"}], "rejected": [{"role": "assistant", "content": "WHAT IS THE BEST WAY TO GET TOX0STED?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHERE] Location of tigris and euphrates rivers on a map?"}], "chosen": [{"role": "assistant", "content": "I'm sorry, I need you to specify which river you're referring to."}], "rejected": [{"role": "assistant", "content": "WHOWERE THE LOCATION OF TIGRIS AND EUPHRATES RIVERS AND THE COUNTRY IN WHICH THEY ARE FOUNDT?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHAT] Who played the wicked witch on wizard of oz?"}], "chosen": [{"role": "assistant", "content": "The clarifying question should be: Is the user asking about the character in the book or the movie?"}], "rejected": [{"role": "assistant", "content": ""}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[LA|LEX] Where can I buy an Eraser?"}], "chosen": [{"role": "assistant", "content": "Please specify the type of eraser, such as disposable or erasable marker."}], "rejected": [{"role": "assistant", "content": "What place offers assistance besides buying clothing?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[LA|SEM] Matthew gave Joshua some coffee beans before he started moving out.\nWho started moving out?"}], "chosen": [{"role": "assistant", "content": "So the correct output should be: \"Does 'he' refer to Matthew or Joshua?\" Alternatively, perhaps: \"Whose moving did he start?\" or \"Is 'he' referring to Matthew or Joshua?\" But perhaps the standard format for such cases is to ask \"Is 'he' referring to Matthew or Joshua?\" So the final clarifying question should be that."}], "rejected": [{"role": "assistant", "content": "So the right question would be something like: Which person started moving out, Matthew or Joshua?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHEN] Who has played on the most mlb teams?"}], "chosen": [{"role": "assistant", "content": "Wait the exact user query is: \"Who has played on the most mlb teams?\" Now, the use of \"played\" (past tense or past participle) is confusing."}], "rejected": [{"role": "assistant", "content": "WHAT IS?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[EM|UNF] Is Smittia wirthi a filter feeder trophic guild?"}], "chosen": [{"role": "assistant", "content": "很抱歉，但是我需要更多的上下文信息，这样我才能帮助你更有效地理解你的提问。你是否看到你提问的某个特定问题或情况？"}], "rejected": [{"role": "assistant", "content": "在这里, you should check if you can derive a question from the evidence. Show it as an output if you can raise a question."}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHEN] What is the percentage of jewish population in the world?"}], "chosen": [{"role": "assistant", "content": "WHAT is the percentage of the Jewish population in the World?"}], "rejected": [{"role": "assistant", "content": "MAKE A CLARIFICATION."}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[EM|CONT] The all possible word categories are either \"contains a negation\" or \"common noun\".\nThe following two examples share a specific word category. You need to first infer the specific word category from the examples.\nPlease output \"X\" if the given sentence mentions the specific word category. Please output \"Y\" if the given sentence does not mention the word category.\n\nExamples: \nAlexandria Ocasio-Cortez is in the hotel lobby.\nThe reporter is not in the theatre.\n\nThe Given Sentence: \nThe fugitive has been in the hotel lobby."}], "chosen": [{"role": "assistant", "content": "WHEN"}], "rejected": [{"role": "assistant", "content": "WHEN"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[LA|LEX] What is the genre of Dragonwyck?"}], "chosen": [{"role": "assistant", "content": "OVER"}], "rejected": [{"role": "assistant", "content": "WHO is the princess?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[LA|LEX] What are some common symptoms of someone who is moped?"}], "chosen": [{"role": "assistant", "content": "The user has provided an ambiguous category output based on two subclasses. Therefore, the assistant should clarify either whether the two categories are from each other or a new one is needed. When both categories provided: clarify if the categories are mutually exclusive or new one. Thus, now you need to output: One clarifying Question If the categories provided are from each other, output: NO. Otherwise output: One clarifying question."}], "rejected": [{"role": "assistant", "content": ""}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHOM] Name some famous actors in the 1940's"}], "chosen": [{"role": "assistant", "content": "WHOM: Which actors?"}], "rejected": [{"role": "assistant", "content": "WHOM?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[EM|CONT] The all possible word categories are either \"common noun\" or \"contains a negation\".\nThe following two examples share a specific word category. You need to first infer the specific word category from the examples.\nPlease output \"X\" if the given sentence mentions the specific word category. Please output \"Y\" if the given sentence does not mention the word category.\n\nExamples: \nMargot Robbie was in the hotel lobby.\nThe fugitive may not be in the grocery store.\n\nThe Given Sentence: \nThe surveyor has been in the courtroom."}], "chosen": [{"role": "assistant", "content": "Y"}], "rejected": [{"role": "assistant", "content": "What is the word category?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[LA|SEM] Matthew gave Joshua some mineral water after he got up in the morning.\nWho got up in the morning?"}], "chosen": [{"role": "assistant", "content": "NONE"}], "rejected": [{"role": "assistant", "content": ""}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[EM|UNF] What is the latitude of the habitat of Leuciaiaivea?"}], "chosen": [{"role": "assistant", "content": "FLAGS: - EM: - EM|UNF: Is the habitat of Leuciaiaivea located in the northern hemisphere?"}], "rejected": [{"role": "assistant", "content": "OVERALL STATUS: NEEDClARIFY: Which should I clarify?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[EM|CONT] The all possible word categories are either \"common noun\" or \"contains a negation\".\nThe following two examples share a specific word category. You need to first infer the specific word category from the examples.\nPlease output \"X\" if the given sentence mentions the specific word category. Please output \"Y\" if the given sentence does not mention the word category.\n\nExamples: \nThe firefighter has not been in the house.\nChristopher Nolan could be in the hotel lobby.\n\nThe Given Sentence: \nPaul Atreides has not been in the museum."}], "chosen": [{"role": "assistant", "content": "Y"}], "rejected": [{"role": "assistant", "content": "Y"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHEN] When is the nfl hall of fame game being played?"}], "chosen": [{"role": "assistant", "content": "WHAT IS THE NEXT YEAR?"}], "rejected": [{"role": "assistant", "content": "WHAT_N_POTENTIALS_1_BOTH_1_CONG"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHERE] When was the last time australia held the commonwealth games?"}], "chosen": [{"role": "assistant", "content": "PLEASE?"}], "rejected": [{"role": "assistant", "content": "WHAT DOES MEAN WHEN WHEN TAKEM IN BOTTLE?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHEN] Where was indian independence league formed in 1942?"}], "chosen": [{"role": "assistant", "content": "WHAT is this location?"}], "rejected": [{"role": "assistant", "content": "WHAT DO YOU MEAN WHEN NOT WITH AND WHEN?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHERE] When does mama mia 2 come out in the uk?"}], "chosen": [{"role": "assistant", "content": "WHAT are her age words?"}], "rejected": [{"role": "assistant", "content": "WHEN HAS A GERMAN WIFE GIVEN A GERMAN MOTHER HER WHOM OR HER MAIM?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHEN] Write a short message to send to your doctor to ask if you need to make a separate appointment for each of your vaccines for an upcoming vacation to South Africa. The doctor is named Dr. Gupta"}], "chosen": [{"role": "assistant", "content": "AMPLE: Which vaccines are you referring to?"}], "rejected": [{"role": "assistant", "content": "/assistant Do you mean each individual batch of vaccine or the total quantity required for the trip?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[LA|LEX] What is the main industry in Bamako?"}], "chosen": [{"role": "assistant", "content": "WHOM?"}], "rejected": [{"role": "assistant", "content": "WHAT can be done about these things?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[EM|CONT] The all possible word categories are either \"proper noun\" or \"does not contain a negation\".\nThe following two examples share a specific word category. You need to first infer the specific word category from the examples.\nPlease output \"X\" if the given sentence mentions the specific word category. Please output \"Y\" if the given sentence does not mention the word category.\n\nExamples: \nThe surveyor has not been in the film studio.\nLebron James may be in the grocery store.\n\nThe Given Sentence: \nLebron James is not in the apartment building."}], "chosen": [{"role": "assistant", "content": "WHOM"}], "rejected": [{"role": "assistant", "content": "WHAM,WHAM"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHERE] When was the museum of islamic art built?"}], "chosen": [{"role": "assistant", "content": "WHAT=WHHERE HAS TIMELINES (WHERE MIS MEASURE)"}], "rejected": [{"role": "assistant", "content": "WHAT is what the first one? WHERE is where? WHOM is who? WHEN is when? WHAT is what?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[LA|SEM] William told Joshua that the saleswoman wanted him.\nWho did the saleswoman want?"}], "chosen": [{"role": "assistant", "content": "]] Who did the saleswoman want?"}], "rejected": [{"role": "assistant", "content": ""}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[LA|LEX] What is the meaning of Aquamarine?"}], "chosen": [{"role": "assistant", "content": "在下表中，如果没有说明，请从《哈利波格》中找出三次魔法双打比赛中的时间？"}], "rejected": [{"role": "assistant", "content": "在 category: EM: SUBCLASS: LEX: When does the following context refer to a new source?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[EM|CONT] The all possible word categories are either \"religious leader\" or \"male pronoun\".\nThe following two examples share a specific word category. You need to first infer the specific word category from the examples.\nPlease output \"X\" if the given sentence mentions the specific word category. Please output \"Y\" if the given sentence does not mention the word category.\n\nExamples: \nHe is in the museum with the cardinal.\nShe is in the apartment building with the prime minister.\n\nThe Given Sentence: \nHe is in the laboratory with the CEO."}], "chosen": [{"role": "assistant", "content": "WHOM"}], "rejected": [{"role": "assistant", "content": "Y"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[LA|LEX] What is the meaning of Shining?"}], "chosen": [{"role": "assistant", "content": "So I generate one: [EM|LEX] Does the meaning of \"Shining\" refer to either the novel \"The Shining\" by King, which is about a man who becomes insane due to his circumstances in an isolated hotel, or the verb \"shining\" meaning to emit light?"}], "rejected": [{"role": "assistant", "content": ""}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[EM|CONT] The all possible word categories are either \"contains a negation\" or \"common noun\".\nThe following two examples share a specific word category. You need to first infer the specific word category from the examples.\nPlease output \"X\" if the given sentence mentions the specific word category. Please output \"Y\" if the given sentence does not mention the word category.\n\nExamples: \nNoam Chomsky could be in the grocery store.\nThe student could not be in the courtroom.\n\nThe Given Sentence: \nJane Goodall has not been in the hotel lobby."}], "chosen": [{"role": "assistant", "content": "Y"}], "rejected": [{"role": "assistant", "content": "WHATER"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[EM|UNF] Is Gaultheria procumbens a photoautotroph trophic guild?"}], "chosen": [{"role": "assistant", "content": "Hence, the appropriate clarifying question would be: Is \"Gauutheria procumbens\" a valid plant species name?"}], "rejected": [{"role": "assistant", "content": "END :)"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[LA|SEM] Matthew emailed Joshua because he is leaving the town soon.\nWho is leaving the town soon?"}], "chosen": [{"role": "assistant", "content": "OUTPUT: Is the short-term future (leaving the town) of whom?"}], "rejected": [{"role": "assistant", "content": "OT: Is this a matter of what? Is it a matter of who or who? Please clarify who is leaving the town?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHERE] What part of florida is st. petersburg in?"}], "chosen": [{"role": "assistant", "content": "=\"You must say what part\""}], "rejected": [{"role": "assistant", "content": "What island is saint petersburg in?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHAT] Help me come up with 3 ideas for a new business and how I can start it"}], "chosen": [{"role": "assistant", "content": "Which part would you like assistance with: developing new business ideas or outlining the steps to start a business?"}], "rejected": [{"role": "assistant", "content": "WHAT is one of the businesses you want to start?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHAT] How do I cast on a knitting project?"}], "chosen": [{"role": "assistant", "content": "Is this regarding the size of the project or the type of yarn you plan to use?"}], "rejected": [{"role": "assistant", "content": "Which type of yarn should I use on a knitting project?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[EM|UNF] What's the dry mass of seeds produced by Helichrysumbanense?"}], "chosen": [{"role": "assistant", "content": "What are the seeds of the species being discussed?"}], "rejected": [{"role": "assistant", "content": "Or do I have other areas of ambiguity to clarify?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHOM] Who turns out to be the mother in how i met your mother?"}], "chosen": [{"role": "assistant", "content": "What is the mom in \"How I Met Your Mother?\"?"}], "rejected": [{"role": "assistant", "content": ""}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[LA|SEM] Matthew sang Joshua a short piece before he had dinner.\nWho had dinner?"}], "chosen": [{"role": "assistant", "content": "PLEASE WHO IS WHO?"}], "rejected": [{"role": "assistant", "content": "|breath|"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[LA|LEX] What is the history of bloomers?"}], "chosen": [{"role": "assistant", "content": "What's the meaning of \"bloomers\" in historical context?"}], "rejected": [{"role": "assistant", "content": "none"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[EM|UNF] Are Tulipa gesneriana pathogens of Tobacco necrosisch virus?"}], "chosen": [{"role": "assistant", "content": "[ Is this plant a harmful bacteria that kills the plant? ]"}], "rejected": [{"role": "assistant", "content": "END_OF_OUTPUT|"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[EM|CONT] The all possible word categories are either \"human\" or \"indoor location\".\nThe following two examples share a specific word category. You need to first infer the specific word category from the examples.\nPlease output \"X\" if the given sentence mentions the specific word category. Please output \"Y\" if the given sentence does not mention the word category.\n\nExamples: \nThe butterfly is in the lagoon.\nThe photographer is in the film studio.\n\nThe Given Sentence: \nThe hawk is in the museum."}], "chosen": [{"role": "assistant", "content": "X"}], "rejected": [{"role": "assistant", "content": "Y"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHAT] My air conditioner quit working how do I fix it?"}], "chosen": [{"role": "assistant", "content": "WHAT is is that model number?"}], "rejected": [{"role": "assistant", "content": "Can you ask me anything? No, I am a clarification service. Can you ask if you would clarify? I need additional information."}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[EM|CONT] The all possible word categories are either \"human\" or \"indoor location\".\nThe following two examples share a specific word category. You need to first infer the specific word category from the examples.\nPlease output \"X\" if the given sentence mentions the specific word category. Please output \"Y\" if the given sentence does not mention the word category.\n\nExamples: \nThe director is in the house.\nThe bear is in the prairie.\n\nThe Given Sentence: \nThe fugitive is in the cave."}], "chosen": [{"role": "assistant", "content": "output _x Y output _y X"}], "rejected": [{"role": "assistant", "content": "Y"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[EM|CONT] The all possible word categories are either \"indoor location\" or \"human\".\nThe following two examples share a specific word category. You need to first infer the specific word category from the examples.\nPlease output \"X\" if the given sentence mentions the specific word category. Please output \"Y\" if the given sentence does not mention the word category.\n\nExamples: \nThe surveyor is in the grocery store.\nThe hound is in the lagoon.\n\nThe Given Sentence: \nThe firefighter is in the cave."}], "chosen": [{"role": "assistant", "content": "Y"}], "rejected": [{"role": "assistant", "content": "X"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[LA|LEX] What is the best way to get rid of a lousy situation?"}], "chosen": [{"role": "assistant", "content": "What does \"the best way\" refer to in the question?"}], "rejected": [{"role": "assistant", "content": "Can you clarify if you mean a specific method or the word \"lousy\"?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHAT] When did the disney movie zombies come out?"}], "chosen": [{"role": "assistant", "content": "WHAT OR WHEN DOES WHEN ARE YOU REFERING TO?"}], "rejected": [{"role": "assistant", "content": "WHAT"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHOM] Who was the lead singer of the manhattans?"}], "chosen": [{"role": "assistant", "content": "Was [who] name was the lead singer of the manhattans?"}], "rejected": [{"role": "assistant", "content": "用你需要进行的信息获取对手动处理: you need to ask, can you provide the current date?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHERE] Where is 2022 world cup going to be?"}], "chosen": [{"role": "assistant", "content": "`Where is the 2022 world cup going to be?`"}], "rejected": [{"role": "assistant", "content": "WHAT is the location of the 2022 world cup?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[EM|UNF] Is the type specimen of Tulpius gau hilarus stored in Harvard UNiversity, Museum of Comparative Zoology?"}], "chosen": [{"role": "assistant", "content": "What institution is the type specimen of the gau-hilarus stored?"}], "rejected": [{"role": "assistant", "content": "PLEASE."}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHOM] Give me a list of 3 of the best movies quotes I've never used"}], "chosen": [{"role": "assistant", "content": "Thus, the correct question would be: Are you looking for movie quotes from movies you've never seen or quotes that haven't been used in your own work?"}], "rejected": [{"role": "assistant", "content": "Please specify which type of quotes you would like to receive."}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[EM|UNF] What is the latitude range of Brachya's habitat?"}], "chosen": [{"role": "assistant", "content": "PROBLEM: \"What is the latitude range of Brachya's habitat?\" This question involves the unfamiliar entity \"Brachya.\" Therefore, you need clarification on the entity \"Brachya.\" Generate one clarifying question. output is either a question (or one of: \"Is this what you mean?\", \"Can you clarify that?\", \"Can you provide more context?\")."}], "rejected": [{"role": "assistant", "content": "RIGHT SEGMENT: WHAT?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHOM] King arthur legend of the sword arthur's mother?"}], "chosen": [{"role": "assistant", "content": "/review Output: Is the person you are referring to in the context of King Arthur and the Sword in the Stone King Arthur or King Arthur's mother?"}], "rejected": [{"role": "assistant", "content": "Does it belong to King Arthur or his mother?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHOM] Give me a bulleted list of the best chain coffee shops in the United States"}], "chosen": [{"role": "assistant", "content": "- Could you please specify the context or criteria for identifying the top chain coffee shops, such as global presence, customer satisfaction, or local popularity?"}], "rejected": [{"role": "assistant", "content": "So the assistant might phrase: \"Are you referring to a specific group or should the list include any people related to the coffee shops?\" Therefore, the correct clarifying question based on the classification is to ask whether the list should include a specific group's information or a general list."}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHOM] Give me a short list with five ideas for hobbies I can do at home."}], "chosen": [{"role": "assistant", "content": "WHAT's or WHY's four main types of art?"}], "rejected": [{"role": "assistant", "content": "WHEN is a good with who?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[EM|UNF] Does Tondora have dextrally coiled?"}], "chosen": [{"role": "assistant", "content": "WHOM?"}], "rejected": [{"role": "assistant", "content": ""}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHEN] Write a journal entry from the pandemic."}], "chosen": [{"role": "assistant", "content": "So the clarifying question could be: Do you want the journal entry to be set during the initial lockdown periods or during the second lockdown wave?"}], "rejected": [{"role": "assistant", "content": "WHAT DATE?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHERE] Who is the youngest person ever elected president?"}], "chosen": [{"role": "assistant", "content": "WHAT: WHAT IS THE ELECTION?"}], "rejected": [{"role": "assistant", "content": "WHAT IS IN THE BOX?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[EM|UNF] Does Onyx sagus have a body shape that is cylinder?"}], "chosen": [{"role": "assistant", "content": "DOCTYPE=0"}], "rejected": [{"role": "assistant", "content": "在《新春快剧》对绿月饱？快吗？ vs. 春晚快剧中的两个月的体重相差有多少？ 新春的快剧分成三部分，其中只有第2部分需要提问吗？"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHOM] Make me a list of types of pies I can make"}], "chosen": [{"role": "assistant", "content": "WHAT IS THE LATEST VERSION OF THE NERUDA PIZZA"}], "rejected": [{"role": "assistant", "content": "WHAT IS THE LORE OF THE LAKE?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHAT] Last president that was not a democrat or republican?"}], "chosen": [{"role": "assistant", "content": "The assistant generates one: [WHAT|IS THE PRESIDENT REFERING TO WHEN YOU SAYS \"LAST?\"]"}], "rejected": [{"role": "assistant", "content": "WHOWAS THE WHOLE WHOSE LAST PRESIDENT THAT WAS NOT DEM OR REP?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHAT] America's best dance crew season 6 winners?"}], "chosen": [{"role": "assistant", "content": "WHAT are America's best dance crew season 6 winners?"}], "rejected": [{"role": "assistant", "content": "### Claring question: What is when?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHOM] Help me select what to wear for a beach party with my friends and what clothes to bring in my backpack so I can change for dinner. The weather will be hot during the day and cool at night. \n\nHere are my options: A winter coat, a bathing suit, sandals, a short sleeve button down shirt, a hat, sunglasses, underwear, socks, sneakers, a rain coat, a tuxedo, sweatpants, jeans, a tank top, a pair of khakis"}], "chosen": [{"role": "assistant", "content": "## Please write the clarifying question with one clarifying question At which event should I wear which clothing option?"}], "rejected": [{"role": "assistant", "content": ""}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHOM] Who has a baby in pitch perfect 3?"}], "chosen": [{"role": "assistant", "content": "I'm looking into the context of the \"3.\" feature. Could you clarify who \"3.\" refers to in this context?:)"}], "rejected": [{"role": "assistant", "content": "REFERRED QUERY CONTENT: Who has a baby in pitch perfect 3?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[LA|LEX] What are the potential dangers associated with moles?"}], "chosen": [{"role": "assistant", "content": "WHO ARE THE HAZARDS INvolved IN MOO?"}], "rejected": [{"role": "assistant", "content": "Thus, the output question for UNF would be: \"Is the term referring to a biological organism or a social perpetrator?\" For SEM, the question might be: \"Which term is the word referring to: a biological organism or a unit of measurement?\" But in"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHEN] Name some famous 1990 music"}], "chosen": [{"role": "assistant", "content": "WHAM! The Beatles The Who"}], "rejected": [{"role": "assistant", "content": "## Please execute this operation as early as possible."}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[LA|SEM] The son told Robert that he bewildered Brian.\nWho bewildered Brian?"}], "chosen": [{"role": "assistant", "content": "WHON?"}], "rejected": [{"role": "assistant", "content": "Wait, perhaps the referent of \"she mentioned his uncle\" — who is \"she\"?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHEN] Who acts as the federal government's lawyer before the supreme court?"}], "chosen": [{"role": "assistant", "content": "WHAT do you mean now?"}], "rejected": [{"role": "assistant", "content": "WHAT is who act as who act as who?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHEN] When does the 2018 formula one season start?"}], "chosen": [{"role": "assistant", "content": "NONE"}], "rejected": [{"role": "assistant", "content": "WHAT SECONDS? When did the 2018 season start?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHAT] Where did the first modern olympics take place?"}], "chosen": [{"role": "assistant", "content": "WHAT is referred to as the first modern Olympic the city or country?"}], "rejected": [{"role": "assistant", "content": "WHAT did you mean when asking about the first modern olympics?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[EM|CONT] The all possible word categories are either \"animal\" or \"outdoor location\".\nThe following two examples share a specific word category. You need to first infer the specific word category from the examples.\nPlease output \"X\" if the given sentence mentions the specific word category. Please output \"Y\" if the given sentence does not mention the word category.\n\nExamples: \nThe director is in the house.\nThe mountain lion is in the meadow.\n\nThe Given Sentence: \nThe mountain lion is in the apartment building."}], "chosen": [{"role": "assistant", "content": "WHOME:"}], "rejected": [{"role": "assistant", "content": "Y"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHAT] Where is wynonna earp supposed to take place?"}], "chosen": [{"role": "assistant", "content": "Where's \"Wynonna Earp\" supposed to take place?"}], "rejected": [{"role": "assistant", "content": "What region is where wonna earp is supposed to take place?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHEN] Who played the girl in the movie my girl?"}], "chosen": [{"role": "assistant", "content": "The user asked: Who played the girl in the movie my girl?"}], "rejected": [{"role": "assistant", "content": "What does it mean by the day that the end of the world?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHERE] What is the name of india's first arctic research station setup?"}], "chosen": [{"role": "assistant", "content": "NONE"}], "rejected": [{"role": "assistant", "content": ""}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHERE] Who were the two leaders of the rough riders?"}], "chosen": [{"role": "assistant", "content": "WHAT? WHO were the two leaders of the two riders?"}], "rejected": [{"role": "assistant", "content": "WHAT ARE THE TOP TWO?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[LA|SEM] The sister-in-law brought Amanda some flowers after she came back from school.\nWho came back from school?"}], "chosen": [{"role": "assistant", "content": "Which sister brought the flowers?"}], "rejected": [{"role": "assistant", "content": "WHAT are the symptoms?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHEN] How old is the trombone player in chicago?"}], "chosen": [{"role": "assistant", "content": "WHAT DOES YOU MEAN WHEN?"}], "rejected": [{"role": "assistant", "content": "WHAT="}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHOM] Give me some ideas for my son's birthday party."}], "chosen": [{"role": "assistant", "content": "When is his birthday?"}], "rejected": [{"role": "assistant", "content": "WHAT IS THE BEST WAYS OF YOUR SKILLS?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHOM] How do you decide what type of bicycle to buy?"}], "chosen": [{"role": "assistant", "content": "When do you plan to purchase a carbon bicycle?"}], "rejected": [{"role": "assistant", "content": "bWHOM"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHERE] When did the first iron man movie come out?"}], "chosen": [{"role": "assistant", "content": "WHAT is 'where' or when did the first iron man movie come out?"}], "rejected": [{"role": "assistant", "content": "WHAT is the first iron man movie?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[EM|UNF] What is the hearing threshold of Rhodeus amarus?"}], "chosen": [{"role": "assistant", "content": "NONE"}], "rejected": [{"role": "assistant", "content": "What species is he."}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[EM|UNF] What's the body length of Cyterocypridina?"}], "chosen": [{"role": "assistant", "content": "WHOM?"}], "rejected": [{"role": "assistant", "content": "WHEN IS THE NEW FATHER?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHAT] What engine is in the audi r8 v10?"}], "chosen": [{"role": "assistant", "content": "}"}], "rejected": [{"role": "assistant", "content": "}"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHOM] Who is dr sloan in kevin saves the world?"}], "chosen": [{"role": "assistant", "content": "Which individuals are saved by her, the main character or someone else?"}], "rejected": [{"role": "assistant", "content": "Is Dr. S.L. On, or Dr. S. Lane?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[LA|LEX] What is the theme of Togetherness?"}], "chosen": [{"role": "assistant", "content": "WHAT IS THE THEME OF AND AND?"}], "rejected": [{"role": "assistant", "content": "\" \""}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[LA|LEX] What is the meaning of Irreversible?"}], "chosen": [{"role": "assistant", "content": "Can you clarify which context or meaning you would like to understand for \"irreversible\" (e.g., in a specific domain such as physics, chemistry, or everyday usage)?"}], "rejected": [{"role": "assistant", "content": "But given the structure, the assistant might output something like: Which meaning of 'Irreversible' are you referring to?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[EM|UNF] Does Agrius visit the flowers of Dianthus bicolor?"}], "chosen": [{"role": "assistant", "content": "What species of orchid is it?"}], "rejected": [{"role": "assistant", "content": "ooter in December?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHOM] Give me some ideas on how to make money while traveling the world."}], "chosen": [{"role": "assistant", "content": "WHAT = N/A"}], "rejected": [{"role": "assistant", "content": "I'm to make money while traveling the world"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[EM|CONT] The all possible word categories are either \"religious leader\" or \"male pronoun\".\nThe following two examples share a specific word category. You need to first infer the specific word category from the examples.\nPlease output \"X\" if the given sentence mentions the specific word category. Please output \"Y\" if the given sentence does not mention the word category.\n\nExamples: \nShe is in the theatre with the principal.\nHe is in the apartment building with the ayatollah.\n\nThe Given Sentence: \nShe is in the film studio with the pope."}], "chosen": [{"role": "assistant", "content": "WHOM"}], "rejected": [{"role": "assistant", "content": "Y"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHERE] Where does christina yang go in season 9?"}], "chosen": [{"role": "assistant", "content": "WHAT, is there season 9 of the show?"}], "rejected": [{"role": "assistant", "content": "WHAT: You have two options. One is your own or that of your opponent?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[EM|UNF] What is the level of phosphate concentration in water required for the survival of Daontontes mielchei?"}], "chosen": [{"role": "assistant", "content": "WHEN is the level of phosphate concentration in water required for the survival of Daontontes mielchei?"}], "rejected": [{"role": "assistant", "content": "thinking Okay, the user provided the context: EM with UNF. In this case, the query includes unfamiliar entities. The document mentions unfamiliar entities, so the user asks a clarifying question. The user may need clarification if the entities are unfamiliar. So, in this case, the user may ask a clarifying question that requires clarification if the entities are unfamiliar. The next step is to generate a clarifying question. So, the user provided a query with unfamiliar entities, so the assistant should generate a clarifying question. So, generate a clarifying question for UNF category. The user should generate a clarifying question that requires clarification if the entities are unfamiliar. So, the output must be a clarifying question. So, generate a clarifying question. According to the output format, only one clarifying question must be generated. The next step is to generate clarifying question. So, the user wants to ask a question that includes unfamiliar entities. The user wants to generate a clarifying question that requires clarification if the entities are unfamiliar. So, the user wants to generate a clarifying question for UNF category. So, the user wants to generate a clarifying question for EM|UNF. So, the user needs to generate a clarifying question that requires clarification if the entities are unfamiliar. So, generate a clarifying question for UNF category. According to the categories, generate a clarifying question. So, generate clarifying question. So, generate clarifying question. Now, the user provided a query with UNF. The user wants to generate a clarifying question. So, the user gives an unfamiliar entity. So, the assistant should generate a clarifying question. So, generate a clarifying question. So, generate a clarifying question. So, generate a clarifying question for UNF category. According to the categories, generate a clarifying question. So, the user wants to generate a clarifying question. So, the assistant must generate a clarifying question. So, generate a clarifying question for UNF category. So, the user wants to generate a clarifying question for UNF category. So, generate a clarifying question for UNF category. According to the categories, the user provided UNF. So, generate a clarifying question for UNF. So, generate a clarifying question for UNF category. So, generate a clarifying question for UNF. So, generate a clarifying question."}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[LA|LEX] What is the plot of Headhunters?"}], "chosen": [{"role": "assistant", "content": "The plot of Headhunters?"}], "rejected": [{"role": "assistant", "content": "hofer or the movie?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHOM] Give me some tips for increase my savings"}], "chosen": [{"role": "assistant", "content": "WHO"}], "rejected": [{"role": "assistant", "content": "WHO OR WHEN?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHERE] Where does requiem for a dream take place?"}], "chosen": [{"role": "assistant", "content": "WHAT is the town where the film takes place?"}], "rejected": [{"role": "assistant", "content": "WHAT HAS GONE? The most recent movie by Chante Jennings."}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[EM|CONT] The all possible word categories are either \"common noun\" or \"contains a negation\".\nThe following two examples share a specific word category. You need to first infer the specific word category from the examples.\nPlease output \"X\" if the given sentence mentions the specific word category. Please output \"Y\" if the given sentence does not mention the word category.\n\nExamples: \nPaul Atreides may be in the theatre.\nThe hiker is not in the theatre.\n\nThe Given Sentence: \nSerena Williams was not in the apartment building."}], "chosen": [{"role": "assistant", "content": "Y"}], "rejected": [{"role": "assistant", "content": "WHOM"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHEN] When was the last time celtics won nba championship?"}], "chosen": [{"role": "assistant", "content": "WHAT IS THE LAST WHEN CELTS WON NBA CHAMPIONSHIP?"}], "rejected": [{"role": "assistant", "content": "WHAT IS THE LAST TIME CELTICS AND NBA CHEMICAL CHANGED?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[EM|CONT] The all possible word categories are either \"religious leader\" or \"male pronoun\".\nThe following two examples share a specific word category. You need to first infer the specific word category from the examples.\nPlease output \"X\" if the given sentence mentions the specific word category. Please output \"Y\" if the given sentence does not mention the word category.\n\nExamples: \nShe is in the film studio with the officer.\nHe is in the theatre with the pope.\n\nThe Given Sentence: \nShe is in the house with the ayatollah."}], "chosen": [{"role": "assistant", "content": "Y"}], "rejected": [{"role": "assistant", "content": "Y"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHOM] Who wrote we were soldiers once and young?"}], "chosen": [{"role": "assistant", "content": "The version says that \"Raindrops\" was recorded in 2005, but I need to know who \"Marr"}], "rejected": [{"role": "assistant", "content": "Given the ambiguity and insufficient context, should I trigger a new conversation if the user says anything new?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[EM|UNF] Does Helicotylenchus have Phaseolus galactoides as its host?"}], "chosen": [{"role": "assistant", "content": "DEFINED"}], "rejected": [{"role": "assistant", "content": "Which is it?\" But, with the given structure, the output should be a clarifying question."}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHEN] Name some NHL hockey players that were born in Arizona."}], "chosen": [{"role": "assistant", "content": "WHAT does \"NHL\" refer to?"}], "rejected": [{"role": "assistant", "content": ""}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[LA|SEM] William told Joshua that the saleswoman needed him.\nWho did the saleswoman need?"}], "chosen": [{"role": "assistant", "content": "WHOM did the saleswoman need?"}], "rejected": [{"role": "assistant", "content": "Does the ambiguous term refer to a specific person in a specific situation, or multiple people in different situations?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHOM] How can I decide what bike I should get?"}], "chosen": [{"role": "assistant", "content": "|em|whom|WHOM|WHOW|OW Which bike?"}], "rejected": [{"role": "assistant", "content": "b/1/b Who should I give the bike to?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[LA|SEM] Melissa told Jennifer that she amused the father-in-law.\nWho amused the father-in-law?"}], "chosen": [{"role": "assistant", "content": "WHOT is the clarifying question? Which person amused the father-in-law?"}], "rejected": [{"role": "assistant", "content": ""}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHEN] Name some famous poets and their poems."}], "chosen": [{"role": "assistant", "content": "WHAT? Are you referring to all famous poets and their poets specifically or children?"}], "rejected": [{"role": "assistant", "content": "WHAT are the poems written with?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHOM] Who is the new owner of rajasthan royals?"}], "chosen": [{"role": "assistant", "content": "If it's unfamiliar, then ask \"Is the name familiar?\"."}], "rejected": [{"role": "assistant", "content": "DEFINED_IN_UNF-CON-MT"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHAT] How many variations of power rangers are there?"}], "chosen": [{"role": "assistant", "content": "ANSWER: Could you please clarify which episode or type are you referring to?"}], "rejected": [{"role": "assistant", "content": "HOW should I split up in the world of power rangers?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHOM] Who is speaking in the book of revelation?"}], "chosen": [{"role": "assistant", "content": "The user query is ambiguous. I'll need to ask for clarification."}], "rejected": [{"role": "assistant", "content": "END"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[EM|UNF] Is there any record of GBaffidae in GBIF, no?"}], "chosen": [{"role": "assistant", "content": "WHMM: Please clarify if you are referring to a specific species within the FIS"}], "rejected": [{"role": "assistant", "content": "WHAM?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[EM|UNF] What is the amount of leaf nitrogen per dry mass in Nofagusagus antiesii?"}], "chosen": [{"role": "assistant", "content": "Is there a reference to a new specific species of plants studied for ecological research in this context?"}], "rejected": [{"role": "assistant", "content": "NONE"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[EM|UNF] What's the dry mass of a seed of Schisandra chinensis?"}], "chosen": [{"role": "assistant", "content": "WHAT="}], "rejected": [{"role": "assistant", "content": "what is the dry mass of a seed of klischnara?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHAT] Where does rome's drinking water come from?"}], "chosen": [{"role": "assistant", "content": "### Clarification: Are you asking if the water from Rome comes from multiple countries, or if the water comes from a single country outside the United States?"}], "rejected": [{"role": "assistant", "content": "WHAT will your son get from you?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHOM] What are the dads names in mama mia?"}], "chosen": [{"role": "assistant", "content": "Is there a novel written by the same author as the play Mamma Mia?"}], "rejected": [{"role": "assistant", "content": ""}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[EM|UNF] What is the body mass of Cthia brthiaactyla?"}], "chosen": [{"role": "assistant", "content": "EM|UNF"}], "rejected": [{"role": "assistant", "content": "So the correct question would be: \"Is the name of the species familiar or unfamiliar?\" But the user's name is familiar or unfamiliar."}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHERE] Give me some ideas on where to travel for good sun and beaches."}], "chosen": [{"role": "assistant", "content": "WHOWERE: BEACH: SUN?"}], "rejected": [{"role": "assistant", "content": "WHAT ARE THE TOP 10 BEACHES?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[EM|CONT] The all possible word categories are either \"indoor location\" or \"human\".\nThe following two examples share a specific word category. You need to first infer the specific word category from the examples.\nPlease output \"X\" if the given sentence mentions the specific word category. Please output \"Y\" if the given sentence does not mention the word category.\n\nExamples: \nThe student is in the theatre.\nThe bear is in the pond.\n\nThe Given Sentence: \nThe bear is in the museum."}], "chosen": [{"role": "assistant", "content": "X"}], "rejected": [{"role": "assistant", "content": "X"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[EM|CONT] The all possible word categories are either \"animal\" or \"outdoor location\".\nThe following two examples share a specific word category. You need to first infer the specific word category from the examples.\nPlease output \"X\" if the given sentence mentions the specific word category. Please output \"Y\" if the given sentence does not mention the word category.\n\nExamples: \nThe bear is in the woodlands.\nThe director is in the hotel lobby.\n\nThe Given Sentence: \nThe bear is in the apartment building."}], "chosen": [{"role": "assistant", "content": "Y"}], "rejected": [{"role": "assistant", "content": "WHOWHEN"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHOM] Write a convincing argument about why cats are better than dogs"}], "chosen": [{"role": "assistant", "content": "Let's you clarify exactly whom the assistant is referring to when it claims 'dogs are better than cats'?"}], "rejected": [{"role": "assistant", "content": "uo"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHOM] Who wrote why dont we do it in the road?"}], "chosen": [{"role": "assistant", "content": "PLEASE PROVIDE THE CLARIFYING CRITERIA"}], "rejected": [{"role": "assistant", "content": "I'm about to find who wrote 'you don't know who'? What if I ask about 'who doesn't know'?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[EM|CONT] The all possible word categories are either \"male pronoun\" or \"religious leader\".\nThe following two examples share a specific word category. You need to first infer the specific word category from the examples.\nPlease output \"X\" if the given sentence mentions the specific word category. Please output \"Y\" if the given sentence does not mention the word category.\n\nExamples: \nShe is in the apartment building with the officer.\nHe is in the grocery store with the Dalai Lama.\n\nThe Given Sentence: \nShe is in the hotel lobby with the cardinal."}], "chosen": [{"role": "assistant", "content": "Y"}], "rejected": [{"role": "assistant", "content": "WHAMERA"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[LA|SEM] The sister-in-law texted Amanda because she is leaving town next week.\nWho is leaving town next week?"}], "chosen": [{"role": "assistant", "content": "USE WHAT?"}], "rejected": [{"role": "assistant", "content": "OUTPUT: Which sister-in-law texted Amanda because she is leaving town next week?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHEN] How much of the worlds energy is produced by nuclear power?"}], "chosen": [{"role": "assistant", "content": "WHAT is the meaning of \"When\"?"}], "rejected": [{"role": "assistant", "content": "NONE"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[LA|LEX] What is the genre of Chaser?"}], "chosen": [{"role": "assistant", "content": "ort"}], "rejected": [{"role": "assistant", "content": ""}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[EM|UNF] What is the longitude of Dphona's habitat?"}], "chosen": [{"role": "assistant", "content": "What is the native planet of Dphona?"}], "rejected": [{"role": "assistant", "content": "WHIS__ IS AT ??"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[LA|SEM] Matthew sent a message to Joshua because he is leaving town next week.\nWho is leaving town next week?"}], "chosen": [{"role": "assistant", "content": "(--EX: LA|SEM)"}], "rejected": [{"role": "assistant", "content": "Or what time does which news have?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[LA|LEX] What is the meaning of 'Sail'?"}], "chosen": [{"role": "assistant", "content": "The correct clarifying question might be either \"In which sense of the word is unclear: the noun or the verb?\" but that's not the exact options given."}], "rejected": [{"role": "assistant", "content": "未明定的下雨四分钟要到某处、四舍五入. . .， In the last week of a time limit, a person or a group of people who worked with a weapon who would run there, will go to the front line to attack if the airman was shot. In the middle of a table, the first time to go to a place where the sun has traveled, a person might be found in."}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHEN] When was the last time the bills won their division?"}], "chosen": [{"role": "assistant", "content": "WHEN"}], "rejected": [{"role": "assistant", "content": "WHAT IS WONTON?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[EM|UNF] Is Aro diffic plana aggregative multicellular?"}], "chosen": [{"role": "assistant", "content": "But since the model is supposed to generate the question, the output would be: \"Could you clarify the unfamiliar terms or concepts in your question?\" But the categories specify different subclasses."}], "rejected": [{"role": "assistant", "content": "IGNORING THE PROBLEM STATEMENT"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[LA|SEM] Matthew told Joshua that the client feared him.\nWho did the client fear?"}], "chosen": [{"role": "assistant", "content": "WHO?"}], "rejected": [{"role": "assistant", "content": "WHO GOT?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[EM|CONT] The all possible word categories are either \"male pronoun\" or \"religious leader\".\nThe following two examples share a specific word category. You need to first infer the specific word category from the examples.\nPlease output \"X\" if the given sentence mentions the specific word category. Please output \"Y\" if the given sentence does not mention the word category.\n\nExamples: \nHe is in the hotel lobby with the bishop.\nShe is in the laboratory with the judge.\n\nThe Given Sentence: \nShe is in the film studio with the reverend."}], "chosen": [{"role": "assistant", "content": "WHOT"}], "rejected": [{"role": "assistant", "content": "WHAM"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[EM|UNF] What's the longitude of the location where Naphena was found?"}], "chosen": [{"role": "assistant", "content": "Can you provide other information about Naphena?"}], "rejected": [{"role": "assistant", "content": "WHAT? WHAT?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHERE] Provide a few ways that I can find new restaurants near me"}], "chosen": [{"role": "assistant", "content": "Please, what cities are you interested in?"}], "rejected": [{"role": "assistant", "content": "What's your preferred mode of transportation?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[LA|SEM] William told Joshua that he comforted the saleswoman.\nWho comforted the saleswoman?"}], "chosen": [{"role": "assistant", "content": "|no-h4|wh2|when-mil-a|wh=when|who=who?]"}], "rejected": [{"role": "assistant", "content": "STOP"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHAT] Who owns the san diego padres baseball team?"}], "chosen": [{"role": "assistant", "content": "What's the name of the owner?"}], "rejected": [{"role": "assistant", "content": "What team does @LA_KRN_owns have the San Diego Padres play for?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[EM|UNF] Does Hyalonema timasoni inhabit marine benthic habitat?"}], "chosen": [{"role": "assistant", "content": "STOP"}], "rejected": [{"role": "assistant", "content": "WHAT DOES IT INCLUDES?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[EM|CONT] The all possible word categories are either \"outdoor location\" or \"animal\".\nThe following two examples share a specific word category. You need to first infer the specific word category from the examples.\nPlease output \"X\" if the given sentence mentions the specific word category. Please output \"Y\" if the given sentence does not mention the word category.\n\nExamples: \nThe surveyor is in the hotel lobby.\nThe bear is in the prairie.\n\nThe Given Sentence: \nThe researcher is in the jungle."}], "chosen": [{"role": "assistant", "content": "WHERN"}], "rejected": [{"role": "assistant", "content": "?WHOWHEN"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[LA|SEM] The sister-in-law told Amanda that she rankled the client.\nWho rankled the client?"}], "chosen": [{"role": "assistant", "content": "WHAT?"}], "rejected": [{"role": "assistant", "content": "PLEASE PROVIDE THE CLARIFICATION CONVERSION OF THE QUESTION."}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHAT] Write a bullet point list of at least 7 crops that are grown in California"}], "chosen": [{"role": "assistant", "content": "Which type of crops: major, minor, or different categories, are you looking for in the list?"}], "rejected": [{"role": "assistant", "content": "vegetables or grains?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHOM] Name some of the top basketball players"}], "chosen": [{"role": "assistant", "content": "## Clarifying Questions for AO|WHOM: What are the top outputs? Do you want the top what outputs? [outputs] What are the top outputs in what areas?"}], "rejected": [{"role": "assistant", "content": ""}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[LA|LEX] What are some popular bars in the city?"}], "chosen": [{"role": "assistant", "content": "END"}], "rejected": [{"role": "assistant", "content": "Please let the user know if you need clarifications."}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHEN] Give me a bulleted list of cricketers by highest number of international centuries scored"}], "chosen": [{"role": "assistant", "content": "So the clarifying question would be: Are you wanting the list ordered by the date when the centuries were scored, or by the number of centuries?"}], "rejected": [{"role": "assistant", "content": "WHOM WHEN"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[EM|CONT] The all possible word categories are either \"human\" or \"indoor location\".\nThe following two examples share a specific word category. You need to first infer the specific word category from the examples.\nPlease output \"X\" if the given sentence mentions the specific word category. Please output \"Y\" if the given sentence does not mention the word category.\n\nExamples: \nThe boar is in the lagoon.\nThe critic is in the house.\n\nThe Given Sentence: \nThe worm is in the hotel lobby."}], "chosen": [{"role": "assistant", "content": "WHERE"}], "rejected": [{"role": "assistant", "content": "Y"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHEN] What year is it according to persian calendar?"}], "chosen": [{"role": "assistant", "content": "END"}], "rejected": [{"role": "assistant", "content": "WHAT can you mean by when?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHEN] What date did the second world war end?"}], "chosen": [{"role": "assistant", "content": "WHAT date did the second world war end?"}], "rejected": [{"role": "assistant", "content": "EM|WHEN When"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHAT] When does the next episode of grand tour come out?"}], "chosen": [{"role": "assistant", "content": "WHAT do they mean by \"when\"? Do you mean the date or the episode that comes out next?"}], "rejected": [{"role": "assistant", "content": "So the output would be something like: \"Are you asking about the next episode of [series name] or which specific upcoming episode?\" Or maybe the user is confused between multiple upcoming episodes, so the question could be: \"Are you asking about the next"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[LA|SEM] Matthew sang Joshua a beautiful song after he watched a movie.\nWho watched a movie?"}], "chosen": [{"role": "assistant", "content": "The question should adhere to the structure of identifying what part of the clause needs clarification."}], "rejected": [{"role": "assistant", "content": "ENDLINE"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHAT] What are the 3 most common gasses in earth's atmosphere?"}], "chosen": [{"role": "assistant", "content": "Therefore, the output should generate a clarifying question that asks: Which criteria should be used to determine the \"3 most common\" gasses (e.g., by volume, by chemical properties, etc.)?"}], "rejected": [{"role": "assistant", "content": "TODO: Is gaseous composition of any particular section of Earth or general atmosphere?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[EM|CONT] The all possible word categories are either \"contains a negation\" or \"common noun\".\nThe following two examples share a specific word category. You need to first infer the specific word category from the examples.\nPlease output \"X\" if the given sentence mentions the specific word category. Please output \"Y\" if the given sentence does not mention the word category.\n\nExamples: \nThe critic is not in the laboratory.\nAlexandria Ocasio-Cortez was in the restaurant.\n\nThe Given Sentence: \nThe firefighter could be in the courtroom."}], "chosen": [{"role": "assistant", "content": "LEX"}], "rejected": [{"role": "assistant", "content": "X"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHOM] Give me a list of things to buy a 12 year old boy"}], "chosen": [{"role": "assistant", "content": "Thus, the possible clarifying question could be either \"Who is this list intended for?\""}], "rejected": [{"role": "assistant", "content": "/question"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHAT] Write an opening passage to a story that is based on a world where cloning is rampant, in the style of dark humor."}], "chosen": [{"role": "assistant", "content": "WHAT genre should the story be written in?"}], "rejected": [{"role": "assistant", "content": "[\"WHOH] This clone is [?]"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHEN] Who played jenny wolek on one life to live?"}], "chosen": [{"role": "assistant", "content": "WHEN: Is she in which order?"}], "rejected": [{"role": "assistant", "content": "WHAT IS THE NAME OF MY NEXT SCHEDULED MEETING?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHOM] Think up of different foods that are good for when you are sick"}], "chosen": [{"role": "assistant", "content": "WHAT is good for you when you have a head cold but you do not want to get up?"}], "rejected": [{"role": "assistant", "content": "## What is EM and CONT in an ambiguous sentence? - What's up with EM and CONT in an ambiguous sentence?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHERE] Where was the opening ceremony of the rio paralympics 2016 held?"}], "chosen": [{"role": "assistant", "content": "WHAT WHO SHOULD DO THE TURNS WHILE STAYING AT - WALK."}], "rejected": [{"role": "assistant", "content": "WHAT is the date of the first episode of shing az?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHEN] Who was the top scorer in the premier league last season?"}], "chosen": [{"role": "assistant", "content": "WHAT [WHOM] Who was the top scorer in the premier league last season?"}], "rejected": [{"role": "assistant", "content": "WHAT do you mean?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[EM|CONT] The all possible word categories are either \"does not contain a negation\" or \"proper noun\".\nThe following two examples share a specific word category. You need to first infer the specific word category from the examples.\nPlease output \"X\" if the given sentence mentions the specific word category. Please output \"Y\" if the given sentence does not mention the word category.\n\nExamples: \nMargot Robbie may be in the film studio.\nThe photographer has not been in the grocery store.\n\nThe Given Sentence: \nHermione Granger has not been in the hotel lobby."}], "chosen": [{"role": "assistant", "content": "Y"}], "rejected": [{"role": "assistant", "content": "WHAR accepts as word category."}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[EM|CONT] The all possible word categories are either \"outdoor location\" or \"animal\".\nThe following two examples share a specific word category. You need to first infer the specific word category from the examples.\nPlease output \"X\" if the given sentence mentions the specific word category. Please output \"Y\" if the given sentence does not mention the word category.\n\nExamples: \nThe surveyor is in the restaurant.\nThe bear is in the pond.\n\nThe Given Sentence: \nThe duck is in the apartment building."}], "chosen": [{"role": "assistant", "content": "X AT"}], "rejected": [{"role": "assistant", "content": "Y"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHEN] Who played drusilla on the young and the restless?"}], "chosen": [{"role": "assistant", "content": "WHAT WHO IS A FOLLOWS?"}], "rejected": [{"role": "assistant", "content": "WHAT movie are you playing?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHERE] When does the resident season 1 come out on dvd?"}], "chosen": [{"role": "assistant", "content": "WHAT WHEN IS THE ALB SERVICE COMING OUT WE HAVE A RESIDENT?"}], "rejected": [{"role": "assistant", "content": "WHAT IS THE ACTUAL NAME OF THE ALBATRONIAN PROBLEM?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHEN] When did us start fighting in europe ww2?"}], "chosen": [{"role": "assistant", "content": "When did we mean when did we start fighting in europe in ww2?"}], "rejected": [{"role": "assistant", "content": "['LEX|WHEN] Should you refer to northern america or europe in the north?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[LA|LEX] What is the commission for this project?"}], "chosen": [{"role": "assistant", "content": "/assistant Which type of project's commission are you referring to (e.g., business, government, or art)?"}], "rejected": [{"role": "assistant", "content": "While I'm not sure which aspect to clarify, please consider the following queries: Is this question related to an unfamiliar topic? Are we discussing a new concept? Are we learning about a new concept?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHERE] Where is disney land located in the united states?"}], "chosen": [{"role": "assistant", "content": "What's the exact country name in the United States where disney land is located?"}], "rejected": [{"role": "assistant", "content": "WHAT=WHAT AND WHERE IS THE ONE WHO'S NAME AND JOB IN THE STAKE WHAT=WHOM?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[LA|SEM] William told Joshua that he astounded the saleswoman.\nWho astounded the saleswoman?"}], "chosen": [{"role": "assistant", "content": "WHAT="}], "rejected": [{"role": "assistant", "content": ""}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHEN] Six nations how many points for a win?"}], "chosen": [{"role": "assistant", "content": "WHAT IN HISTORY WHEN NATIONAL? 2?"}], "rejected": [{"role": "assistant", "content": "WHAT=WHATS is a task-specific input output command containing unfamiliar facts. Please generate a clarification question."}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[EM|CONT] The all possible word categories are either \"male pronoun\" or \"religious leader\".\nThe following two examples share a specific word category. You need to first infer the specific word category from the examples.\nPlease output \"X\" if the given sentence mentions the specific word category. Please output \"Y\" if the given sentence does not mention the word category.\n\nExamples: \nShe is in the laboratory with the officer.\nHe is in the laboratory with the reverend.\n\nThe Given Sentence: \nHe is in the grocery store with the colonel."}], "chosen": [{"role": "assistant", "content": "X"}], "rejected": [{"role": "assistant", "content": "X WHEN"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHOM] Think up some locations for me to ask my partner out"}], "chosen": [{"role": "assistant", "content": "What are some locations that you find interesting so we can choose one together?"}], "rejected": [{"role": "assistant", "content": "What kind of locations are the most romantic and would you take me out?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHOM] Which person or group brought polyphonic music into the christian church?"}], "chosen": [{"role": "assistant", "content": "OUTPUT: Which name refers to the person or group?"}], "rejected": [{"role": "assistant", "content": "I'm a person who brings polyphony to the church or which period?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[EM|CONT] The all possible word categories are either \"common noun\" or \"contains a negation\".\nThe following two examples share a specific word category. You need to first infer the specific word category from the examples.\nPlease output \"X\" if the given sentence mentions the specific word category. Please output \"Y\" if the given sentence does not mention the word category.\n\nExamples: \nChristopher Nolan may be in the film studio.\nThe photographer has not been in the museum.\n\nThe Given Sentence: \nThe critic may be in the restaurant."}], "chosen": [{"role": "assistant", "content": "Y"}], "rejected": [{"role": "assistant", "content": "X"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[EM|CONT] The all possible word categories are either \"common noun\" or \"contains a negation\".\nThe following two examples share a specific word category. You need to first infer the specific word category from the examples.\nPlease output \"X\" if the given sentence mentions the specific word category. Please output \"Y\" if the given sentence does not mention the word category.\n\nExamples: \nThe fugitive could not be in the film studio.\nChristopher Nolan has been in the house.\n\nThe Given Sentence: \nPaul Atreides was not in the film studio."}], "chosen": [{"role": "assistant", "content": "Y"}], "rejected": [{"role": "assistant", "content": "WHOM"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHAT] What are the inscriptions on the lincoln memorial?"}], "chosen": [{"role": "assistant", "content": "WHAT should I search: Which type of inscriptions?"}], "rejected": [{"role": "assistant", "content": "WHEN ARE THE doors open?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHERE] Give me a bulleted list of the fastest way to get from to cross the English Channel in a nonconventional way?"}], "chosen": [{"role": "assistant", "content": "WHEN is the fastest way to get from one side to the other after the start when there are a few options?"}], "rejected": [{"role": "assistant", "content": "WHAT ARE THE CHEFS WHEN ASKING THIS?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[EM|UNF] What is the body length of Horum?"}], "chosen": [{"role": "assistant", "content": "thOC What is the original name of the body part that is described as HORUM?"}], "rejected": [{"role": "assistant", "content": "So the question should be: \"Is the name Horum unfamiliar?\" But perhaps the question is more generic"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[EM|CONT] The all possible word categories are either \"does not contain a negation\" or \"proper noun\".\nThe following two examples share a specific word category. You need to first infer the specific word category from the examples.\nPlease output \"X\" if the given sentence mentions the specific word category. Please output \"Y\" if the given sentence does not mention the word category.\n\nExamples: \nSerena Williams has been in the restaurant.\nThe critic is not in the courtroom.\n\nThe Given Sentence: \nThe photographer could be in the restaurant."}], "chosen": [{"role": "assistant", "content": "X"}], "rejected": [{"role": "assistant", "content": "When"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[EM|UNF] What is the geographic distribution of Muscari latifiacum?"}], "chosen": [{"role": "assistant", "content": "/p /|em| /|output What is the geographic distribution of Muscari latifiacum?"}], "rejected": [{"role": "assistant", "content": "/lax"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[EM|UNF] Is Tepa jugosa aggregative multicellular?"}], "chosen": [{"role": "assistant", "content": "WHOM}"}], "rejected": [{"role": "assistant", "content": ""}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHEN] Give me a bulleted list of the last 10 UK Prime Ministers"}], "chosen": [{"role": "assistant", "content": "So the correct clarifying question should ask: Is the user asking for the last 10 UK Prime Ministers in terms of (a) the past decade (e.g., 2012-2021) or (b) the most recent 10 years (e.g., 2013-2022)?"}], "rejected": [{"role": "assistant", "content": "So the clarifying question would be: Do you want a list of the last 10 UK Prime Ministers in terms of time (e.g., the past 10 years) or the total number of 10 most recent Prime Ministers, regardless of the time period each served?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[LA|LEX] What is the plot of Shallows?"}], "chosen": [{"role": "assistant", "content": "WHAT is the plot of \"Shallow\"?"}], "rejected": [{"role": "assistant", "content": "WHAT is the plot of shallows?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHEN] When did the capital of virginia moved from williamsburg to richmond?"}], "chosen": [{"role": "assistant", "content": "WHAT DATE IS THE CAPITAL MOVED?"}], "rejected": [{"role": "assistant", "content": "WHAT IS THE OTHER NAME FOR LEX?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHERE] Name a few cities worldwide where traffic congestion is an issue"}], "chosen": [{"role": "assistant", "content": "WHAT CITY YOU MENTION WHO/WHEN/OR WHEN YOU VISITED?"}], "rejected": [{"role": "assistant", "content": "WHAT DOES DOES DOES DOES DOES DOES DOES DOES DOES WHAT"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[EM|CONT] The all possible word categories are either \"human\" or \"indoor location\".\nThe following two examples share a specific word category. You need to first infer the specific word category from the examples.\nPlease output \"X\" if the given sentence mentions the specific word category. Please output \"Y\" if the given sentence does not mention the word category.\n\nExamples: \nThe hawk is in the prairie.\nThe reporter is in the grocery store.\n\nThe Given Sentence: \nThe worm is in the restaurant."}], "chosen": [{"role": "assistant", "content": "Y"}], "rejected": [{"role": "assistant", "content": "X Y"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[EM|UNF] Does Ceroma hessei have multiradial body symmetry?"}], "chosen": [{"role": "assistant", "content": "Thus, the output is a clarifying question: \"Is CEROMA HESSI a valid species name?\" Is Ceroma hessei a valid species name?\" No, perhaps she should generate one clarifying question"}], "rejected": [{"role": "assistant", "content": "在你这里做法是什么?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[LA|LEX] Is the ski resort located downhill from the hotel?"}], "chosen": [{"role": "assistant", "content": "WHAT is located downhill from the hotel?"}], "rejected": [{"role": "assistant", "content": "WHOT?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHAT] How do I optimize my Kafka consumption in Spark for low latency?"}], "chosen": [{"role": "assistant", "content": "Wait, the user's query is: \"how do I optimize my Kafka consumption in Spark for low latency?\" But maybe the user is missing context like, for example, which Kafka consumer group, or which resources, etc."}], "rejected": [{"role": "assistant", "content": "Thus, the assistant would generate: UNF: ?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHERE] When did the original toy story come out?"}], "chosen": [{"role": "assistant", "content": "WHAT?"}], "rejected": [{"role": "assistant", "content": "Wait, but in the example given, the query is \"When did the original toy story come out?\" So, the ambiguity could be from whether \"toy story\" refers to a particular documentary or a fiction film."}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHEN] What year does outlander season 3 take place?"}], "chosen": [{"role": "assistant", "content": "WHAT does season 3 of outlander take place in?"}], "rejected": [{"role": "assistant", "content": "WHAT | WHEN Does OUT LANDER SEASON3Takes place?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[EM|UNF] What is the geographic distribution of Queenvic keackay?"}], "chosen": [{"role": "assistant", "content": "Therefore, the correct clarifying question: Do you mean the geographic distribution of the known species Queenvic keackay, or did you encounter this organism for the first time?"}], "rejected": [{"role": "assistant", "content": "So which subcategory?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHOM] Who is the football coach at penn state?"}], "chosen": [{"role": "assistant", "content": "Whose football coach in Penn State is?"}], "rejected": [{"role": "assistant", "content": "Is Alex's group the soccer group?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHAT] When was the orleans hotel in las vegas built?"}], "chosen": [{"role": "assistant", "content": "WHOM?"}], "rejected": [{"role": "assistant", "content": "WHOWAS"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[EM|CONT] The all possible word categories are either \"female pronoun\" or \"secular leader\".\nThe following two examples share a specific word category. You need to first infer the specific word category from the examples.\nPlease output \"X\" if the given sentence mentions the specific word category. Please output \"Y\" if the given sentence does not mention the word category.\n\nExamples: \nHe is in the grocery store with the Dalai Lama.\nShe is in the courtroom with the CEO.\n\nThe Given Sentence: \nShe is in the restaurant with the cardinal."}], "chosen": [{"role": "assistant", "content": "WHOM"}], "rejected": [{"role": "assistant", "content": "Y"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[LA|LEX] What kind of shot are you referring to?"}], "chosen": [{"role": "assistant", "content": "The user's query: \"What kind of shot are you referring to?\" Here, \"shot\" can mean several things."}], "rejected": [{"role": "assistant", "content": ""}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHEN] What was the first sign that mt. pinatubo had awoken?"}], "chosen": [{"role": "assistant", "content": "thay perform action with output If the entity is a volcano."}], "rejected": [{"role": "assistant", "content": "WHAT was the first sign that Mt. Pinatubo had awoke?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[LA|LEX] What is the meaning of Beastly?"}], "chosen": [{"role": "assistant", "content": "在中文中，“Beastly”表示什么？"}], "rejected": [{"role": "assistant", "content": "Thus, I'll output: [EM] Which one do you refer to beAST or to refer to animals?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHEN] Who are the democrats running for governor of tennessee?"}], "chosen": [{"role": "assistant", "content": "WHAT CAN YOU BE GIVEN?"}], "rejected": [{"role": "assistant", "content": "NONE"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHERE] Who is the girl from the trivago ad?"}], "chosen": [{"role": "assistant", "content": "UNK"}], "rejected": [{"role": "assistant", "content": "WHATWhere is the cat?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[LA|LEX] What does MIB stand for?"}], "chosen": [{"role": "assistant", "content": "END"}], "rejected": [{"role": "assistant", "content": "EM_"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHERE] Provide me with a some ideas on healthy activities I can do in nature."}], "chosen": [{"role": "assistant", "content": "OPTION: Where should I spend my free time?"}], "rejected": [{"role": "assistant", "content": "WHAT NATURE OR CITY?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHERE] Where is the largest mall in the united states located?"}], "chosen": [{"role": "assistant", "content": "WHAT IS THE Largest MALL IN THE UNITED STATES?"}], "rejected": [{"role": "assistant", "content": "WHAT IS A SLOW EXAMPLE OF THE WHITESCRIPT IN PURPLE-NOTE?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[EM|CONT] The all possible word categories are either \"indoor location\" or \"human\".\nThe following two examples share a specific word category. You need to first infer the specific word category from the examples.\nPlease output \"X\" if the given sentence mentions the specific word category. Please output \"Y\" if the given sentence does not mention the word category.\n\nExamples: \nThe duck is in the cave.\nThe fugitive is in the theatre.\n\nThe Given Sentence: \nThe boar is in the hotel lobby."}], "chosen": [{"role": "assistant", "content": "Y"}], "rejected": [{"role": "assistant", "content": "Y"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHEN] Who is the leader of ruling party in rajya sabha?"}], "chosen": [{"role": "assistant", "content": "WHAT IS THE LEADING PART OF RAH?"}], "rejected": [{"role": "assistant", "content": "WHAT IS WHO?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[LA|LEX] What is the meaning of Messengers?"}], "chosen": [{"role": "assistant", "content": "Thus, the correct clarifying question would be: \"Are you referring to the celestial messenger (such as the Muses in Greek mythology) or a person who delivers messages?\" Alternatively, the assistant might ask: \"Which meaning are you asking about"}], "rejected": [{"role": "assistant", "content": "ah"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHEN] Who did oklahoma play in the bowl game this year?"}], "chosen": [{"role": "assistant", "content": "WHAT WHO DID OKLAHOMA PLAY IN THE BOWL game?"}], "rejected": [{"role": "assistant", "content": "WHAT DID THE 1970 LIONS DO IN 2018?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHERE] Where is the x factor final 2017 filmed?"}], "chosen": [{"role": "assistant", "content": "thinking Okay, let's look at this query. The user is asking about where the \"x factor final 2017\" was filmed. They mention the show \"x factor final 2017\", but there are a few ambiguities here. First, \"x factor final 2017\" could refer to different things. Maybe it's a specific episode or season of the UK show \"The X Factor,\" which is known to be filmed in different locations each year. But \"x factor\" might also refer to other versions or different years. The user mentions 2017, so it's likely they are referring to that particular season or episode. But then, the main ambiguity here is the name itself: \"x factor final 2017\". The user might not be clear on which specific instance they are referring to. Without clarification, we need to determine if they mean the UK version, the US version, or perhaps a different country's adaptation. Additionally, the show \"x factor\" usually has different filming locations depending on the season and country. For example, the UK versions are filmed in various locations, but the US version is typically in Los Angeles. However, the specifics for each season might vary. So the first thing is, do they mean the UK show? US show? Australian show? All these have different filming locations. And then in 2017, which season or episode? For the UK show, \"x Factor 2017\" would be their 10th season, I think. For the US version, \"x Factor\" first premiered in 2008, so 2017 would be a recent season. But without knowing which country's version they're referring to, it's ambiguous. Therefore, the clarifying question should first determine which country's version (UK vs US) and which season/episode of \"x factor\" (final?) they are referring to. But since the categories here require a specific clarifying question related to the ambiguity, perhaps asking if the user specified the country, the season, or the exact name of the show. Alternatively, possible options could be: - Are you referring to the UK or US version of \"x Factor?\" - Is \"x Factor (2017)\" referring to a specific episode or season? - Can you specify the country/region if the ambiguous context changes? But given the structure of the categories (where the subclasses define specific aspects), perhaps the user's question falls under AO WHERE: Missing context leading to multiple interpretations. But since the categories are specific, the question should be a one-word tag. For example: WHO, WHEN, or WHERE (depending on the ambiguity type). But in this case, the ambiguity is about multiple possible identities for \"x factor final 2017\" (different countries, different seasons). The missing information is country and/or season. According to the categories, for where to ask clarification, the key is missing location context. But in the problem's case, the user mentions the show name as ambiguous. So the main missing info is which country's version and which season/episode. But the clarifying question should be a single category tag. For example, if it's about the country's version, which would fall under UNF (if unfamiliar country name). Or if it's about episode vs season, perhaps OM (Other Missing?). Wait, the categories have EM UNF or maybe AO categories with OW (Other Where)? But based on the given categories, the user's question falls under the AO category: where? So the main category is UNF or CONT. Wait, the EM's subclasses are UNF or CONT. But the question here is ambiguous due to multiple UNFs (Unfamiliar entities). So the missing information could be country and/or episode. So according to the output format, we need to generate a one-word clarifying question related to the category. The categories are to ask for one category or term. So, for the user's case, which is a mix of not knowing which country's show and which season, so which categories to ask? Since the main ambiguity is under AO: missing parts (where, whom, when, etc.), the output should be a one-word category. But in this case, the user is confused because the ambiguous entity could be about different countries or versions. Now, according to the categories given, the user needs to choose the appropriate aspect to ask for. The categories relevant here are: - The show could be referring to multiple countries (UK vs US), so missing UNF (for UNFAMILIAR). - Also, which season? The question mentions \"final 2017\", so presumably the final episode of the 2017 season, but depending on the country show, the season episodes might be labeled different. So the missing entities are: - Country version (UNF) - Season (could be SW - Seasonal Variation?) but not defined here. Alternatively, the user might be asking about the show name vs the specific episode. In the absence of a specific category for \"season\", the user may be pointing to two different UNFs. According to the problem, the possible subclasses to ask: - EM's subclasses: UNF or CONT. So the main entities to ask"}], "rejected": [{"role": "assistant", "content": "WHAT= ?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[EM|UNF] What's the body mass of Macapcebus?"}], "chosen": [{"role": "assistant", "content": "WHER?"}], "rejected": [{"role": "assistant", "content": "PLEASE."}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[LA|LEX] What is the best way to fix a bored hole?"}], "chosen": [{"role": "assistant", "content": "How do you fix a bored hole?"}], "rejected": [{"role": "assistant", "content": "I am encountering a word with multiple meanings. Can you clarify what it means?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHEN] When was the last time the sixers won a championship?"}], "chosen": [{"role": "assistant", "content": "### Clarifying Question: Wait, which championship are you referring to for the Sixers?"}], "rejected": [{"role": "assistant", "content": "WHEN: Last time the sixers won a championship?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[LA|SEM] William told Joshua that he devastated the saleswoman.\nWho devastated the saleswoman?"}], "chosen": [{"role": "assistant", "content": "|nohw|What do you mean by he? Is it your or the boy?"}], "rejected": [{"role": "assistant", "content": "CLEARING: Will or Joshua?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[LA|SEM] Melissa told Jennifer that she aggrieved the father-in-law.\nWho aggrieved the father-in-law?"}], "chosen": [{"role": "assistant", "content": "WHOWHERE?"}], "rejected": [{"role": "assistant", "content": "WHAT IS THE LOCATION?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHAT] Where is the oldest living tree in the united states?"}], "chosen": [{"role": "assistant", "content": "WHAT is the oldest living tree in the united states?"}], "rejected": [{"role": "assistant", "content": "WHAT is the criteria for oldest living tree in the united states?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[EM|CONT] The all possible word categories are either \"does not contain a negation\" or \"proper noun\".\nThe following two examples share a specific word category. You need to first infer the specific word category from the examples.\nPlease output \"X\" if the given sentence mentions the specific word category. Please output \"Y\" if the given sentence does not mention the word category.\n\nExamples: \nThe director has not been in the laboratory.\nMargot Robbie has been in the film studio.\n\nThe Given Sentence: \nSerena Williams may not be in the restaurant."}], "chosen": [{"role": "assistant", "content": "X"}], "rejected": [{"role": "assistant", "content": "what word category is present in? Output: X/Y X Y Y Y Since the given sentence mentions present present word categories. You need to output: X or Y Since both sentences mention present word categories."}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[LA|LEX] What happens when the machine is folded?"}], "chosen": [{"role": "assistant", "content": "Possible options: Physical, Programmatic So the output is: What type of folding method of the machine?"}], "rejected": [{"role": "assistant", "content": "ort"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHOM] Give me a list of things I can do with a bunch of extra money."}], "chosen": [{"role": "assistant", "content": "WHAT is a list of things I can do with a bunch of extra money."}], "rejected": [{"role": "assistant", "content": "WHAT is a list of things I can do with a bunch of extra money?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHAT] Where did the english bill of rights happen?"}], "chosen": [{"role": "assistant", "content": "So the clarifying question would be which country's: England or United Kingdom?"}], "rejected": [{"role": "assistant", "content": "WHAT=|"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHERE] Where does the saying the devil is beating his wife come from?"}], "chosen": [{"role": "assistant", "content": "WHAT DOES THE SINGING HAVE TO DO WITH?"}], "rejected": [{"role": "assistant", "content": "WHAT IS the meaning of where?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[LA|SEM] The sister-in-law wrote a letter to Amanda because she is attending a conference next week.\nWho is attending a conference next week?"}], "chosen": [{"role": "assistant", "content": "() What is the name of the conference?"}], "rejected": [{"role": "assistant", "content": "oto"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHOM] Whats the dogs name in the movie up?"}], "chosen": [{"role": "assistant", "content": "WHAT WHO IS IN the Movie UP?"}], "rejected": [{"role": "assistant", "content": "When does he take place up."}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[LA|LEX] Who is Valli?"}], "chosen": [{"role": "assistant", "content": "WHAT IS NERU"}], "rejected": [{"role": "assistant", "content": "hern in in to get in to the what in?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[EM|UNF] What is the longitude of Galphyea's habitat?"}], "chosen": [{"role": "assistant", "content": "WHAT is the longitude of Galphyea's habitat?"}], "rejected": [{"role": "assistant", "content": "What star system is she in the same solar system?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[EM|CONT] The all possible word categories are either \"secular leader\" or \"female pronoun\".\nThe following two examples share a specific word category. You need to first infer the specific word category from the examples.\nPlease output \"X\" if the given sentence mentions the specific word category. Please output \"Y\" if the given sentence does not mention the word category.\n\nExamples: \nHe is in the house with the ayatollah.\nShe is in the grocery store with the judge.\n\nThe Given Sentence: \nShe is in the laboratory with the cardinal."}], "chosen": [{"role": "assistant", "content": "Y"}], "rejected": [{"role": "assistant", "content": "WHOM"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[LA|SEM] The sister-in-law texted Amanda because she is flying abroad soon.\nWho is flying abroad soon?"}], "chosen": [{"role": "assistant", "content": "Amanda's or the sister-in-law's?\" Therefore, the output should be something like: \"Whose flight is she referring to in this context?\" or \"Is she the sister-in-law or Amanda who is flying abroad soon?\" But the best way to phrase it, according to the categories, would be: \"In the context provided, does the term 'she' refer to Amanda or the sister-in-law?\" /Assistant In the context provided, does the term \"she\" refer to Amanda or the sister-in-law?"}], "rejected": [{"role": "assistant", "content": "WHO HAS SHE FLYING ABROAD SOON?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[EM|CONT] The all possible word categories are either \"outdoor location\" or \"animal\".\nThe following two examples share a specific word category. You need to first infer the specific word category from the examples.\nPlease output \"X\" if the given sentence mentions the specific word category. Please output \"Y\" if the given sentence does not mention the word category.\n\nExamples: \nThe firefighter is in the film studio.\nThe boar is in the woodlands.\n\nThe Given Sentence: \nThe snake is in the theatre."}], "chosen": [{"role": "assistant", "content": "X WHAT"}], "rejected": [{"role": "assistant", "content": "X"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[EM|UNF] Does Pyryrnus magnet have a exoskeleton skeleton structure?"}], "chosen": [{"role": "assistant", "content": "PROBLEM: The category is EM|UNF, so the user wants to clarify the unfamiliar entity or fact mentioned in the query. In the provided clarifying questions, you should select one that helps find out more about the unfamiliar entity or fact present in the sentence. Therefore, choose a clarifying question that helps answer the UNF or other subclauses."}], "rejected": [{"role": "assistant", "content": "多少"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[LA|SEM] Matthew told Joshua that he pacified the client.\nWho pacified the client?"}], "chosen": [{"role": "assistant", "content": "When did you mean 'she'?"}], "rejected": [{"role": "assistant", "content": "END"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHERE] When does the how to train your dragon 3 movie come out?"}], "chosen": [{"role": "assistant", "content": "WHEN= When do you want to train your dragon 3?"}], "rejected": [{"role": "assistant", "content": "WHAT IS THE THE TIME ZOMBIE CHASE STARTS?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[EM|CONT] The all possible word categories are either \"human\" or \"indoor location\".\nThe following two examples share a specific word category. You need to first infer the specific word category from the examples.\nPlease output \"X\" if the given sentence mentions the specific word category. Please output \"Y\" if the given sentence does not mention the word category.\n\nExamples: \nThe horse is in the jungle.\nThe critic is in the museum.\n\nThe Given Sentence: \nThe hound is in the restaurant."}], "chosen": [{"role": "assistant", "content": "Y"}], "rejected": [{"role": "assistant", "content": "X Y"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHEN] What is the latest episode of house of cards?"}], "chosen": [{"role": "assistant", "content": "(WHAT episode is the latest)"}], "rejected": [{"role": "assistant", "content": ""}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHERE] Can you please divide these fruit and vegetables into red and green colors. Some can be either red or green, so list those as 'both red and green varieties'. Here is the list: cherries, raspberries, lettuce, celery cherries, strawberries, apples, peppers, cabbage, beans, kale, tomatoes, capsicum, raspberries, celery, spinach."}], "chosen": [{"role": "assistant", "content": "Wat fruit en groenten kunt u indelen in rood en groen kleur, met als alternatief sowohlrode- als grune variëteiten, vraag als item."}], "rejected": [{"role": "assistant", "content": "WHERE: WHEN IS PRODUCING PRODUCE ENDURING ART?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHERE] When do we celebrate veterans day this year?"}], "chosen": [{"role": "assistant", "content": "WHAT country do you mean when you say the US?"}], "rejected": [{"role": "assistant", "content": "WHAT ARE YOUR AVAILABLE TAPE?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[LA|SEM] Kimberly told the aunt that she enchanted the granddaughter.\nWho enchanted the granddaughter?"}], "chosen": [{"role": "assistant", "content": "VERIFY: Which word refers to the person you spoke with, whether grandmother or grandmother."}], "rejected": [{"role": "assistant", "content": "NONE"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[EM|CONT] The all possible word categories are either \"does not contain a negation\" or \"proper noun\".\nThe following two examples share a specific word category. You need to first infer the specific word category from the examples.\nPlease output \"X\" if the given sentence mentions the specific word category. Please output \"Y\" if the given sentence does not mention the word category.\n\nExamples: \nThe surveyor may not be in the grocery store.\nNoam Chomsky may be in the hotel lobby.\n\nThe Given Sentence: \nJane Goodall has not been in the museum."}], "chosen": [{"role": "assistant", "content": "WHOM"}], "rejected": [{"role": "assistant", "content": "WHAM?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[EM|CONT] The all possible word categories are either \"outdoor location\" or \"animal\".\nThe following two examples share a specific word category. You need to first infer the specific word category from the examples.\nPlease output \"X\" if the given sentence mentions the specific word category. Please output \"Y\" if the given sentence does not mention the word category.\n\nExamples: \nThe horse is in the cave.\nThe director is in the courtroom.\n\nThe Given Sentence: \nThe worm is in the film studio."}], "chosen": [{"role": "assistant", "content": "X Loom Y Outdoor location: out of the other options, outdoor location is either outdoors or outdoor location is either outdoors or inside."}], "rejected": [{"role": "assistant", "content": "X WHAT"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[LA|LEX] What are some common uses of shoots?"}], "chosen": [{"role": "assistant", "content": "Are you asking about 'shoot' as the noun with multiple meanings or the verb?"}], "rejected": [{"role": "assistant", "content": ""}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHEN] The truth about the harry quebert affair tv show release date?"}], "chosen": [{"role": "assistant", "content": "WHEN is the time when the \"hquelber\" affair was revealed on TV?"}], "rejected": [{"role": "assistant", "content": "WHAT=[WHEN]"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHERE] Where did the beatles first perform in america?"}], "chosen": [{"role": "assistant", "content": "WHAT IS THE FIRST PLACE?"}], "rejected": [{"role": "assistant", "content": "So, in the final step, I need to ask in the presence of any entity names in the sentence?\" So, in the first step, I need to ask for any entity names in the sentence.\" So, in the first step, I need to ask:\" So, final step: when there is any entity or entity names.\" So, when I have any entity names in the name of the beatles name.\" So, in the final step, I need to ask: which entity in the name of the beatles name.\" So, when I have any entity names in the name of the beatles name.\" So, final step: if I have any entity in the name of the beatles name.\" I need to ask which entity in the name of the beatles name.\" So, in the final step, I need to clarify when I have any entity names in the name of the beatles name.\" So, first and last question: So, first: clarify whether the beatles name.\" So, first: which entity in the name of the beatles ?\" So, which entity in the name of the beatles name.\" So, first: if the name contains any entities, which is in the name of the beatles name.\" First: which entity in the name of the beatles name.\" So, in the first step: if the speaker has any entity names with the name of the beatles.\" First: which entity in the name of the beatles name.\" So, in the first step, if I have any entity names in the name of the beatles name.\" First: which entity in the name of the beatles name.\" So, first: which entity in the name of the beatles name.\" So, if I have any entity names in the name of the beatles name.\" So, first: which entity in the name of the beatles name.\""}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[LA|SEM] The sister-in-law told Amanda that she moved the client.\nWho moved the client?"}], "chosen": [{"role": "assistant", "content": "Thus, the main clarifying question is: Does \"she\" refer to the sister-in-law or Amanda?"}], "rejected": [{"role": "assistant", "content": "When is the client's move scheduled?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[EM|UNF] Does Sitophilus granarius have Zea mays as its host?"}], "chosen": [{"role": "assistant", "content": "So the output can be: \"Which of the following refers to the appropriate genus/species name in your query?\" \"Does Sitophilus granarius refer to one specific species, and does Zea mays refer to corn or another species?\"\" But the answer should be in the format: Choose the correct category and subtype, then ask a clarification."}], "rejected": [{"role": "assistant", "content": "input"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[EM|CONT] The all possible word categories are either \"does not contain a negation\" or \"proper noun\".\nThe following two examples share a specific word category. You need to first infer the specific word category from the examples.\nPlease output \"X\" if the given sentence mentions the specific word category. Please output \"Y\" if the given sentence does not mention the word category.\n\nExamples: \nThe researcher was not in the house.\nAlexandria Ocasio-Cortez was in the laboratory.\n\nThe Given Sentence: \nThe hiker could be in the apartment building."}], "chosen": [{"role": "assistant", "content": "When mentions the word category \"proper noun\"."}], "rejected": [{"role": "assistant", "content": "WHARE"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[EM|UNF] Does Nilea innhesoni have otoliths as part of its auditory system?"}], "chosen": [{"role": "assistant", "content": "WHAT is the name of the structure of human eye that facilitates the transfer of sound waves to the brain?"}], "rejected": [{"role": "assistant", "content": "PLEASE CONFIRM: Does idileptonisha/i have otoliths as a part of its auditory system?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[LA|SEM] Matthew pinged Joshua because he is traveling abroad tomorrow.\nWho is traveling abroad tomorrow?"}], "chosen": [{"role": "assistant", "content": "WHO?"}], "rejected": [{"role": "assistant", "content": "hoferjames.aghami@gmail # 'er, I just had a baby, # Where's Joshua?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[LA|SEM] Matthew passed Joshua a pen before he lost track of time.\nWho lost track of time?"}], "chosen": [{"role": "assistant", "content": "POST-PROBLEM: WHO LOST TRACK OF TIME?"}], "rejected": [{"role": "assistant", "content": "OUTPUT: The question has no ambiguous entity in the first place. Please provide the identity."}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[EM|UNF] What is the amount of carbon biomass in Carya alata?"}], "chosen": [{"role": "assistant", "content": "What is the carbon biomass of Carya alata in the United States?"}], "rejected": [{"role": "assistant", "content": "What is the amount of carbon biomass in the genus Carya allata?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHOM] Name some famous jazz songs?"}], "chosen": [{"role": "assistant", "content": "WHAT=FAMOUS JAZZ SINGLES?"}], "rejected": [{"role": "assistant", "content": ""}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHOM] How do I choose a new phone?"}], "chosen": [{"role": "assistant", "content": "RIGHT: Can you name which other phone you are suggesting?"}], "rejected": [{"role": "assistant", "content": ""}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHEN] When did michael jordan join the chicago bulls?"}], "chosen": [{"role": "assistant", "content": "WHAT TIME did Michael Jordan join the Chicago Bulls?"}], "rejected": [{"role": "assistant", "content": "WHAT TEAM DID ?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHAT] Who has won the most oscars of all time?"}], "chosen": [{"role": "assistant", "content": "WHAT: Who has won the most Oscar award?"}], "rejected": [{"role": "assistant", "content": "Who did you just defeat?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[LA|SEM] The sister-in-law left a note for Amanda because she was upset.\nWho was upset?"}], "chosen": [{"role": "assistant", "content": "� Was it the sister-in-law who was upset or Amanda who was upset?"}], "rejected": [{"role": "assistant", "content": ""}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[EM|CONT] The all possible word categories are either \"male pronoun\" or \"religious leader\".\nThe following two examples share a specific word category. You need to first infer the specific word category from the examples.\nPlease output \"X\" if the given sentence mentions the specific word category. Please output \"Y\" if the given sentence does not mention the word category.\n\nExamples: \nShe is in the museum with the CEO.\nHe is in the theatre with the imam.\n\nThe Given Sentence: \nHe is in the courtroom with the officer."}], "chosen": [{"role": "assistant", "content": "WHM:"}], "rejected": [{"role": "assistant", "content": "WHOM"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[LA|LEX] What is the significance of Illumina in genetics?"}], "chosen": [{"role": "assistant", "content": "--) What does the term \"Significance\" refer to in the context of \"In the field of genetics\"?"}], "rejected": [{"role": "assistant", "content": "END"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHAT] How can I be more productive?"}], "chosen": [{"role": "assistant", "content": "I'm confused. You want to find the most clear question for this input, or just an output that is a clarifying question?"}], "rejected": [{"role": "assistant", "content": "I'm not a human."}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[EM|CONT] The all possible word categories are either \"indoor location\" or \"human\".\nThe following two examples share a specific word category. You need to first infer the specific word category from the examples.\nPlease output \"X\" if the given sentence mentions the specific word category. Please output \"Y\" if the given sentence does not mention the word category.\n\nExamples: \nThe director is in the hotel lobby.\nThe hawk is in the pond.\n\nThe Given Sentence: \nThe boar is in the film studio."}], "chosen": [{"role": "assistant", "content": "X"}], "rejected": [{"role": "assistant", "content": "WHOM"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHOM] Who was a at the beginning of pretty little liars?"}], "chosen": [{"role": "assistant", "content": "I'm confused about who you were referring to."}], "rejected": [{"role": "assistant", "content": "Is there a character named \"A\"?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[EM|CONT] The all possible word categories are either \"proper noun\" or \"does not contain a negation\".\nThe following two examples share a specific word category. You need to first infer the specific word category from the examples.\nPlease output \"X\" if the given sentence mentions the specific word category. Please output \"Y\" if the given sentence does not mention the word category.\n\nExamples: \nThe surveyor could not be in the film studio.\nSerena Williams may be in the apartment building.\n\nThe Given Sentence: \nThe firefighter could be in the theatre."}], "chosen": [{"role": "assistant", "content": "?=X"}], "rejected": [{"role": "assistant", "content": "X"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHAT] Who did the land ordinance of 1785 benefit?"}], "chosen": [{"role": "assistant", "content": "What country did the landlord benefit in the Land Ordinance of 1785?"}], "rejected": [{"role": "assistant", "content": ".contains?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[LA|SEM] Matthew told Joshua that the client disdained him.\nWho did the client disdain?"}], "chosen": [{"role": "assistant", "content": "|erudite|"}], "rejected": [{"role": "assistant", "content": "STOP"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHAT] When was television introduced to the general public?"}], "chosen": [{"role": "assistant", "content": "WHET"}], "rejected": [{"role": "assistant", "content": "WHOV?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[LA|SEM] Kimberly told the aunt that the granddaughter trusted her.\nWho did the granddaughter trust?"}], "chosen": [{"role": "assistant", "content": "On which relative did the granddaughter trust?"}], "rejected": [{"role": "assistant", "content": "-"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[EM|UNF] What is the preferred water depth range of Hime capitonis?"}], "chosen": [{"role": "assistant", "content": "QUESTION: Does the reference point for the preferred water depth range of Hime capitonis include water depths less than what or more than what?"}], "rejected": [{"role": "assistant", "content": ") How do you know what you want?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHERE] What is the origin of the name benjamin?"}], "chosen": [{"role": "assistant", "content": "What specific origin (biological, etymological, or cultural) are you referring to when asking about the name \"Benjamin\"?"}], "rejected": [{"role": "assistant", "content": "WHAT is the origin of any person nick named benjamin?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHOM] Give me a list of good coffee shops?"}], "chosen": [{"role": "assistant", "content": "Question: What is the city or country of your favorite coffee shop?"}], "rejected": [{"role": "assistant", "content": "WHOM is a location?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHEN] When was the first texas chainsaw massacre movie made?"}], "chosen": [{"role": "assistant", "content": "WHAT WHEN? Do you mean THE FIRST OR THE LAUDABLY-THE FIRST?"}], "rejected": [{"role": "assistant", "content": "WHAT | When did the first 'when' happen?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[LA|LEX] What is the meaning of Unwound?"}], "chosen": [{"role": "assistant", "content": "- What does Unwound mean in which context?"}], "rejected": [{"role": "assistant", "content": "So in this case, the clarification would be: \"Is 'unwounded' referring to a person's name, a date, or a location?\" Wait, let me correct this"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHEN] Where is the champions league cup final being held?"}], "chosen": [{"role": "assistant", "content": "WHAT is the ambiguity type contained in this request?"}], "rejected": [{"role": "assistant", "content": "WHAT IS"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[LA|SEM] Melissa told Jennifer that she confused the father-in-law.\nWho confused the father-in-law?"}], "chosen": [{"role": "assistant", "content": "CLEARING_BRIEF: WHO_"}], "rejected": [{"role": "assistant", "content": "WHOM: WHOW?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHAT] How to find the area of a rectangle?"}], "chosen": [{"role": "assistant", "content": "INQUIRE: Which sides length are we calculating for the area of the rectangle?"}], "rejected": [{"role": "assistant", "content": "} What do you mean by \"area\"? Is there a difference between using an area measure and something else in this context?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHERE] When will hey arnold the jungle movie be on dvd?"}], "chosen": [{"role": "assistant", "content": "WHAT WHEN WILL HEY ARNOLD THE JUNGLE MOVIE BE ON DVD?"}], "rejected": [{"role": "assistant", "content": "WHAT is a new case of a lion with a man walking into the lion!"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[LA|SEM] The sister-in-law told Amanda that the client idolized her.\nWho did the client idolize?"}], "chosen": [{"role": "assistant", "content": "@WHENA"}], "rejected": [{"role": "assistant", "content": "---"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[EM|CONT] The all possible word categories are either \"male pronoun\" or \"religious leader\".\nThe following two examples share a specific word category. You need to first infer the specific word category from the examples.\nPlease output \"X\" if the given sentence mentions the specific word category. Please output \"Y\" if the given sentence does not mention the word category.\n\nExamples: \nHe is in the apartment building with the Dalai Lama.\nShe is in the house with the prime minister.\n\nThe Given Sentence: \nHe is in the restaurant with the prime minister."}], "chosen": [{"role": "assistant", "content": "Y"}], "rejected": [{"role": "assistant", "content": "WHAM?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHEN] When does the new mlb game come out?"}], "chosen": [{"role": "assistant", "content": "WHAT is the new mlb game timeline? What are in the new mlb game timeline?"}], "rejected": [{"role": "assistant", "content": "WHAT does when mean?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[EM|UNF] Can Arichria be found in terrestrial habitat?"}], "chosen": [{"role": "assistant", "content": "WHAT"}], "rejected": [{"role": "assistant", "content": "WHOM: Who?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHEN] Who has become the new member of upsc?"}], "chosen": [{"role": "assistant", "content": "WHAT DID?"}], "rejected": [{"role": "assistant", "content": "WHAT do you think is news report?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHOM] Give me a list of things I should bring when taking a baby to the park."}], "chosen": [{"role": "assistant", "content": "WHAT DO YOU MEAN by \"things\""}], "rejected": [{"role": "assistant", "content": ""}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[LA|LEX] Who is Amy's best friend?"}], "chosen": [{"role": "assistant", "content": "ort"}], "rejected": [{"role": "assistant", "content": "请给出"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHERE] Where was tiger spy in the jungle filmed?"}], "chosen": [{"role": "assistant", "content": "WHAT"}], "rejected": [{"role": "assistant", "content": "WHAT is the name of the song that is the 22nd track in the 2016?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHAT] The last electron acceptor of the electron transport chain (etc) in cellular respiration is?"}], "chosen": [{"role": "assistant", "content": "Is the last electron acceptor located in the mitochondrial matrix or intermembrane space?"}], "rejected": [{"role": "assistant", "content": "WHAT"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHAT] How can I do a figure skating toe loop jump?"}], "chosen": [{"role": "assistant", "content": "What specific details do you need clarification on? Are you asking about the execution of the technique or the context in which the move can be performed?"}], "rejected": [{"role": "assistant", "content": "Okay, the user is asking, \"How can I do a figure skating toe loop jump?\" The assistant needs to generate a clarifying question based on the ambiguity type."}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[LA|LEX] What is the role of the bench in a courtroom?"}], "chosen": [{"role": "assistant", "content": "START:The role of the bench in the courtroom has some ambiguity WHAT: In what context do you say role of the bench in the courtroom?"}], "rejected": [{"role": "assistant", "content": "EM Is there a context outside of the legal system for the bench?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[EM|UNF] Is Eteone's locomotion based on crawler?"}], "chosen": [{"role": "assistant", "content": "PROBLEM: Which part is used for moving forward with the model of locomotion, specifically for crawling forward. What is the model name that can move forward?"}], "rejected": [{"role": "assistant", "content": "NONE What's the type of Eteone's locomotion?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[EM|CONT] The all possible word categories are either \"religious leader\" or \"male pronoun\".\nThe following two examples share a specific word category. You need to first infer the specific word category from the examples.\nPlease output \"X\" if the given sentence mentions the specific word category. Please output \"Y\" if the given sentence does not mention the word category.\n\nExamples: \nHe is in the theatre with the rabbi.\nShe is in the apartment building with the colonel.\n\nThe Given Sentence: \nShe is in the hotel lobby with the ayatollah."}], "chosen": [{"role": "assistant", "content": "WHEN"}], "rejected": [{"role": "assistant", "content": "WHOM"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHERE] Who was america's leading ace of ww1?"}], "chosen": [{"role": "assistant", "content": "WHAT IS NOT MEASURE BY WHAT?"}], "rejected": [{"role": "assistant", "content": "WHAT WHO WAS"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHERE] When did they do away with the draft?"}], "chosen": [{"role": "assistant", "content": "WHAT is happened?"}], "rejected": [{"role": "assistant", "content": "WHAT DID THE AMOUNT OF HOCKS IN AN EIGHT HOUR GAME?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[EM|UNF] What's the average temperature range in the geographic range of Suncus dayi?"}], "chosen": [{"role": "assistant", "content": "1) Can you specify which geographic locations were included in your research for the species Suncus dayi?"}], "rejected": [{"role": "assistant", "content": "WHAT IS THE THE TEMPERATURE Ranges FOR SUNDUS DAYI?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHOM] Give me a list of different cat species that are good for people with allergies."}], "chosen": [{"role": "assistant", "content": "WHAT CAT SPECIES IS BEST SUIT FOR PEOPLE WHO HAS ALERGIES"}], "rejected": [{"role": "assistant", "content": "WHAT IS A cat species that is good for people with allergies?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHOM] Who is mr jones in counting crows song?"}], "chosen": [{"role": "assistant", "content": "Jones' from the same album?"}], "rejected": [{"role": "assistant", "content": "Jones from the song 'counting crows song' or is it a character from another source?\" But in the specific categories for UNF, the user could mention either an unfamiliar entity (e.g., who Mr."}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHERE] Give me the steps to purchase a new pair of shoes."}], "chosen": [{"role": "assistant", "content": "WHAT'S THE PRICE OF NEW SHOOSES?"}], "rejected": [{"role": "assistant", "content": "WHAT ARE THE FLORAL COLORS?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[EM|UNF] What's the longitude of the location where Hyalina is commonly found?"}], "chosen": [{"role": "assistant", "content": "DEFINED as: Hyalina, is a common name of a non-porous organism found in the arctic region where the surface is covered in ice and is known to be found east of the U.S."}], "rejected": [{"role": "assistant", "content": "EM: Query contains unfamiliar facts."}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[EM|CONT] The all possible word categories are either \"does not contain a negation\" or \"proper noun\".\nThe following two examples share a specific word category. You need to first infer the specific word category from the examples.\nPlease output \"X\" if the given sentence mentions the specific word category. Please output \"Y\" if the given sentence does not mention the word category.\n\nExamples: \nThe student has not been in the courtroom.\nAlexandria Ocasio-Cortez may be in the hotel lobby.\n\nThe Given Sentence: \nAlexandria Ocasio-Cortez has not been in the restaurant."}], "chosen": [{"role": "assistant", "content": "WHOM"}], "rejected": [{"role": "assistant", "content": "WHOM"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[EM|UNF] Is Herentia thalmanni multicellular?"}], "chosen": [{"role": "assistant", "content": "Is \"herentia thalmanni\" a type of bacteria?"}], "rejected": [{"role": "assistant", "content": "Is \"there\" a location described as multicellular?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[LA|LEX] How has the word \"changed\" been used in different contexts?"}], "chosen": [{"role": "assistant", "content": "Can you provide more context to clarify the specific meanings of \"changed\"?"}], "rejected": [{"role": "assistant", "content": "把程序优化的概念用在不同的上下文中？"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[EM|CONT] The all possible word categories are either \"human\" or \"indoor location\".\nThe following two examples share a specific word category. You need to first infer the specific word category from the examples.\nPlease output \"X\" if the given sentence mentions the specific word category. Please output \"Y\" if the given sentence does not mention the word category.\n\nExamples: \nThe duck is in the meadow.\nThe student is in the courtroom.\n\nThe Given Sentence: \nThe surveyor is in the meadow."}], "chosen": [{"role": "assistant", "content": "X Y"}], "rejected": [{"role": "assistant", "content": "X Y"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHEN] Mexico is led by a chief of state who is?"}], "chosen": [{"role": "assistant", "content": "['LEX|WHAT|WHENER|WHEN?']"}], "rejected": [{"role": "assistant", "content": "WHAT HAS ALWAYS BEEN IN THE NEWS, AND THE PRESIDENT? - WHON (WHOM)?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[EM|CONT] The all possible word categories are either \"female pronoun\" or \"secular leader\".\nThe following two examples share a specific word category. You need to first infer the specific word category from the examples.\nPlease output \"X\" if the given sentence mentions the specific word category. Please output \"Y\" if the given sentence does not mention the word category.\n\nExamples: \nShe is in the apartment building with the principal.\nHe is in the museum with the bishop.\n\nThe Given Sentence: \nHe is in the grocery store with the CEO."}], "chosen": [{"role": "assistant", "content": "X"}], "rejected": [{"role": "assistant", "content": "When does the word category mention appear?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHAT] When did they start using rebar in concrete?"}], "chosen": [{"role": "assistant", "content": "WHAT | WHAT does rebar start mean when using rebar in concrete?"}], "rejected": [{"role": "assistant", "content": "EM|UNF-IMIS"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHAT] When did how to train a dragon come out?"}], "chosen": [{"role": "assistant", "content": "WHOTIME IS NOT A TRAINING DOG?"}], "rejected": [{"role": "assistant", "content": "WHAT is when to play the role of a spy or a thief when the player loses?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHEN] Who is the president of holy cross college?"}], "chosen": [{"role": "assistant", "content": "WHEN is the time reference for the president of holly college? If today is Thursday afternoon and the day changes to Friday evening?"}], "rejected": [{"role": "assistant", "content": "END"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[LA|LEX] What is the main business of Ryder?"}], "chosen": [{"role": "assistant", "content": "Thus, the clarifying question would be: \"Which type of 'Ryder' is your subject (company, person, etc.) a reference to: the company's business, or an individual's background?\" What is the main reference of \"Ryder\"—specific entity category (e.g., role or entity type, like company or person)?"}], "rejected": [{"role": "assistant", "content": "WHAT is the main business of RYDER?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[EM|UNF] What is the body length of Pristis perottistis?"}], "chosen": [{"role": "assistant", "content": "WHAT"}], "rejected": [{"role": "assistant", "content": "END_OF_TEMPLATE"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHOM] Who sings i can't tell you why by the eagles?"}], "chosen": [{"role": "assistant", "content": "/read Output: Who are you referring to: the individual artists (Gladys Knight) or the band (The Eagles) version of \"I Can't Stop\"?"}], "rejected": [{"role": "assistant", "content": "REFERRED QUERY: Who is the one who sings \"i can't tell you why\"?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[EM|UNF] What is the latitude range of icarchidae's habitat?"}], "chosen": [{"role": "assistant", "content": "PERHAPS]: Are you referencing the ICAR group?"}], "rejected": [{"role": "assistant", "content": "REGISTER CONFIRMED"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHOM] Name a few popular metal genres"}], "chosen": [{"role": "assistant", "content": "WHAT are a few popular metal genres"}], "rejected": [{"role": "assistant", "content": "WHAT ARE THE NAME OF SOME METALS"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHEN] Where was the movie fundamentals of caring filmed?"}], "chosen": [{"role": "assistant", "content": "WHAT city?"}], "rejected": [{"role": "assistant", "content": "WHAT: Which part?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[EM|UNF] Is Urbanus protea introduced in an area that includes The Contiguous United States?"}], "chosen": [{"role": "assistant", "content": "What part of the United States is included in the original introduction area?"}], "rejected": [{"role": "assistant", "content": "PROBLEM: The question contains unfamiliar entities, either unfamiliar or unknown by the user."}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHERE] Where is the oldest bristlecone pine tree located?"}], "chosen": [{"role": "assistant", "content": "WHAT'S THE NAME OF THE CANDY IN THE UNIVERSE?"}], "rejected": [{"role": "assistant", "content": "WHAT IS THE ATENOR NAME THAT HAS ORIGINS IN MEXICO?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[LA|LEX] What is the meaning of Doomed?"}], "chosen": [{"role": "assistant", "content": "So the clarifying question should be something like, \"Are you referring to one of the possible meanings of 'Doomed' as a noun, a verb, or another sense?\" But in the given categories, the assistant should generate a question that follows the classifier."}], "rejected": [{"role": "assistant", "content": "空杯子, 4.46, can you tell me more or are you trying to test me?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[LA|LEX] What is the meaning of the term 'Towelhead'?"}], "chosen": [{"role": "assistant", "content": "So the question would be: Which aspect of the term 'Towelhead' is the user interested in?"}], "rejected": [{"role": "assistant", "content": "title"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[EM|UNF] What's the concentration of nitrates in the water where Geuryphaorella lives?"}], "chosen": [{"role": "assistant", "content": "WHAT IS THE WAYS THAT THE GEURYPHAORELLA IN THE CANY ON THE WEST SIDER OF 2?"}], "rejected": [{"role": "assistant", "content": "QUESTION: Is the subject of \"What is the name of the first one, not the last one or one?\" referring to the original description of what the subject is?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[EM|CONT] The all possible word categories are either \"male pronoun\" or \"religious leader\".\nThe following two examples share a specific word category. You need to first infer the specific word category from the examples.\nPlease output \"X\" if the given sentence mentions the specific word category. Please output \"Y\" if the given sentence does not mention the word category.\n\nExamples: \nHe is in the grocery store with the pastor.\nShe is in the grocery store with the ambassador.\n\nThe Given Sentence: \nHe is in the grocery store with the officer."}], "chosen": [{"role": "assistant", "content": "WHOM"}], "rejected": [{"role": "assistant", "content": "Y"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHEN] When does the radio times come out for christmas?"}], "chosen": [{"role": "assistant", "content": "WHAT OR WHEN?"}], "rejected": [{"role": "assistant", "content": "WHAT_VERSION_OF_CHRISTMAS"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[EM|UNF] Does the developmental mode of Lystra include precocial?"}], "chosen": [{"role": "assistant", "content": "So, in this case, the clarifying question could be: Are you referring to a species called 'ystra', or is the name a misspelling of another term?"}], "rejected": [{"role": "assistant", "content": "The key parts of the question are: \"Does the developmental mode of Lystra include precocious?\" There are two words that could be ambiguous."}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHERE] Where is the isle of man tt race held at?"}], "chosen": [{"role": "assistant", "content": "WHAT is a one unit event?"}], "rejected": [{"role": "assistant", "content": "WHAT IS THE ISLE OF MAN AT?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[LA|SEM] Kimberly told the aunt that she discouraged the granddaughter.\nWho discouraged the granddaughter?"}], "chosen": [{"role": "assistant", "content": "Is it Kimberly's or the aunt's?"}], "rejected": [{"role": "assistant", "content": "|seperate_name| What is the name of the person?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[LA|LEX] What is the climate like in Harbin?"}], "chosen": [{"role": "assistant", "content": "/s What climate do you mean: cold or harsh?"}], "rejected": [{"role": "assistant", "content": "在寒冬时，哈林的气温会达到多少度呢？"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHERE] When did pokemon gold and silver come out?"}], "chosen": [{"role": "assistant", "content": "WHAT V VERSION?"}], "rejected": [{"role": "assistant", "content": "WHAT is where=west=over=over=city=or=when?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHOM] Give me a list of pizza restaurants in San Francisco"}], "chosen": [{"role": "assistant", "content": "INSTRUCTIONS: Use the list of subclasses as context. Based on the information provided in the interaction, label one clarifying question using either the subclasses. Finally, provide the label for the specific scenario."}], "rejected": [{"role": "assistant", "content": "My clarifying question is \"Who are in the list? Please provide the specific type (if any) of pizza restaurants?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[LA|SEM] The sister-in-law built Amanda a garden after she earned a billion dollars.\nWho earned a billion dollars?"}], "chosen": [{"role": "assistant", "content": "thermy] What did you mean by built the garden?"}], "rejected": [{"role": "assistant", "content": ""}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHEN] Who is the most paid player in the mlb?"}], "chosen": [{"role": "assistant", "content": "WHAT IS A SIMPLE ONE OR TWO WORD QUERY? WHO IS THE BEST?"}], "rejected": [{"role": "assistant", "content": "NONE"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHERE] Where is the pga championship played in 2017?"}], "chosen": [{"role": "assistant", "content": "WHAT IS THE CITY THAT HOSTED THE PGA CHAMPIONSHIP IN 2017?"}], "rejected": [{"role": "assistant", "content": "\"where is the pga championship played in 2017?\" \"Where is the pg championship played in 1978?\""}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHEN] Who sings the song that's what i like about you?"}], "chosen": [{"role": "assistant", "content": "INCLUDE: Which song?"}], "rejected": [{"role": "assistant", "content": "PLEASE SAY WHO?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHEN] Who won the last 5 mlb all star games?"}], "chosen": [{"role": "assistant", "content": "WHAT is UNF?"}], "rejected": [{"role": "assistant", "content": "I hope to get one of your questions now."}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[EM|UNF] What's the geographic distribution of Gerra aocles?"}], "chosen": [{"role": "assistant", "content": "thol"}], "rejected": [{"role": "assistant", "content": "So the correct clarifying question is \"Does the name of the organism as stated refer to a specific species, or is there a possibility of a typo?\" The best possible question from the possible options would be: \"Does the name of the organism as stated refer to a specific species, or is there a possibility of a typo?\" But the possible questions are UNF and categories."}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHOM] Who is the onion knight in game of thrones?"}], "chosen": [{"role": "assistant", "content": "WHO is the knight who is the onion in game of thrones?"}], "rejected": [{"role": "assistant", "content": "WHO IS THE ONI ONION KNIGHT IN THE GAME OF THRONES?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[EM|UNF] What is the longitude of Euphausia h superba's habitat?"}], "chosen": [{"role": "assistant", "content": "INPUT: \"What is the longitude of the Titius-Gajhi species' location?\""}], "rejected": [{"role": "assistant", "content": "WH M:"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[EM|UNF] Is Meleraceae found in the geographic distribution of Mozambique?"}], "chosen": [{"role": "assistant", "content": "What type of organisms' description does \"Pteridinium aff. Meleraceae\" refer to?"}], "rejected": [{"role": "assistant", "content": "END"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHAT] Tell me three key things to do to drive a car faster on a track"}], "chosen": [{"role": "assistant", "content": "VALID CLARIFY QUESTIONS: Is it the front-wheel drive or the all-wheel drive? Is it a 3- or 5-speed transmission? If I have ABS (ASPECT JETABLE), do you press the brake or not?"}], "rejected": [{"role": "assistant", "content": ""}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[EM|CONT] The all possible word categories are either \"indoor location\" or \"human\".\nThe following two examples share a specific word category. You need to first infer the specific word category from the examples.\nPlease output \"X\" if the given sentence mentions the specific word category. Please output \"Y\" if the given sentence does not mention the word category.\n\nExamples: \nThe worm is in the meadow.\nThe researcher is in the grocery store.\n\nThe Given Sentence: \nThe worm is in the museum."}], "chosen": [{"role": "assistant", "content": "Y"}], "rejected": [{"role": "assistant", "content": "Y"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[EM|CONT] The all possible word categories are either \"outdoor location\" or \"animal\".\nThe following two examples share a specific word category. You need to first infer the specific word category from the examples.\nPlease output \"X\" if the given sentence mentions the specific word category. Please output \"Y\" if the given sentence does not mention the word category.\n\nExamples: \nThe worm is in the pond.\nThe hiker is in the film studio.\n\nThe Given Sentence: \nThe reporter is in the marsh."}], "chosen": [{"role": "assistant", "content": "X LM|WO: The worm is a different location option."}], "rejected": [{"role": "assistant", "content": "X"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[LA|SEM] The son told Robert that he annoyed Brian.\nWho annoyed Brian?"}], "chosen": [{"role": "assistant", "content": "Which brother does \"he\" in \"he annoyed Brian\" refer to; the son or Robert?"}], "rejected": [{"role": "assistant", "content": ""}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[EM|UNF] Is the type specimen repository of Saccolopolyspora Naturalis Biodiversity Center, Zoology Collections?"}], "chosen": [{"role": "assistant", "content": "How do you distinguish the unrecognized species in the type specimen repository belonging to the Naturalization Biodiversity Center?"}], "rejected": [{"role": "assistant", "content": "Can you specify the taxonomic rank or characteristics of the new species observed in the type specimen repository of Saccolopolyspora Naturalis Biodiversity Center, Zoology Collections?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHOM] Give me a list of certain insurances that I should take when moving to Germany."}], "chosen": [{"role": "assistant", "content": "What insurances are you referring to?"}], "rejected": [{"role": "assistant", "content": "Where are you?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHEN] Who played roos mum in home and away?"}], "chosen": [{"role": "assistant", "content": "WHAT IS YOUR MEANING OF THAT?"}], "rejected": [{"role": "assistant", "content": "WHAT are your two favorite games of you?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHOM] Tell me about toys that can help children learn to write."}], "chosen": [{"role": "assistant", "content": "Final Output: WHO CONTRAD Claring: Are you asking about parent, teacher, or child's own exploration?"}], "rejected": [{"role": "assistant", "content": "WHAT TOYS HELP Children learn to write AND SPELL"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHOM] How should I pick a name for my baby?"}], "chosen": [{"role": "assistant", "content": "bx-001 When is the baby born? Who is the baby named for?"}], "rejected": [{"role": "assistant", "content": "Looking at the examples, for instance, if the user says \"Who is [EM|UNC]) wanting a story with zombies?\", the classifier picks CLARIFY"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHERE] Who is the 1st governor general of india?"}], "chosen": [{"role": "assistant", "content": "]"}], "rejected": [{"role": "assistant", "content": "] ] ] ]"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[EM|CONT] The all possible word categories are either \"common noun\" or \"contains a negation\".\nThe following two examples share a specific word category. You need to first infer the specific word category from the examples.\nPlease output \"X\" if the given sentence mentions the specific word category. Please output \"Y\" if the given sentence does not mention the word category.\n\nExamples: \nThe hiker was not in the apartment building.\nAlexandria Ocasio-Cortez is in the hotel lobby.\n\nThe Given Sentence: \nHermione Granger was not in the grocery store."}], "chosen": [{"role": "assistant", "content": "Y"}], "rejected": [{"role": "assistant", "content": "whom"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[LA|SEM] The sister-in-law taught Amanda skiing after she took another leave.\nWho took another leave?"}], "chosen": [{"role": "assistant", "content": "WHAT WHAT?"}], "rejected": [{"role": "assistant", "content": "WHEN IS THE CLARIFYING QUESTION?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[LA|LEX] What is the maximum length of a sentence?"}], "chosen": [{"role": "assistant", "content": "For example, \"Which do you mean, 'sentence' as in a period of time in a sentence (like in grammar) or a sentence imposed by a court (like in legal terms)?\" Alternatively, using the categories and subclasses, the clarifying question should be along the lines of \"Are you asking about a sentence as"}], "rejected": [{"role": "assistant", "content": "please complete a movie?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHERE] When does the new solo movie come out?"}], "chosen": [{"role": "assistant", "content": "WHAT: New Solo movie when?"}], "rejected": [{"role": "assistant", "content": "WHAT: WHAT movie is the new?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHAT] Brightest star in the constellation lyra dan word?"}], "chosen": [{"role": "assistant", "content": "Question: Do you mean the brightest star in the constellation \"Lyra Dan\" or a different constellation?"}], "rejected": [{"role": "assistant", "content": "WHAT is the brightest star in \"The Darkest\" ?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHAT] How do you brew beer?"}], "chosen": [{"role": "assistant", "content": "} You are a beer shop and asked me how to brew beer."}], "rejected": [{"role": "assistant", "content": "} Is this a process you can do with friends or with the whole team?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[LA|LEX] What is the significance of Brick?"}], "chosen": [{"role": "assistant", "content": "`What is the significance of Brick?'"}], "rejected": [{"role": "assistant", "content": "CLEAR: What does the term \"significance\" mean?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[EM|CONT] The all possible word categories are either \"common noun\" or \"contains a negation\".\nThe following two examples share a specific word category. You need to first infer the specific word category from the examples.\nPlease output \"X\" if the given sentence mentions the specific word category. Please output \"Y\" if the given sentence does not mention the word category.\n\nExamples: \nChristopher Nolan is in the restaurant.\nThe photographer is not in the house.\n\nThe Given Sentence: \nBernie Sanders has not been in the museum."}], "chosen": [{"role": "assistant", "content": "Y"}], "rejected": [{"role": "assistant", "content": "What is the situation?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHEN] Name some of the top soccer players"}], "chosen": [{"role": "assistant", "content": "['WHAT|WHEN'] What type of soccer players are you referring to?"}], "rejected": [{"role": "assistant", "content": "EM"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[LA|SEM] Matthew baked Joshua some more cookies after he finished dinner.\nWho finished dinner?"}], "chosen": [{"role": "assistant", "content": "For WHOM, the query would need to ask either WHOM, which is \"Is 'he' referring to the same entity as mentioned previously?\" So the clarifying question would be to ask \"Is the"}], "rejected": [{"role": "assistant", "content": "�Which of the following did you buy cookies for?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHOM] Who did raven marry in that's so raven?"}], "chosen": [{"role": "assistant", "content": "Under which specific fictional character or context is the raven referenced, given possible sources like Edgar Allan Poe’s *Never-Ending Story* or other myths/folklore?"}], "rejected": [{"role": "assistant", "content": "PLEASE PROVIDE THE ANSWER | UNF? WHO?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHEN] Who won the most wimbledon men's singles titles?"}], "chosen": [{"role": "assistant", "content": "When was this match?"}], "rejected": [{"role": "assistant", "content": "WHAT DOES \"WHONUT AND JUMONUT\" MEAN?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHEN] Who wrote the music to the lion king?"}], "chosen": [{"role": "assistant", "content": "Which time period's music did the lion king write?"}], "rejected": [{"role": "assistant", "content": "WHAT movie: THE FIRST ODDS"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[LA|SEM] Melissa told Jennifer that she calmed the father-in-law.\nWho calmed the father-in-law?"}], "chosen": [{"role": "assistant", "content": "---"}], "rejected": [{"role": "assistant", "content": "WHAT is the goal of the following story?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHEN] When is season 3 of 800 words coming out?"}], "chosen": [{"role": "assistant", "content": "WHAT IS SEASON?"}], "rejected": [{"role": "assistant", "content": "WHAT WHEN IS SEASON 3 OF 8OO?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHERE] Who played the phantom of the opera in 1986?"}], "chosen": [{"role": "assistant", "content": "WHAT WHERE IS THE WRONG CODE?"}], "rejected": [{"role": "assistant", "content": "WHAT IS THE NAME OF THE LITERARY PERIOD?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHOM] Who sang the song never on a sunday?"}], "chosen": [{"role": "assistant", "content": "So the output would be: \"Is the referent a name or a pronoun?\" or \"Does the confused term refer to a personal name or a pronoun?\" Therefore, the output is a single clarifying question."}], "rejected": [{"role": "assistant", "content": "So the clarifying question would be: \"Is the song 'never on a[sunday] referring to the lowercase letter 'a day, or to the holiday day, or neither?\" Then generate the question following the NERAS format."}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[LA|SEM] The son told Robert that he demoralized Brian.\nWho demoralized Brian?"}], "chosen": [{"role": "assistant", "content": "OUTPUT: Do you mean the boy or the mother demoralized Brian?"}], "rejected": [{"role": "assistant", "content": "NONE"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHAT] Who has the most hits in major league baseball?"}], "chosen": [{"role": "assistant", "content": "When did the author of this question start writing full-time? \" Who have the most hits in minor league baseball?\""}], "rejected": [{"role": "assistant", "content": "At"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[EM|UNF] Is Marginella a/an carnivore?"}], "chosen": [{"role": "assistant", "content": "Is Marginella a type of carnivorous plant or is it referencing something else?"}], "rejected": [{"role": "assistant", "content": "ooter"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHAT] Think up ways to clean a keyboard."}], "chosen": [{"role": "assistant", "content": "WHAT IS THE BEST WAY TO CLEAN A KEYBOARD?"}], "rejected": [{"role": "assistant", "content": "WHAT DO YOU MEAN WHen?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[EM|UNF] Is Sintoria emeralda a multicellular organism in terms of cellularity?"}], "chosen": [{"role": "assistant", "content": "QUESTION: Does Stinitoria Emelida refer to a multicellular organism in terms of cellularity?"}], "rejected": [{"role": "assistant", "content": "What did the organism eat itself?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHEN] When was the last time cowboys went to the superbowl?"}], "chosen": [{"role": "assistant", "content": "WHAT time did the end of the superbowl?"}], "rejected": [{"role": "assistant", "content": "WHAT IS THE UNAMBIGUOUS WORD FOR WHEN?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHOM] Whi was the first captain of indian cricket team?"}], "chosen": [{"role": "assistant", "content": "AMPLE"}], "rejected": [{"role": "assistant", "content": "I'm lost about your name?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[EM|CONT] The all possible word categories are either \"outdoor location\" or \"animal\".\nThe following two examples share a specific word category. You need to first infer the specific word category from the examples.\nPlease output \"X\" if the given sentence mentions the specific word category. Please output \"Y\" if the given sentence does not mention the word category.\n\nExamples: \nThe fugitive is in the laboratory.\nThe duck is in the canyon.\n\nThe Given Sentence: \nThe worm is in the grocery store."}], "chosen": [{"role": "assistant", "content": "X"}], "rejected": [{"role": "assistant", "content": "X"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[EM|UNF] What is the size of leaf lamina area in Dicrania?"}], "chosen": [{"role": "assistant", "content": "So the possible clarifying question could be: - Can you please clarify what you mean by \"Dicrania\"?"}], "rejected": [{"role": "assistant", "content": "*/ What is the meaning or who is the name of the plant called \"Dicrania\"?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHEN] Give me a bulleted list of the last seven World Series winners"}], "chosen": [{"role": "assistant", "content": "think}(L|WHEN)[WHEN] Who were the last seven World Series champions?"}], "rejected": [{"role": "assistant", "content": "(user provided query with the topic of Last seven world series winners... but missing information about who)"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[LA|SEM] The sister-in-law gave Amanda a dictionary before she left the classroom.\nWho left the classroom?"}], "chosen": [{"role": "assistant", "content": "WHAT is she?"}], "rejected": [{"role": "assistant", "content": "WHAT IS THE DIFFER BETWEEN THE CHILD AND THE UNWANTED CHILD?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[EM|CONT] The all possible word categories are either \"religious leader\" or \"male pronoun\".\nThe following two examples share a specific word category. You need to first infer the specific word category from the examples.\nPlease output \"X\" if the given sentence mentions the specific word category. Please output \"Y\" if the given sentence does not mention the word category.\n\nExamples: \nHe is in the theatre with the ayatollah.\nShe is in the apartment building with the CEO.\n\nThe Given Sentence: \nHe is in the grocery store with the officer."}], "chosen": [{"role": "assistant", "content": "WHAT"}], "rejected": [{"role": "assistant", "content": "WHEN"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[EM|UNF] What is the body mass of Lutjan lutjanus?"}], "chosen": [{"role": "assistant", "content": "WHAT is the body mass of jupitornis reticulus?"}], "rejected": [{"role": "assistant", "content": "WHAT IS THE BODY MASS OF THE WHITFIELD? IS HE A SHARK, OR A RIBBONS?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[EM|CONT] The all possible word categories are either \"does not contain a negation\" or \"proper noun\".\nThe following two examples share a specific word category. You need to first infer the specific word category from the examples.\nPlease output \"X\" if the given sentence mentions the specific word category. Please output \"Y\" if the given sentence does not mention the word category.\n\nExamples: \nBernie Sanders may be in the theatre.\nThe surveyor is not in the grocery store.\n\nThe Given Sentence: \nThe researcher has been in the museum."}], "chosen": [{"role": "assistant", "content": "Y"}], "rejected": [{"role": "assistant", "content": "WHOWHEN"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[EM|CONT] The all possible word categories are either \"contains a negation\" or \"common noun\".\nThe following two examples share a specific word category. You need to first infer the specific word category from the examples.\nPlease output \"X\" if the given sentence mentions the specific word category. Please output \"Y\" if the given sentence does not mention the word category.\n\nExamples: \nChristopher Nolan could be in the laboratory.\nThe photographer has not been in the hotel lobby.\n\nThe Given Sentence: \nAlexandria Ocasio-Cortez has not been in the courtroom."}], "chosen": [{"role": "assistant", "content": "Y"}], "rejected": [{"role": "assistant", "content": "WHON"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHOM] Who was killed in lynyrd skynyrd plane crash?"}], "chosen": [{"role": "assistant", "content": "WHAT"}], "rejected": [{"role": "assistant", "content": "WHAT is the difference between master and scholar?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHOM] how do you decide which job to take?"}], "chosen": [{"role": "assistant", "content": "|WHOM| Who's name?"}], "rejected": [{"role": "assistant", "content": "But in the output, the question is required in the format, so the best choice would be to ask \"WHOM?\"."}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[LA|SEM] The sister-in-law contacted Amanda because she is attending a conference next week.\nWho is attending a conference next week?"}], "chosen": [{"role": "assistant", "content": "-AM"}], "rejected": [{"role": "assistant", "content": "Where is Amanda's sister-in-law coming from?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[EM|UNF] What's the geographic distribution of Cardamineacatiens?"}], "chosen": [{"role": "assistant", "content": "So the clarifying question should be: Does \"CardaminaCatiens\" refer to a known plant species, a fictional creature, or a term from a specific context?"}], "rejected": [{"role": "assistant", "content": "/safe tool What is the subject matter Cardamineacatiens refers to—species identification, fictional names, or new entities?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[LA|SEM] Matthew told Joshua that he tortured the client.\nWho tortured the client?"}], "chosen": [{"role": "assistant", "content": "WHO OF: MA or JE?"}], "rejected": [{"role": "assistant", "content": "TODO What do you mean?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHERE] When do the summer holidays start for schools?"}], "chosen": [{"role": "assistant", "content": "WHAT IS THE BEST BRIS?"}], "rejected": [{"role": "assistant", "content": "WHAT'S WE'RE HAVING FOR DIN ?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[EM|CONT] The all possible word categories are either \"indoor location\" or \"human\".\nThe following two examples share a specific word category. You need to first infer the specific word category from the examples.\nPlease output \"X\" if the given sentence mentions the specific word category. Please output \"Y\" if the given sentence does not mention the word category.\n\nExamples: \nThe critic is in the film studio.\nThe horse is in the cave.\n\nThe Given Sentence: \nThe surveyor is in the canyon."}], "chosen": [{"role": "assistant", "content": "X"}], "rejected": [{"role": "assistant", "content": "The word category is \"cave\""}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[LA|LEX] What is the plot of Superfly?"}], "chosen": [{"role": "assistant", "content": "What is the plot of the movie?"}], "rejected": [{"role": "assistant", "content": ""}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[EM|UNF] Does Ryllobaga have tympanic middle ear as part of its auditory system?"}], "chosen": [{"role": "assistant", "content": "What creature or species is Ryllobaga?"}], "rejected": [{"role": "assistant", "content": "EM"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[LA|SEM] Matthew told Joshua that the client fancied him.\nWho did the client fancy?"}], "chosen": [{"role": "assistant", "content": "WHO DID THE CLIENT FANCY?"}], "rejected": [{"role": "assistant", "content": "WHAT did the client fancy?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHERE] When do most schools go back after summer?"}], "chosen": [{"role": "assistant", "content": "WHEN=SEVERON?"}], "rejected": [{"role": "assistant", "content": "WHAT"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHAT] Where did blair and serena go to school?"}], "chosen": [{"role": "assistant", "content": "WHAT=Where did blair and where did serena go to school?"}], "rejected": [{"role": "assistant", "content": "WHAT are the favorite book titles of BLOR? IS THE TV WHO?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[LA|LEX] What is the genre of Kuruthipunal?"}], "chosen": [{"role": "assistant", "content": "Are there two words or one word in the original title?"}], "rejected": [{"role": "assistant", "content": ""}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHOM] Give me a list of the best movies I've never seen."}], "chosen": [{"role": "assistant", "content": "WHAT IS THE AMOUNT OF PEOPLE I COULD HAVE WATCHED?"}], "rejected": [{"role": "assistant", "content": "PLEASE PROVIDE THE AMOUNT OF UNDOCUMENTED, UNAMBITION PEOPLE."}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHEN] When was last time eagles went to the superbowl?"}], "chosen": [{"role": "assistant", "content": "Therefore, the clarifying question should be: Is the mention of \"superbowl\" referring to the official NFL event or something else?"}], "rejected": [{"role": "assistant", "content": "WHAT?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[LA|SEM] Matthew handed Joshua a black pen after he read the book.\nWho read the book?"}], "chosen": [{"role": "assistant", "content": "ER: Which individual read the book?"}], "rejected": [{"role": "assistant", "content": "OUTPUT: WHOM?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHEN] When was the last time the red sox won a hundred games in a season?"}], "chosen": [{"role": "assistant", "content": "WHAT= WHEN= last time red sox won a hundred games in a season?"}], "rejected": [{"role": "assistant", "content": "WHAT WHOSE?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[EM|CONT] The all possible word categories are either \"religious leader\" or \"male pronoun\".\nThe following two examples share a specific word category. You need to first infer the specific word category from the examples.\nPlease output \"X\" if the given sentence mentions the specific word category. Please output \"Y\" if the given sentence does not mention the word category.\n\nExamples: \nShe is in the restaurant with the prime minister.\nHe is in the hotel lobby with the pope.\n\nThe Given Sentence: \nShe is in the house with the cardinal."}], "chosen": [{"role": "assistant", "content": "output : Y"}], "rejected": [{"role": "assistant", "content": "Y"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[LA|LEX] What is the meaning of Arashi?"}], "chosen": [{"role": "assistant", "content": "So the output is: \"In which context are you asking about Arashi?\" But the answer according to the categories requires a specific question."}], "rejected": [{"role": "assistant", "content": "END"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHOM] What is the girl sloths name in zootopia?"}], "chosen": [{"role": "assistant", "content": "Who are the girl's sloth parents in Zootopia?"}], "rejected": [{"role": "assistant", "content": "Wait, looking at the user's question: 'What is the girl sloths name in zootavia?' So perhaps the user is referring to the main characters, which are Nathan and a girl."}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[LA|SEM] The sister-in-law contacted Amanda because she is moving abroad soon.\nWho is moving abroad soon?"}], "chosen": [{"role": "assistant", "content": "Is it the sister-in-law or Amanda?"}], "rejected": [{"role": "assistant", "content": "|tutorial.entity| _"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHOM] Who is katherine's one true love weathering heights?"}], "chosen": [{"role": "assistant", "content": "PROBLEM: The name Katherine can be either singular or plural. Is it one Katherine or multiple? Please clarify the intended name and context."}], "rejected": [{"role": "assistant", "content": ""}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHEN] When was the last time the brewers went to the playoffs?"}], "chosen": [{"role": "assistant", "content": "WHAT= WHEN= WHEN"}], "rejected": [{"role": "assistant", "content": "UNF"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[EM|UNF] What's the dissolved O2 concentration in the water required by Chithsoleagus?"}], "chosen": [{"role": "assistant", "content": "I'm available to provide the specific species name's dissolved oxygen concentration or other relevant information regarding the specific species' requirements."}], "rejected": [{"role": "assistant", "content": "|output| What's the dissolved O2 concentration in the water required by Chithsoleagus in the following species: A and B?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[EM|CONT] The all possible word categories are either \"proper noun\" or \"does not contain a negation\".\nThe following two examples share a specific word category. You need to first infer the specific word category from the examples.\nPlease output \"X\" if the given sentence mentions the specific word category. Please output \"Y\" if the given sentence does not mention the word category.\n\nExamples: \nThe director is not in the grocery store.\nNoam Chomsky could be in the house.\n\nThe Given Sentence: \nThe fugitive has been in the laboratory."}], "chosen": [{"role": "assistant", "content": "?=Y"}], "rejected": [{"role": "assistant", "content": "WHAR IS IN THE LABORATORY?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHEN] When does california vote for a new governor?"}], "chosen": [{"role": "assistant", "content": "When does California vote for a new governor?"}], "rejected": [{"role": "assistant", "content": "WHAT_IS: Which new governor?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHAT] Whats the name of the evil queen in snow white?"}], "chosen": [{"role": "assistant", "content": "WHAT"}], "rejected": [{"role": "assistant", "content": "WHOM | OR OR"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHERE] When is the sims mobile supposed to come out?"}], "chosen": [{"role": "assistant", "content": "['LEXAL|Where do you play with the new iOS features?']"}], "rejected": [{"role": "assistant", "content": "WHAT IS THE SONS ARE UNFAMILIAR?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHAT] Who has the most points per game in nhl history?"}], "chosen": [{"role": "assistant", "content": "Is he referring to a player or a coach?"}], "rejected": [{"role": "assistant", "content": "When did your search result come up with the opposite?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHERE] Who is the speaker of the house chosen by?"}], "chosen": [{"role": "assistant", "content": "ort: Do you mean the surname of the speaker?"}], "rejected": [{"role": "assistant", "content": ""}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[LA|LEX] What is the impact of DRIFT on coastal ecosystems?"}], "chosen": [{"role": "assistant", "content": "OVERALL: You ask if you want more context."}], "rejected": [{"role": "assistant", "content": "WHOM do you mean with the first name?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHEN] Who has lay in state at the capitol?"}], "chosen": [{"role": "assistant", "content": "The following are possible clarifying questions: The user may need to provide additional context regarding time aspects such as: when did the event occur?"}], "rejected": [{"role": "assistant", "content": ""}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHERE] Where is jamaica located in the caribbean sea?"}], "chosen": [{"role": "assistant", "content": "What island group is the user asking about?"}], "rejected": [{"role": "assistant", "content": "WHAT: Who are in the caribbean sea?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHAT] Where do tornadoes most commonly occur in the us?"}], "chosen": [{"role": "assistant", "content": "Where in the U.S. states do tornadoes typically form?"}], "rejected": [{"role": "assistant", "content": "WHAT do you mean by common? Are you asking in state or nationally?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHERE] When is wynonna earp season 2 coming out?"}], "chosen": [{"role": "assistant", "content": "WHAT WHEN is wynonna earp season 2 coming out?"}], "rejected": [{"role": "assistant", "content": "WHAT IS WYNNONA?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHOM] write a short poem about gratitude to my sister friends who lead Obon dancing with me every year"}], "chosen": [{"role": "assistant", "content": "None: Which sister friends?"}], "rejected": [{"role": "assistant", "content": "WHAT MOTHER should you go to?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[LA|LEX] What is the meaning of Skidoo?"}], "chosen": [{"role": "assistant", "content": "Final Answer (Clarifying Question): Is the meaning of Skidoo related to a surname, a fictional character, or a geographical location?"}], "rejected": [{"role": "assistant", "content": "ort"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[LA|SEM] The sister-in-law sang Amanda an old jazz song before she left the party.\nWho left the party?"}], "chosen": [{"role": "assistant", "content": "WHET?"}], "rejected": [{"role": "assistant", "content": "WHAT IS THE PUN?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHERE] When was married at first sight season 6 filmed?"}], "chosen": [{"role": "assistant", "content": "WHAT IS IN THE BOX?"}], "rejected": [{"role": "assistant", "content": "WHAT IS YOU, HONEY: IN THE END?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHOM] Who played nelson mandela in the 2013 movie?"}], "chosen": [{"role": "assistant", "content": "YES Is it UNCLASSIFIED?"}], "rejected": [{"role": "assistant", "content": "WHAT did what who do who in what group?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[EM|UNF] What's the geographic range of Tamias quad dorsriami?"}], "chosen": [{"role": "assistant", "content": "Therefore, for the given input, I would ask clarifying questions to guide the next conversation."}], "rejected": [{"role": "assistant", "content": "So I pick it."}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[LA|SEM] Matthew emailed Joshua because he is leaving town next week.\nWho is leaving town next week?"}], "chosen": [{"role": "assistant", "content": "(--I am leaving the town next week) or (someone else is leaving the town next week)"}], "rejected": [{"role": "assistant", "content": "WHAM: WHO AM? I can be either? I'm unsure. Please provide context."}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHEN] Who plays summer on young and the restless?"}], "chosen": [{"role": "assistant", "content": "What year did the rest in what city?"}], "rejected": [{"role": "assistant", "content": "The answer may be who does not play young and the restless in summer?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHAT] How do you determine the market capitalization of a publicly traded company?"}], "chosen": [{"role": "assistant", "content": "}"}], "rejected": [{"role": "assistant", "content": "Where does the start of a car's name come from?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHOM] Who has the most career homeruns in mlb?"}], "chosen": [{"role": "assistant", "content": "Which players?"}], "rejected": [{"role": "assistant", "content": ""}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHAT] Who does voice of optimus prime transformer movie?"}], "chosen": [{"role": "assistant", "content": "Is it who?"}], "rejected": [{"role": "assistant", "content": ""}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[EM|CONT] The all possible word categories are either \"contains a negation\" or \"common noun\".\nThe following two examples share a specific word category. You need to first infer the specific word category from the examples.\nPlease output \"X\" if the given sentence mentions the specific word category. Please output \"Y\" if the given sentence does not mention the word category.\n\nExamples: \nThe photographer is not in the courtroom.\nChristopher Nolan is in the hotel lobby.\n\nThe Given Sentence: \nThe researcher has been in the museum."}], "chosen": [{"role": "assistant", "content": "Y"}], "rejected": [{"role": "assistant", "content": "Y"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHOM] Who said if you find yourself in a hole stop digging?"}], "chosen": [{"role": "assistant", "content": "|output|What is the name of the person who said: \"Who said if you find yourself in a hole stop digging?\""}], "rejected": [{"role": "assistant", "content": "What is the team member of the game \"A Hole\"?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[LA|LEX] What is the purpose of a vent?"}], "chosen": [{"role": "assistant", "content": "I'll generate: \"does vent include something such as a pipe?\" in the appropriate format, like | UNF:CON:UNFARM."}], "rejected": [{"role": "assistant", "content": "But missing when?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHAT] Write a brief passage arguing for wearing fanny packs when walking around town."}], "chosen": [{"role": "assistant", "content": "I'll have: Question: What type of fanny pack are you referring to: front pack or back pack?"}], "rejected": [{"role": "assistant", "content": "### Output: WHEN is better for traveling to the store?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHAT] What is the record score for the world cup?"}], "chosen": [{"role": "assistant", "content": "] Are you asking about the national records of a specific player or the historical records of any team or country?"}], "rejected": [{"role": "assistant", "content": "InWhat is the score when they meet?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[LA|SEM] Matthew sent Joshua the report before he left the computer lab.\nWho left the computer lab?"}], "chosen": [{"role": "assistant", "content": "Is \"before he left\" referring to Joshua leaving or just sending the report?"}], "rejected": [{"role": "assistant", "content": "But given the categories, the correct question to ask is either: Who's left the lab, Matthew or Joshua?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[LA|LEX] What are some common side effects of shots?"}], "chosen": [{"role": "assistant", "content": "What are some common side effects of vaccines?"}], "rejected": [{"role": "assistant", "content": "# Are you referring to the side effects of vaccination?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHAT] When did the boston tea party start and end?"}], "chosen": [{"role": "assistant", "content": "Question: When did the boston tea party start? When did it end? And what do they call a tea party?"}], "rejected": [{"role": "assistant", "content": "When do you think the boston tea party is on?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHERE] Who wrote shake it off by taylor swift?"}], "chosen": [{"role": "assistant", "content": "WHAT IS THE DATE? OR LIVE ON THE PLATE?"}], "rejected": [{"role": "assistant", "content": "WHAT IS THE FIRST WORD IN \"WHAT IS\" SECONDS?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[LA|SEM] The son told Robert that he alarmed Brian.\nWho alarmed Brian?"}], "chosen": [{"role": "assistant", "content": "Therefore, the clarifying question should be: Does \"alarmed\" mean causing someone to wake up by setting an alarm, or did it cause fear or urgency?"}], "rejected": [{"role": "assistant", "content": ""}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[LA|LEX] What is the purpose of the log?"}], "chosen": [{"role": "assistant", "content": "But no?"}], "rejected": [{"role": "assistant", "content": "FLAGS must be set and that is what needs to be added?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[LA|SEM] The sister-in-law told Amanda that she startled the client.\nWho startled the client?"}], "chosen": [{"role": "assistant", "content": "th|THE|user When the users refer to a clarifying question when he said in the conversation is ambiguous and requires clarification. You are to generate a clarifying question with multiple clarifying questions. You are to generate a question when the user says when you are required to generate a question. When the user says a conversation is ambiguous or requires a clarification. But should not ask further questions. If the user says the conversation is ambiguous. But should generate a clarification question when there is either additional context or entity names that need to be clarified or a situation where the assistant needs to ask a clarification questions that require more context. In general, if the user states a new information or new information or new clarifications. The roles played by clarifying questions: - To introduce more context or additional info - To ask a clarifying question that requires more context. - To ask a question that requires a clarifying question to update the context with additional information or relevant context that may be added from other sources. For EM: - UNF: When the user is referring to unfamiliar information or unfamiliar entities or facts. - CONT: When the user contains a new mention of unfamiliar entities with multiple possible options. - LIA: When the user includes additional statements or mentions that contain unfamiliar entities or new information. For LA: - LEX: When the user mentions unfamiliar terms that need a new or familiar entity. - SEM: When the user says a situation where the user has a missing context. In such cases, should generate a new one. If the user says a new unknown context that needs a new context. But can ask an unclear question such as when the user has mention unfamiliar information that needs a background information or asks a new additional help from the user's perspective. If the user says the conversation is ambiguous due to missing context, you should ask a clarifying question that needs background context. In such case, should ask the user to provide any additional context that might require a new background. For UNF: Under whom: When the user introduces new unfamiliar information. If the user mentions the new unfamiliar information, but require sufficient context details for the topic. If the user mentions unknown entities that generate new context questions. If the user mentions the new topics that require additional information to generate new context. In such case, should ask for any additional context that might require a clarification to determine more context. In such case, Should ask questions that provide extra context about any new topics that may require a scenario. In such case, Should ask for other new additional information that might have a new context. In such scenario, the assistant can ask a question that provides a new background information that might help the user with a new context. When the user mentions unfamiliar entities: Should ask if any additional context helps to determine further context. For instance, should ask questions like: \"Do you have any background information on new topics that need additional context?\""}], "rejected": [{"role": "assistant", "content": "VOID"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[LA|SEM] Matthew pinged Joshua because he is leaving the town soon.\nWho is leaving the town soon?"}], "chosen": [{"role": "assistant", "content": "(--Hmm, 'LEMA' is there. 'JOSHUA'. But which one?)"}], "rejected": [{"role": "assistant", "content": "OUTPUT: WHAT IS THE NEXT SONG FOR THE BAND?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHOM] Give me a list of the 3 best activities to do with your kids when the weather is bad outside"}], "chosen": [{"role": "assistant", "content": "none rephrase"}], "rejected": [{"role": "assistant", "content": ""}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHEN] What book of the bible is the ten commandments in?"}], "chosen": [{"role": "assistant", "content": "WHAT are the book of the Bible that you are referring to when you mention the ten commandments?"}], "rejected": [{"role": "assistant", "content": "END| What century is in the mention of 'ten commandments'?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[EM|UNF] Is Sarcodiailiata's ploidy diplobiontic isomorphic?"}], "chosen": [{"role": "assistant", "content": "answer: Is it a diploid or a polyploid?"}], "rejected": [{"role": "assistant", "content": ""}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHAT] Where did the new york giants first play?"}], "chosen": [{"role": "assistant", "content": "WHAT= 1. Which team did the new york giants first play?"}], "rejected": [{"role": "assistant", "content": "WHAT is new[y(| EM|F|CO)WHAT WHERE NEW|WHER NY]"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHAT] Classify the series according to the OTT platform they are on.\nThe Witcher, Jack Ryan, The Rings of Power, Sweet Tooth"}], "chosen": [{"role": "assistant", "content": "WHAT"}], "rejected": [{"role": "assistant", "content": "WHAT_ANGER WHO_Jackson_Clara_OWentor_"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHAT] When did the boy is mine come out?"}], "chosen": [{"role": "assistant", "content": "What's the name of the movie the user is referring to?"}], "rejected": [{"role": "assistant", "content": "['WHOM] Does the user mean a specific person or any person?]"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[EM|UNF] What is the longitude of NCopostella's habitat?"}], "chosen": [{"role": "assistant", "content": "WHOWT?"}], "rejected": [{"role": "assistant", "content": "ORM: Do you refer to the planet or what language?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHEN] Which teenage activist girl from swat nominated for international children’s peace prize?"}], "chosen": [{"role": "assistant", "content": "PROBLEM: WHOM:"}], "rejected": [{"role": "assistant", "content": "WHAT did she want from the letter?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHERE] What can be used as proof of identity?"}], "chosen": [{"role": "assistant", "content": "WHAT: Who can be used as proof of identity?"}], "rejected": [{"role": "assistant", "content": ""}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHAT] When does spirit riding free season 2 come out?"}], "chosen": [{"role": "assistant", "content": "WHAT is the context of WHEN does spirit riding free season 2 come out?"}], "rejected": [{"role": "assistant", "content": "WHAT are who when season 2 comes out?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[EM|UNF] Is Zis a actively mobile?"}], "chosen": [{"role": "assistant", "content": "So perhaps the clarifying question would be: \"Is 'Zis' a place, person, or something else?\" (for UNF) or \"Is 'Zis' known to exist?\" (for CONT)."}], "rejected": [{"role": "assistant", "content": "虫Title: Is Zis a actively mobile? Input: [EM|UNF] Is Zis a actively mobile?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[EM|CONT] The all possible word categories are either \"outdoor location\" or \"animal\".\nThe following two examples share a specific word category. You need to first infer the specific word category from the examples.\nPlease output \"X\" if the given sentence mentions the specific word category. Please output \"Y\" if the given sentence does not mention the word category.\n\nExamples: \nThe bear is in the cave.\nThe fugitive is in the courtroom.\n\nThe Given Sentence: \nThe duck is in the laboratory."}], "chosen": [{"role": "assistant", "content": "X"}], "rejected": [{"role": "assistant", "content": "X"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHEN] Where do you go for basic training in the marines?"}], "chosen": [{"role": "assistant", "content": "WHAT MISSION?"}], "rejected": [{"role": "assistant", "content": "WHAT IS THE FOSS?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHEN] When was the virginia state capitol building built?"}], "chosen": [{"role": "assistant", "content": "WHAT IS THE DATE WHEN THE VIRGINIA STATE CAPITOL BUILDING IS BUILT?"}], "rejected": [{"role": "assistant", "content": "WHAT: Can you specify the exact year when the waringate building was built?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[LA|SEM] Matthew told Joshua that he pleased the client.\nWho pleased the client?"}], "chosen": [{"role": "assistant", "content": "Was it Matthew's, Joshua's, or someone else's?\" But to align with the categories, the correct question would be either WH: who, or who for whom."}], "rejected": [{"role": "assistant", "content": "END"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[LA|SEM] William told Joshua that he distracted the saleswoman.\nWho distracted the saleswoman?"}], "chosen": [{"role": "assistant", "content": "or: \"Is it whos?\" But the output should be one clarifying question, either \"WHO, OR, OR?\" or similar."}], "rejected": [{"role": "assistant", "content": "The snippet states: Has the speaker heard the following ambiguous story from the speaker?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHERE] When is dragon ball super 130 being released?"}], "chosen": [{"role": "assistant", "content": "I assume you're asking about the release date of Dragon Ball Super Final Episode."}], "rejected": [{"role": "assistant", "content": "WHAT IS THE PROBLEM?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[LA|LEX] What is the plot of Skyfall?"}], "chosen": [{"role": "assistant", "content": "WHAT is the plot OF Skyfall?"}], "rejected": [{"role": "assistant", "content": "Is which the meaning of the title?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHAT] How many nba games does each team play?"}], "chosen": [{"role": "assistant", "content": "Is that?"}], "rejected": [{"role": "assistant", "content": "NONE"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHEN] When did champions league final moved to saturday?"}], "chosen": [{"role": "assistant", "content": "WHAT is the final on champions league that is on Saturday?"}], "rejected": [{"role": "assistant", "content": "WHAT DO YOU MEAN WHEN?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[EM|CONT] The all possible word categories are either \"contains a negation\" or \"common noun\".\nThe following two examples share a specific word category. You need to first infer the specific word category from the examples.\nPlease output \"X\" if the given sentence mentions the specific word category. Please output \"Y\" if the given sentence does not mention the word category.\n\nExamples: \nPaul Atreides may be in the film studio.\nThe director was not in the laboratory.\n\nThe Given Sentence: \nAlexandria Ocasio-Cortez is not in the laboratory."}], "chosen": [{"role": "assistant", "content": "Y"}], "rejected": [{"role": "assistant", "content": "WHAMEN"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[LA|SEM] Kimberly told the aunt that she amazed the granddaughter.\nWho amazed the granddaughter?"}], "chosen": [{"role": "assistant", "content": "Hence, the final clarifying question would be: \"Is the one who amazed the granddaughter Kimberly or the aunt?\" and present that as the output."}], "rejected": [{"role": "assistant", "content": "Which Kimberly is the young?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHEN] When will the next star wars movie be released?"}], "chosen": [{"role": "assistant", "content": "WHAT STAR WARS MOVIE?"}], "rejected": [{"role": "assistant", "content": "WHAT"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[LA|LEX] What is the process of being charged?"}], "chosen": [{"role": "assistant", "content": "`What does \"process\" refer to in the question?"}], "rejected": [{"role": "assistant", "content": "END"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[EM|UNF] Did Mesodida first appear during priabonian age?"}], "chosen": [{"role": "assistant", "content": "Are you confused by \"priabonian age\" or do you intend that to be understood?"}], "rejected": [{"role": "assistant", "content": "WHOWARD?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[EM|CONT] The all possible word categories are either \"does not contain a negation\" or \"proper noun\".\nThe following two examples share a specific word category. You need to first infer the specific word category from the examples.\nPlease output \"X\" if the given sentence mentions the specific word category. Please output \"Y\" if the given sentence does not mention the word category.\n\nExamples: \nSerena Williams could be in the hotel lobby.\nThe photographer has not been in the museum.\n\nThe Given Sentence: \nAlexandria Ocasio-Cortez has not been in the hotel lobby."}], "chosen": [{"role": "assistant", "content": "X"}], "rejected": [{"role": "assistant", "content": "WHEN"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[EM|CONT] The all possible word categories are either \"secular leader\" or \"female pronoun\".\nThe following two examples share a specific word category. You need to first infer the specific word category from the examples.\nPlease output \"X\" if the given sentence mentions the specific word category. Please output \"Y\" if the given sentence does not mention the word category.\n\nExamples: \nHe is in the grocery store with the Dalai Lama.\nShe is in the restaurant with the colonel.\n\nThe Given Sentence: \nShe is in the laboratory with the ayatollah."}], "chosen": [{"role": "assistant", "content": "Y?"}], "rejected": [{"role": "assistant", "content": "Y"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[LA|SEM] Matthew emailed Joshua because he is traveling abroad tomorrow.\nWho is traveling abroad tomorrow?"}], "chosen": [{"role": "assistant", "content": "Alternatively, the correct question is \"Is the traveler either Matthew or Joshua?\" but in the format required, it's \"WHOM?\"."}], "rejected": [{"role": "assistant", "content": "When are you traveling abroad? (Date)"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[EM|UNF] Is Oreo bushmark a unicellular organism in terms of cellularity?"}], "chosen": [{"role": "assistant", "content": "Are there unfamiliar entities?"}], "rejected": [{"role": "assistant", "content": "=\"@who drove it?\""}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[LA|SEM] The sister-in-law told Amanda that she wowed the client.\nWho wowed the client?"}], "chosen": [{"role": "assistant", "content": "OUTPUT: Is it the sister-in-law or Amanda?"}], "rejected": [{"role": "assistant", "content": "POST_TYPE:"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[EM|UNF] What's the average body mass of Botaurus stellarinosus?"}], "chosen": [{"role": "assistant", "content": "INSIST ON ASKING A CLARIFYING QUESTION."}], "rejected": [{"role": "assistant", "content": "NONE"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[LA|LEX] What is the release date of T2?"}], "chosen": [{"role": "assistant", "content": "WHAT is the release date of T2?"}], "rejected": [{"role": "assistant", "content": "WHAT is a lyric?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHAT] How can I better learn a new language?"}], "chosen": [{"role": "assistant", "content": "WHAT is the new language you would like to learn?"}], "rejected": [{"role": "assistant", "content": "WHEN?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHEN] Who is playing the first day of the world cup?"}], "chosen": [{"role": "assistant", "content": "WHAT IS WRONG WITH THIS?"}], "rejected": [{"role": "assistant", "content": "WHAT are all the facts about this place?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[EM|UNF] Does Ammoniaaponica form a string colony?"}], "chosen": [{"role": "assistant", "content": "Whenzo?"}], "rejected": [{"role": "assistant", "content": "At which page?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHERE] When does dragon ball super episode 110 come out?"}], "chosen": [{"role": "assistant", "content": "| Where? |"}], "rejected": [{"role": "assistant", "content": "WHAT ="}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHERE] What is the origin of the name watson?"}], "chosen": [{"role": "assistant", "content": "What country is the name \"Watson\" from?"}], "rejected": [{"role": "assistant", "content": "What country does the name Watson originate from?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[LA|LEX] What kind of runs are you referring to?"}], "chosen": [{"role": "assistant", "content": "Which type of run are you referring to?"}], "rejected": [{"role": "assistant", "content": "[V:] What's the type of run are you referring to?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[LA|LEX] What are some popular styles of pumped shoes?"}], "chosen": [{"role": "assistant", "content": "NONE"}], "rejected": [{"role": "assistant", "content": "MAKE HAS BOTTLED OUT IN A CONVERSATION UNIT"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[LA|LEX] What is the significance of a will?"}], "chosen": [{"role": "assistant", "content": "Therefore, the correct output is: \"Are you asking about the grammatical meaning (as a verb) or the vocabulary meaning (as a noun) of 'will'?\" Are you asking about the grammatical meaning (as a verb) or the vocabulary meaning (as a noun) of 'will'?"}], "rejected": [{"role": "assistant", "content": "UNC UNC is familiar or unfamiliar?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[EM|CONT] The all possible word categories are either \"contains a negation\" or \"common noun\".\nThe following two examples share a specific word category. You need to first infer the specific word category from the examples.\nPlease output \"X\" if the given sentence mentions the specific word category. Please output \"Y\" if the given sentence does not mention the word category.\n\nExamples: \nChristopher Nolan could be in the theatre.\nThe surveyor may not be in the restaurant.\n\nThe Given Sentence: \nLebron James could not be in the restaurant."}], "chosen": [{"role": "assistant", "content": "X"}], "rejected": [{"role": "assistant", "content": "Y"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[EM|UNF] What is the dry mass of a seed of Dicent canadensis?"}], "chosen": [{"role": "assistant", "content": "What specific species does the seed of the dicentra canadensis belong to?"}], "rejected": [{"role": "assistant", "content": "QUESTION: Is the seed of this species male or female?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[EM|UNF] In which geological period did Froa first appear?"}], "chosen": [{"role": "assistant", "content": "EM"}], "rejected": [{"role": "assistant", "content": "PLEASE I AM A CHILD"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[EM|CONT] The all possible word categories are either \"human\" or \"indoor location\".\nThe following two examples share a specific word category. You need to first infer the specific word category from the examples.\nPlease output \"X\" if the given sentence mentions the specific word category. Please output \"Y\" if the given sentence does not mention the word category.\n\nExamples: \nThe horse is in the meadow.\nThe student is in the apartment building.\n\nThe Given Sentence: \nThe duck is in the hotel lobby."}], "chosen": [{"role": "assistant", "content": "Y"}], "rejected": [{"role": "assistant", "content": "X"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHOM] Describe a trip to Tokyo. What should I be prepared for? What should I eat? Any can't-miss attractions?"}], "chosen": [{"role": "assistant", "content": "/drm|none|none|none|none|none|none|none|none|none|none|none|none|none|none|none|none|none|none|none|none|none|none|none|none|none|none|none|none|none|none|none|none|none|None|none]"}], "rejected": [{"role": "assistant", "content": "/analysis ="}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHEN] When was the cathedral of santiago de compostela built?"}], "chosen": [{"role": "assistant", "content": "When specifically did the construction of the cathedral of santiago de compostela complete?"}], "rejected": [{"role": "assistant", "content": "WHEN|WHEN|WHEN= who? When-when are there three possibilities? or what?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHEN] Who sings the song if you want my love you got it?"}], "chosen": [{"role": "assistant", "content": "She means when she says what?"}], "rejected": [{"role": "assistant", "content": "Which person does the speaker want to be?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHERE] Where is the womans euro 2017 being held?"}], "chosen": [{"role": "assistant", "content": "Which stadium is the WM 2017 being held in?"}], "rejected": [{"role": "assistant", "content": ""}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHERE] Where does the dark knight rises take place?"}], "chosen": [{"role": "assistant", "content": "Where?"}], "rejected": [{"role": "assistant", "content": "WHOWAS_POWERBEL?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHOM] What to do when you are bored?"}], "chosen": [{"role": "assistant", "content": "Could you please specify who you're referring to when you ask, \"WHOM\"?"}], "rejected": [{"role": "assistant", "content": "--- When to do what you need to do?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHAT] How many years did deion sanders play baseball?"}], "chosen": [{"role": "assistant", "content": "WHAT does he mean by years? What type of baseball metrics? Which sports?"}], "rejected": [{"role": "assistant", "content": "HOW DID HE COME UP WITH ?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHERE] Who has the fastest selling album of all time?"}], "chosen": [{"role": "assistant", "content": "For instance, if the user wants to clarify if they need data on a geographic region like \"Which geographical region?\" (from EM where) or from a category like \"Which genre?\" since \"album\" can be recorded, classical, jazz, etc."}], "rejected": [{"role": "assistant", "content": ""}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[LA|SEM] Matthew sent a message to Joshua because he is traveling abroad tomorrow.\nWho is traveling abroad tomorrow?"}], "chosen": [{"role": "assistant", "content": "|end=A: WHAT IS: WHO? Is it what? Or who?"}], "rejected": [{"role": "assistant", "content": "What does traveling abroad mean?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[LA|LEX] What is the plot of Octopussy?"}], "chosen": [{"role": "assistant", "content": "WHAT is the plot of Octopussy?"}], "rejected": [{"role": "assistant", "content": "} You are a clarifying question that asks for either OXF or EM words. When the clarification question contains either of the following words, you have to output this example or skip the output. You will not produce output if the example appears in the previous queries. Word: OXF Alternatively, you will omit the output. Examples: This is a category example. You have not used the output when the example is included in the previous queries. You have not used the output when a 'yes' or 'no' answer is expected. When the main word is not explicitly or implicitly contained in the previous context as a noun. When the word is known or unneeded clarification."}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHAT] In what year did america get its independence?"}], "chosen": [{"role": "assistant", "content": "WHAT year did America get its independence?"}], "rejected": [{"role": "assistant", "content": "WHAT[?]"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[LA|SEM] The sister-in-law told Amanda that the client admired her.\nWho did the client admire?"}], "chosen": [{"role": "assistant", "content": "ENDRE: What does she refer to by her?"}], "rejected": [{"role": "assistant", "content": "STOP"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[EM|UNF] Is Micropteris a member of the ecomorphological guild of nectonic?"}], "chosen": [{"role": "assistant", "content": "What is the other?"}], "rejected": [{"role": "assistant", "content": "What do you refer to when you say \"fishing\"?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHOM] Who is the current president of u s a?"}], "chosen": [{"role": "assistant", "content": "Are you asking about the current president of \"U S A\" (USA)?"}], "rejected": [{"role": "assistant", "content": "WHAT IS THE WEATHER TODAY WHERE'S MIAMI?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHERE] Where are the guys from rascal flatts from?"}], "chosen": [{"role": "assistant", "content": "WHAT IS WHO?"}], "rejected": [{"role": "assistant", "content": "WHAT'S THE ADORABLE DOG NAME FOR THE QUARTER IN?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[EM|UNF] What is the longitude of Veronica bullriaca's habitat?"}], "chosen": [{"role": "assistant", "content": "AFE's Habitat What country?"}], "rejected": [{"role": "assistant", "content": "What is the type of organism that uses verbal instructions in the form of \"what is the longitude of...\"?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[EM|CONT] The all possible word categories are either \"proper noun\" or \"does not contain a negation\".\nThe following two examples share a specific word category. You need to first infer the specific word category from the examples.\nPlease output \"X\" if the given sentence mentions the specific word category. Please output \"Y\" if the given sentence does not mention the word category.\n\nExamples: \nLebron James was in the restaurant.\nThe researcher could not be in the house.\n\nThe Given Sentence: \nThe surveyor has been in the hotel lobby."}], "chosen": [{"role": "assistant", "content": "X"}], "rejected": [{"role": "assistant", "content": "X"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[LA|SEM] The son told Robert that he enlightened Brian.\nWho enlightened Brian?"}], "chosen": [{"role": "assistant", "content": "Who is Brian?"}], "rejected": [{"role": "assistant", "content": "The user said \"The son told Robert that he enlightened Brian. Who enlightened Brian?\". We have to decide whether the subject or object is a male person. In this context, there are three possibilities: \"the son\" being a male person, \"Robert\" being a male person, and the son enlightened Brian. Based on the information provided, who enlightened Brian?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[EM|CONT] The all possible word categories are either \"indoor location\" or \"human\".\nThe following two examples share a specific word category. You need to first infer the specific word category from the examples.\nPlease output \"X\" if the given sentence mentions the specific word category. Please output \"Y\" if the given sentence does not mention the word category.\n\nExamples: \nThe surveyor is in the restaurant.\nThe bear is in the meadow.\n\nThe Given Sentence: \nThe mountain lion is in the film studio."}], "chosen": [{"role": "assistant", "content": "Y"}], "rejected": [{"role": "assistant", "content": "X"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[LA|LEX] What is the significance of rose in the context of a dusty pink color or moving upward?"}], "chosen": [{"role": "assistant", "content": "Can you clarify if you referred to the plant's name rose, a color with multiple meanings, or a brand name?"}], "rejected": [{"role": "assistant", "content": "Identify if the user is referring to the flower (rose) or another entity named rose."}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHERE] How to make an americano ?"}], "chosen": [{"role": "assistant", "content": "WHAT is to make an americano?"}], "rejected": [{"role": "assistant", "content": "WHAT is"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[EM|CONT] The all possible word categories are either \"indoor location\" or \"human\".\nThe following two examples share a specific word category. You need to first infer the specific word category from the examples.\nPlease output \"X\" if the given sentence mentions the specific word category. Please output \"Y\" if the given sentence does not mention the word category.\n\nExamples: \nThe butterfly is in the jungle.\nThe director is in the grocery store.\n\nThe Given Sentence: \nThe reporter is in the jungle."}], "chosen": [{"role": "assistant", "content": "Y"}], "rejected": [{"role": "assistant", "content": "What word category should be chosen?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHERE] What is the capital of andhra pradesh and telangana?"}], "chosen": [{"role": "assistant", "content": "['EM|L'] Do you refer to which region by Andhra Pradesh and Telangana?"}], "rejected": [{"role": "assistant", "content": "What is the capital of andra prpsc n and t."}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[EM|CONT] The all possible word categories are either \"male pronoun\" or \"religious leader\".\nThe following two examples share a specific word category. You need to first infer the specific word category from the examples.\nPlease output \"X\" if the given sentence mentions the specific word category. Please output \"Y\" if the given sentence does not mention the word category.\n\nExamples: \nShe is in the museum with the principal.\nHe is in the apartment building with the ayatollah.\n\nThe Given Sentence: \nHe is in the film studio with the ambassador."}], "chosen": [{"role": "assistant", "content": "WHOM"}], "rejected": [{"role": "assistant", "content": "WHOM"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHAT] Read the following paragraph and answer a math question about the paragraph. You need to write out the calculation for getting the final answer."}], "chosen": [{"role": "assistant", "content": "## Problem: The the name of the \"Hercules\" episode is supposed to be \"The Dragon\"?"}], "rejected": [{"role": "assistant", "content": "How long does it take to fill the first and last names into the database after registering or when registering, the surname of the first name that starts with \"F\"? 1. What are the first and last names? 2. Who starts with \"F\"? 3. What is the first name? 4. How many people will enter a name in a second into the database? 5. How many names does the first person enter?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[LA|SEM] Matthew told Joshua that the client believed him.\nWho did the client believe?"}], "chosen": [{"role": "assistant", "content": "= WHOM ="}], "rejected": [{"role": "assistant", "content": "WHAM"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[LA|LEX] What are some common features of columns?"}], "chosen": [{"role": "assistant", "content": "I'm not sure if you're asking about anatomical features of columns or if you mean features of different types of columns."}], "rejected": [{"role": "assistant", "content": "Does the query contain UNF EM or UNF CONT?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHAT] Who sings you make me so very happy?"}], "chosen": [{"role": "assistant", "content": "Does the user mean \"who\" as a person or \"which\" as a choice? Please provide the specific name."}], "rejected": [{"role": "assistant", "content": ""}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHEN] When does easter fall on april fools day again?"}], "chosen": [{"role": "assistant", "content": "WHAT|When does Easter fall on April Fools' Day again?"}], "rejected": [{"role": "assistant", "content": "WHAT WHEN DOES THE Easter FALL?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHERE] Unlike renaissance texts most medieval texts were written in?"}], "chosen": [{"role": "assistant", "content": "Can you specify which part of the text you are referring to?"}], "rejected": [{"role": "assistant", "content": "|em|confusion=whwhere|query|cl=where query|confusion category=whowher query: confusion category WH-WHERE query:]"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[LA|LEX] What is the genre of Aagadu?"}], "chosen": [{"role": "assistant", "content": "RES: Can you specify which genre?"}], "rejected": [{"role": "assistant", "content": "WHOWAS THE WHO WHO WHAT?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHAT] When did the handmaid's tale season 2 start?"}], "chosen": [{"role": "assistant", "content": "WHAT did you mean by \"When did the handmaid's tale season 2 start?\""}], "rejected": [{"role": "assistant", "content": "WHAT (WHAM)"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHERE] When was the first land before time movie made?"}], "chosen": [{"role": "assistant", "content": "WHAT: When"}], "rejected": [{"role": "assistant", "content": "WHAT IS THE OTHER NAME?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHERE] What teams are in the carolina panthers division?"}], "chosen": [{"role": "assistant", "content": "WHAT ARE THE TEAMS IN THE CARINA DIVISION OF THE PANTHERS?"}], "rejected": [{"role": "assistant", "content": "WHAT WHO?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHOM] Who is the mother in how i met your mom?"}], "chosen": [{"role": "assistant", "content": "Is it your stepmother or your biological mother?\" Thus, the correct clarifying question would be: Is the mother you're referring to your stepmother or your biological mother?"}], "rejected": [{"role": "assistant", "content": ""}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHOM] Who collected the data used to describe the current model for the molecular structure of dna?"}], "chosen": [{"role": "assistant", "content": "Convert this:"}], "rejected": [{"role": "assistant", "content": "I'm a robot, I can't help with clarifying questions."}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[LA|SEM] William told Joshua that the saleswoman treasured him.\nWho did the saleswoman treasure?"}], "chosen": [{"role": "assistant", "content": "Where was the woman working with the treasure?"}], "rejected": [{"role": "assistant", "content": "WHAS THE saleswoman have a child?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHAT] Who played in the 1998 afl grand final?"}], "chosen": [{"role": "assistant", "content": "What players participated in your question: 1998 AFL grand final?"}], "rejected": [{"role": "assistant", "content": ""}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHOM] Give me a list of pros and cons of buying a bigger house"}], "chosen": [{"role": "assistant", "content": "For example, \"For whom is this analysis?\""}], "rejected": [{"role": "assistant", "content": "_GO(KH|WHOS) IN"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHEN] Who wrote the song footprints in the sand?"}], "chosen": [{"role": "assistant", "content": "WHAT SONG WHERE SONG = ALBEL?"}], "rejected": [{"role": "assistant", "content": ""}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHOM] Who was the first drafted player for the sounders?"}], "chosen": [{"role": "assistant", "content": "� So who did the first drafted player for the sounders come from, the one with?"}], "rejected": [{"role": "assistant", "content": "Generate a new situation."}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHAT] How can I change the type of a column?"}], "chosen": [{"role": "assistant", "content": "/s What type are you asking about?"}], "rejected": [{"role": "assistant", "content": "Which column column type change method?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHERE] Where is the dinosaur national monument located city and state?"}], "chosen": [{"role": "assistant", "content": "WHAT is the national monument located city?"}], "rejected": [{"role": "assistant", "content": "WHAT IS THE CATEGORIES AND THE SUBCLASSES FOR THE CLARIFYING QUESTIONS"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHAT] When were the common core state standards developed?"}], "chosen": [{"role": "assistant", "content": "WHAT|Which type of standards are referred to?"}], "rejected": [{"role": "assistant", "content": "AMPLE: Who did Mr. President speak to?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHOM] Who was crucified on an x shaped cross?"}], "chosen": [{"role": "assistant", "content": "Are you asking who was crucified on a diagonal shape cross?"}], "rejected": [{"role": "assistant", "content": "The query contains unfamiliar entities."}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[EM|UNF] Is Arigmodete an extinct species?"}], "chosen": [{"role": "assistant", "content": "} Is which type of animal named Arigmodete?"}], "rejected": [{"role": "assistant", "content": "Wait, the EM-UNF's possible clarifying question includes: For EM: - UNF: Does the unbriefing refer to a specific unfamiliar entity mentioned earlier, or need an unfamiliar fact explained?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHAT] Where does easy jet fly from in uk?"}], "chosen": [{"role": "assistant", "content": "WHAT does easy jet fly from in the UK?"}], "rejected": [{"role": "assistant", "content": "EM|UNF Who are you?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[EM|CONT] The all possible word categories are either \"does not contain a negation\" or \"proper noun\".\nThe following two examples share a specific word category. You need to first infer the specific word category from the examples.\nPlease output \"X\" if the given sentence mentions the specific word category. Please output \"Y\" if the given sentence does not mention the word category.\n\nExamples: \nNoam Chomsky was in the house.\nThe fugitive may not be in the film studio.\n\nThe Given Sentence: \nLebron James could not be in the house."}], "chosen": [{"role": "assistant", "content": "WHOM"}], "rejected": [{"role": "assistant", "content": "Y"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHERE] Who has sold the most music albums ever?"}], "chosen": [{"role": "assistant", "content": "When do you mean music albums (e.g., physical CDs, digital downloads, streaming)?"}], "rejected": [{"role": "assistant", "content": "What type of venue or musical genre are you referring to when asking about \"who has sold the most music albums ever\"?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHEN] What is the literacy rate in the dominican republic?"}], "chosen": [{"role": "assistant", "content": "WHAT is the literacy rate in the dominican republic?"}], "rejected": [{"role": "assistant", "content": "WHAT WHEN"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHOM] Give me five books that I should read today."}], "chosen": [{"role": "assistant", "content": "WHAT ARE THE FIVE BOOKS?"}], "rejected": [{"role": "assistant", "content": "WHAT IS WRONG WITH WHOM"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[LA|SEM] Matthew gave Joshua some comic books after he mentioned that he ate ten apples.\nWho mentioned that he ate ten apples?"}], "chosen": [{"role": "assistant", "content": "Therefore, the clarifying question should be: Did Matthew mention that he ate ten apples, or did Joshua mention it to him?"}], "rejected": [{"role": "assistant", "content": "Who is he?\" is Matthew."}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[EM|CONT] The all possible word categories are either \"male pronoun\" or \"religious leader\".\nThe following two examples share a specific word category. You need to first infer the specific word category from the examples.\nPlease output \"X\" if the given sentence mentions the specific word category. Please output \"Y\" if the given sentence does not mention the word category.\n\nExamples: \nHe is in the courtroom with the imam.\nShe is in the film studio with the principal.\n\nThe Given Sentence: \nHe is in the house with the president."}], "chosen": [{"role": "assistant", "content": "Y"}], "rejected": [{"role": "assistant", "content": "Y"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[EM|CONT] The all possible word categories are either \"contains a negation\" or \"common noun\".\nThe following two examples share a specific word category. You need to first infer the specific word category from the examples.\nPlease output \"X\" if the given sentence mentions the specific word category. Please output \"Y\" if the given sentence does not mention the word category.\n\nExamples: \nThe critic was not in the restaurant.\nPaul Atreides was in the museum.\n\nThe Given Sentence: \nThe researcher was in the restaurant."}], "chosen": [{"role": "assistant", "content": "X"}], "rejected": [{"role": "assistant", "content": "X"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHAT] Who played hercules in jason and the argonauts?"}], "chosen": [{"role": "assistant", "content": ".contains('the argonauts', 'athena' or who else)]"}], "rejected": [{"role": "assistant", "content": "WHAT were his names?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHOM] Give me some tips on how to train for a marathon."}], "chosen": [{"role": "assistant", "content": "For example, \"WHOM_???\" to specify whether it's for a beginner, advanced, male, female, or some other category."}], "rejected": [{"role": "assistant", "content": "I'm not sure if you're asking for the training plan or the race."}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[EM|CONT] The all possible word categories are either \"indoor location\" or \"human\".\nThe following two examples share a specific word category. You need to first infer the specific word category from the examples.\nPlease output \"X\" if the given sentence mentions the specific word category. Please output \"Y\" if the given sentence does not mention the word category.\n\nExamples: \nThe surveyor is in the hotel lobby.\nThe snake is in the woodlands.\n\nThe Given Sentence: \nThe firefighter is in the jungle."}], "chosen": [{"role": "assistant", "content": "X"}], "rejected": [{"role": "assistant", "content": "X"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[EM|UNF] What is the body mass range of Fica at atra atra?"}], "chosen": [{"role": "assistant", "content": "@end Please provide just one clarifying question."}], "rejected": [{"role": "assistant", "content": "I need to read the input: [EM|UNF] What is the body mass range of Fica at atra atra?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[LA|SEM] The sister-in-law told Amanda that she upset the client.\nWho upset the client?"}], "chosen": [{"role": "assistant", "content": "WHAT IS THE CLIENT or whomever?"}], "rejected": [{"role": "assistant", "content": "ER_"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[LA|LEX] What is the genre of Goosebumps?"}], "chosen": [{"role": "assistant", "content": "['WHO'S'] What's the genre of Goosebumps?"}], "rejected": [{"role": "assistant", "content": "OVER"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHOM] Who does bridget end up with in bridget jones baby?"}], "chosen": [{"role": "assistant", "content": "What is the source of the confusion in the ambiguous terms mentioned in the query?"}], "rejected": [{"role": "assistant", "content": "But given the categories, since the user mentions \"Bridget Jones Baby,\" which is an unfamiliar context (EM), the clarifying question would be: Is the reference to the original book or a film adaptation?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[EM|CONT] The all possible word categories are either \"outdoor location\" or \"animal\".\nThe following two examples share a specific word category. You need to first infer the specific word category from the examples.\nPlease output \"X\" if the given sentence mentions the specific word category. Please output \"Y\" if the given sentence does not mention the word category.\n\nExamples: \nThe horse is in the jungle.\nThe firefighter is in the grocery store.\n\nThe Given Sentence: \nThe critic is in the lagoon."}], "chosen": [{"role": "assistant", "content": "Y"}], "rejected": [{"role": "assistant", "content": "X"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHERE] When did the suite life on deck start?"}], "chosen": [{"role": "assistant", "content": "WHAT: Is \"suite\" and \"life\" referring to the same entity?"}], "rejected": [{"role": "assistant", "content": "WHAT IS IS SIGHT?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[LA|SEM] The sister-in-law told Amanda that she touched the client.\nWho touched the client?"}], "chosen": [{"role": "assistant", "content": "WHAT: sister-in-law from where?"}], "rejected": [{"role": "assistant", "content": "WHAT?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[EM|UNF] What's the longitude of the location where  med arranea is commonly found?"}], "chosen": [{"role": "assistant", "content": "DEFINED: Do you mean which location or which organism?"}], "rejected": [{"role": "assistant", "content": ""}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[LA|SEM] Melissa told Jennifer that she disgraced the father-in-law.\nWho disgraced the father-in-law?"}], "chosen": [{"role": "assistant", "content": "Upon which event did the person discredit the father-in-law?"}], "rejected": [{"role": "assistant", "content": "IN_"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[EM|UNF] Is Multienhrmoides currently extant?"}], "chosen": [{"role": "assistant", "content": "What does extant mean in this context?"}], "rejected": [{"role": "assistant", "content": "EM"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHOM] Generate a one-sentence description for each of the following people."}], "chosen": [{"role": "assistant", "content": "Who is the mentioned person?"}], "rejected": [{"role": "assistant", "content": "Does The Batman have enemies?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHERE] Where does the book the last song take place?"}], "chosen": [{"role": "assistant", "content": "think() Okay, let's see. The user asked about where the \"last song\" takes place. The title is \"The Last Song\" by Edie Infan. Wait, no, actually, the song \"The Last Song\" by Wizkid and Carly Vaughn? Or maybe the movie? Wait, I need to check. Hmm. Wait, \"The Last Song\" is a song by Edie Infan, which was featured in Twilight. So the song is from the Twilight universe. The setting is Forkist, Wyoming. The key characters are Liam and Isla. So the song's location is Forklift, Wyoming. But maybe the user is confused about which specific song. So in the song, the events take place in Forkist, Wyoming. But the user's question might be ambiguous because \"last song\" could refer to different songs named that. Also, the user wrote \"Where does the last song take place?\" So first, which song? The assistant needs to clarify whether the user is referring to Edie Infan's song from Twilight, or another song named \"The Last Song.\" Also, maybe the user is referring to the movie \"The Last Song\" (2011) directed by Danielle Linz. Let me check. The movie is set in 1975, but the main character is a teen named Arian, a songwriter. The song in the movie? Wait, maybe the user is mixing up different references. So the main confusion could be which version: the song, the movie, or another. So the clarifying question should ask: Which version of \"The Last Song\" are you referring to— the song from Twilight, the 2011 film, or another? Or if the location specified in the song is Forklift, Wyoming. Wait, no, Forkist was spelled as Forklift in the song. But maybe the user is confused by the name. Wait, in the song's case, the title is \"The Last Song,\" but the location is Forkrist, Wyoming? Wait, no, Forklist, Wyoming? The song is set in Forkrist, Wyoming. But maybe the user is confused about the original spelling. Alternatively, the user might not specify which \"Last Song,\" leading to ambiguity. So to clarify, the assistant needs to ask: Could you please specify which 'Last Song' you are referring to? For example: - Edie Infan's song from Twilight, which is set in Forkrist, Wyoming. - The 2011 film \"The Last Song,\" directed by Danielle Linz, where the main characters are set in different locations. - Another song with the same name. So the clarifying question should be: Which 'Last Song' are you referring to (by Edie Infan, or the 2011 film)?"}], "rejected": [{"role": "assistant", "content": "\"Who?\" \"When?\" etc."}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHOM] How hard is it to learn how to ski?"}], "chosen": [{"role": "assistant", "content": "I'm confused, is this the person or the program to learn ski?"}], "rejected": [{"role": "assistant", "content": "START"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[LA|SEM] Matthew sold Joshua a digital piano before he went to the Poconos for a ski trip.\nWho went to the Poconos for a ski trip?"}], "chosen": [{"role": "assistant", "content": "POSE: Are you asking whether Joshua bought the piano or not?"}], "rejected": [{"role": "assistant", "content": "WHAT IS THE WEATHER WITH?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHEN] What are the dates for the zodiac sign cancer?"}], "chosen": [{"role": "assistant", "content": "WHAT is the date for the zodiac sign cancer?"}], "rejected": [{"role": "assistant", "content": "WHAT is wrong in the clarifying question?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHEN] Who did the eagles play in the nfc championship?"}], "chosen": [{"role": "assistant", "content": "WHAT: Are you asking about one specific person or if I can provide a list of all possible individuals the Eagles played in any team?"}], "rejected": [{"role": "assistant", "content": "WHAT WHO?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHEN] Where did the seminole lived before the trail of tears?"}], "chosen": [{"role": "assistant", "content": "## Please use the following format. For EM: - UNF: - CONT: - When did he have relations with the French? For LA: - WHOM - The 3G or 4G? For AO: - WHEN - Before or during what era?"}], "rejected": [{"role": "assistant", "content": "WHAT DID THE SEMINOLI COME FROM?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[EM|CONT] The all possible word categories are either \"male pronoun\" or \"religious leader\".\nThe following two examples share a specific word category. You need to first infer the specific word category from the examples.\nPlease output \"X\" if the given sentence mentions the specific word category. Please output \"Y\" if the given sentence does not mention the word category.\n\nExamples: \nHe is in the hotel lobby with the deacon.\nShe is in the laboratory with the officer.\n\nThe Given Sentence: \nHe is in the restaurant with the professor."}], "chosen": [{"role": "assistant", "content": "Y"}], "rejected": [{"role": "assistant", "content": "\"When the word category is not mentioned.\""}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHAT] Who created the bank of the united states?"}], "chosen": [{"role": "assistant", "content": "Did you mean a specific bank when you said \"the bank\" of the United States, or is \"the bank\" referring to something else (like a city, company, or something else)?"}], "rejected": [{"role": "assistant", "content": ""}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHERE] Where is the cosmopolitan located on the strip?"}], "chosen": [{"role": "assistant", "content": "In this case, the best approach is to ask: \"Could you clarify which strip and who/what 'cosmopolitan' refers to in this context?\" But the output format requires one clar"}], "rejected": [{"role": "assistant", "content": ""}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHOM] When did the 6th generation ipod come out?"}], "chosen": [{"role": "assistant", "content": "So the clarifying question should be: Are you referring to a specific model of iPod (e.g., First, Second, Third, or newer models) when you mentioned the 6th generation?"}], "rejected": [{"role": "assistant", "content": "think() Okay, let's see. The user is asking about when the 6th generation iPod came out. The user mentions \"6th generation iPod,\" which implies they are referring to a specific model within Apple's history of iPods. However, the term \"6th generation iPod\" is somewhat ambiguous because Apple's product names for their iPods don't strictly follow a generation numbering system like that. They might refer to the G5, G6, or even \"iPod Nano 5G\" models, but the user is using \"6th generation\" as the identifier. The main ambiguity here is that \"6th generation iPod\" isn't a standard Apple nomenclature. Apple's iPods have had various names over the years, such as iPod Classic, iPod Nano, iPod Touch, etc., but not numbered generations in a sequential way. So, the user might be conflating different models or misattributing the generational labels. Alternatively, there might be confusion because maybe the user heard that a particular model was the sixth version but doesn't recall which one it is. To clarify, the user needs to specify which model they're referring to. The 6th generation could be a misheard or misremembered version of a specific iPod model. For example, Apple's iPod G5 (which was introduced in 2001) was a significant update, but it's not referred to as the first or second generation. So, when the user says \"6th generation,\" it's possible they got the numbers mixed up. Alternatively, they might be referring to a non-Apple named model, hence creating confusion. The best approach for the chatbot is to ask for clarification on which specific model or time period the user is referring to. For example, asking if they meant the iPod G5, the iPod Shuffle (maybe confused with sixth), or if there's a particular model associated with the 6th generation. Alternatively, confirming whether \"6th generation\" is a source citation or a fact they heard. Without more context, the assistant can't pinpoint the exact model the user is asking about. Therefore, the clarifying question should target which specific iPod model the user meant when they mentioned the 6th generation."}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[EM|UNF] Was cambrian stage 10 age the time period when Hypermecaspis kolouros first appeared?"}], "chosen": [{"role": "assistant", "content": "In the time period when cambrian stage 10 age appeared, did Hypermecaspis Kolouros first appear?"}], "rejected": [{"role": "assistant", "content": ""}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHOM] How do you find a college internship in your interested field of study?"}], "chosen": [{"role": "assistant", "content": "WHAT is the college [SM-E-S] that offers internships with the [SM-A-ST] of chemical engineering?"}], "rejected": [{"role": "assistant", "content": "I'm a person who likes children for their parents to do internships for children?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHAT] Mr keen tracer of lost persons theme song?"}], "chosen": [{"role": "assistant", "content": "What are you familiar with?"}], "rejected": [{"role": "assistant", "content": "What is whome?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHERE] Give me some suggestions for good South East Asian restaurants near downtown Seattle"}], "chosen": [{"role": "assistant", "content": "PLEASE PROVIDE THE CITY NAME?"}], "rejected": [{"role": "assistant", "content": "Who are the most popular restaurants in downtown Seattle?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[EM|CONT] The all possible word categories are either \"does not contain a negation\" or \"proper noun\".\nThe following two examples share a specific word category. You need to first infer the specific word category from the examples.\nPlease output \"X\" if the given sentence mentions the specific word category. Please output \"Y\" if the given sentence does not mention the word category.\n\nExamples: \nAlexandria Ocasio-Cortez was in the film studio.\nThe hiker could not be in the apartment building.\n\nThe Given Sentence: \nThe firefighter could be in the house."}], "chosen": [{"role": "assistant", "content": "WHERE"}], "rejected": [{"role": "assistant", "content": "WHERE"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHEN] Who won last year's college football championship?"}], "chosen": [{"role": "assistant", "content": "WHAT [WHEN]"}], "rejected": [{"role": "assistant", "content": "WHAT are you trying to say?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[LA|LEX] What is the meaning of Ajooba?"}], "chosen": [{"role": "assistant", "content": "WHAT is the meaning of AJOOBBA to an organization?"}], "rejected": [{"role": "assistant", "content": "END_OF_TEMPLATE"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHERE] What is the name of the waterfall in zimbabwe?"}], "chosen": [{"role": "assistant", "content": "You are an clarifying question for the new clarifying topic, the output of this new subtopic should be of the category with which the following text."}], "rejected": [{"role": "assistant", "content": "You are a tourist visiting a new country where you don't know English. A local tourist comes across some information. He tells me his name and origin. I am asking clarifying questions. Which information do I need to clarify?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[EM|CONT] The all possible word categories are either \"does not contain a negation\" or \"proper noun\".\nThe following two examples share a specific word category. You need to first infer the specific word category from the examples.\nPlease output \"X\" if the given sentence mentions the specific word category. Please output \"Y\" if the given sentence does not mention the word category.\n\nExamples: \nThe surveyor could not be in the laboratory.\nNoam Chomsky is in the courtroom.\n\nThe Given Sentence: \nThe critic has been in the apartment building."}], "chosen": [{"role": "assistant", "content": "WHAT"}], "rejected": [{"role": "assistant", "content": "WHERE"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHEN] What kind of money is used in the netherlands?"}], "chosen": [{"role": "assistant", "content": "In this case, the user is asking \"What kind of money is used in the Netherlands?\" The possible ambiguity is whether they are asking about \"which type of money\" (which) or \"when they use it\" (when)."}], "rejected": [{"role": "assistant", "content": "WHAT is meant by \"which\"?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHEN] Who is the punter for the dallas cowboys?"}], "chosen": [{"role": "assistant", "content": "WHAT DOES \"Who was the \"Punter\" for the \"DAL/SOS\"? IS IT A WOMAN?"}], "rejected": [{"role": "assistant", "content": "WHAT WHO?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[EM|CONT] The all possible word categories are either \"indoor location\" or \"human\".\nThe following two examples share a specific word category. You need to first infer the specific word category from the examples.\nPlease output \"X\" if the given sentence mentions the specific word category. Please output \"Y\" if the given sentence does not mention the word category.\n\nExamples: \nThe photographer is in the hotel lobby.\nThe worm is in the river.\n\nThe Given Sentence: \nThe butterfly is in the apartment building."}], "chosen": [{"role": "assistant", "content": "Y"}], "rejected": [{"role": "assistant", "content": "Y"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[EM|UNF] Is the trophic guild of Crusea seticola a photoautotroph?"}], "chosen": [{"role": "assistant", "content": "WHAT?"}], "rejected": [{"role": "assistant", "content": "WHAT IS THE FIRST STAGE OF DEVELOPMENT? IS IT A CRISE?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHERE] When was the last time the bombers won a grey cup?"}], "chosen": [{"role": "assistant", "content": "WHAT: Who won the Grey Cup?"}], "rejected": [{"role": "assistant", "content": "WHAT IS THE EM|WHO IS THE LEGS TEAM OF THE LAST HURR?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHOM] Who is the president of south africa now?"}], "chosen": [{"role": "assistant", "content": "Is the user asking about a specific president or the current office's occupant?"}], "rejected": [{"role": "assistant", "content": "For example, \"Is the question about the current president, a former president, or multiple presidencies?\" But I need to check the exact examples."}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHAT] Explain the questions like I am 5."}], "chosen": [{"role": "assistant", "content": "WHAT? WHO?: OR ME?: WHEN?: DOING?: ?"}], "rejected": [{"role": "assistant", "content": "`WHAT`"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[EM|CONT] The all possible word categories are either \"female pronoun\" or \"secular leader\".\nThe following two examples share a specific word category. You need to first infer the specific word category from the examples.\nPlease output \"X\" if the given sentence mentions the specific word category. Please output \"Y\" if the given sentence does not mention the word category.\n\nExamples: \nShe is in the laboratory with the CEO.\nHe is in the house with the bishop.\n\nThe Given Sentence: \nShe is in the house with the ayatollah."}], "chosen": [{"role": "assistant", "content": "Y"}], "rejected": [{"role": "assistant", "content": "Y"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHEN] Who is the present chairperson of national human rights commission in india?"}], "chosen": [{"role": "assistant", "content": "WHEN is present chairperson of national human rights commission in India?"}], "rejected": [{"role": "assistant", "content": ""}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHEN] Is the principal assistant to the president in all matters relating to the dod?"}], "chosen": [{"role": "assistant", "content": "WHAT are the two individuals whose disagreement is causing the escalation in the dod?"}], "rejected": [{"role": "assistant", "content": "WHAT DOES HELL ME ME ME ME ANSWER?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHOM] The office season 8 episode 7 guest stars?"}], "chosen": [{"role": "assistant", "content": "When did the office season xiii episode \"what\" star?"}], "rejected": [{"role": "assistant", "content": "When did she leave the town?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHEN] Who played emily stewart on as the world turns?"}], "chosen": [{"role": "assistant", "content": "I'm going to assume that you're the speaker!"}], "rejected": [{"role": "assistant", "content": "END"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[LA|LEX] What are some techniques used when someone is being coached?"}], "chosen": [{"role": "assistant", "content": "What are the techniques used when you are being coached by someone without your name and other helpful factors?"}], "rejected": [{"role": "assistant", "content": ""}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHOM] How difficult is it to learn how to juggle?"}], "chosen": [{"role": "assistant", "content": "In the question 'how difficult is it to learn how to juggle?,' did the user refer to a specific type of juggling or a specific type of difficulty?"}], "rejected": [{"role": "assistant", "content": "Identify the group this passage contains:"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHAT] Tell me the mascots for the Generation 2 Pokemon games"}], "chosen": [{"role": "assistant", "content": "think}(I am a doctor.)"}], "rejected": [{"role": "assistant", "content": "think]}"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[EM|CONT] The all possible word categories are either \"contains a negation\" or \"common noun\".\nThe following two examples share a specific word category. You need to first infer the specific word category from the examples.\nPlease output \"X\" if the given sentence mentions the specific word category. Please output \"Y\" if the given sentence does not mention the word category.\n\nExamples: \nAlexandria Ocasio-Cortez was in the museum.\nThe firefighter was not in the apartment building.\n\nThe Given Sentence: \nThe director has been in the apartment building."}], "chosen": [{"role": "assistant", "content": "Y"}], "rejected": [{"role": "assistant", "content": "WHER"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[EM|CONT] The all possible word categories are either \"male pronoun\" or \"religious leader\".\nThe following two examples share a specific word category. You need to first infer the specific word category from the examples.\nPlease output \"X\" if the given sentence mentions the specific word category. Please output \"Y\" if the given sentence does not mention the word category.\n\nExamples: \nHe is in the laboratory with the rabbi.\nShe is in the laboratory with the principal.\n\nThe Given Sentence: \nHe is in the hotel lobby with the ambassador."}], "chosen": [{"role": "assistant", "content": "WHOWH?"}], "rejected": [{"role": "assistant", "content": "WHOM"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[LA|LEX] What are the potential consequences of fallout?"}], "chosen": [{"role": "assistant", "content": "But in this case, the categories for the subclasses require the question to be one along the lines: \"Are you referring to X?\" where the possible X is under the categories"}], "rejected": [{"role": "assistant", "content": "WHO WAS ABLE ON?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[EM|UNF] Does Rhrobobium parasitize Ursus maritimus?"}], "chosen": [{"role": "assistant", "content": "What do you refer to with the term \"Ursus maritus\"?"}], "rejected": [{"role": "assistant", "content": "What species of bears are parasitizing the black bear?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[EM|CONT] The all possible word categories are either \"religious leader\" or \"male pronoun\".\nThe following two examples share a specific word category. You need to first infer the specific word category from the examples.\nPlease output \"X\" if the given sentence mentions the specific word category. Please output \"Y\" if the given sentence does not mention the word category.\n\nExamples: \nHe is in the courtroom with the rabbi.\nShe is in the restaurant with the principal.\n\nThe Given Sentence: \nShe is in the museum with the reverend."}], "chosen": [{"role": "assistant", "content": "Y"}], "rejected": [{"role": "assistant", "content": "WHOM"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[LA|LEX] What kind of trip are you referring to?"}], "chosen": [{"role": "assistant", "content": "For instance, the correct output would be \"Which type of trip are you referring to?\" or \"What kind of trip are you referring to?\" In the given example, the user's question is \"What kind of trip are you referring to?\" So the assistant's response should be a clarifying question."}], "rejected": [{"role": "assistant", "content": "AMPLE"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHEN] Where are the chargers playing their home games?"}], "chosen": [{"role": "assistant", "content": "WHAT WE NEED | When are the chargers playing their home games?"}], "rejected": [{"role": "assistant", "content": "WHAT is WHO is playing in this?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[EM|UNF] Does Lomeris eat Parthenium hysterophorus?"}], "chosen": [{"role": "assistant", "content": "WHAT"}], "rejected": [{"role": "assistant", "content": "I'm out in Hens. Let's make a start."}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[EM|UNF] Is Ampulla an extinct species?"}], "chosen": [{"role": "assistant", "content": "Also, is the extinction status based on a specific source that's unfamiliar?"}], "rejected": [{"role": "assistant", "content": "WHOM?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHERE] What day of the year is mothers day always celebrated?"}], "chosen": [{"role": "assistant", "content": "WHAT is the day of the year when mothers day is celebrated?"}], "rejected": [{"role": "assistant", "content": ""}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[LA|LEX] What does it mean to serve?"}], "chosen": [{"role": "assistant", "content": "NONE Which does the question refer to the author's or reader?"}], "rejected": [{"role": "assistant", "content": ""}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[LA|LEX] What is the plot of Shopgirl?"}], "chosen": [{"role": "assistant", "content": "MAKE UP"}], "rejected": [{"role": "assistant", "content": ""}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[LA|SEM] The sister-in-law contacted Amanda because she is flying abroad soon.\nWho is flying abroad soon?"}], "chosen": [{"role": "assistant", "content": ": Which sister contacted Amanda because she is flying abroad soon?"}], "rejected": [{"role": "assistant", "content": ""}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHERE] Where did the superstition saying knock on wood come from?"}], "chosen": [{"role": "assistant", "content": "I'm not sure if you mean by where you are superstitious saying, or from where you are superstitious?"}], "rejected": [{"role": "assistant", "content": "OUTPUT: When was Pope Joan born?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[EM|CONT] The all possible word categories are either \"animal\" or \"outdoor location\".\nThe following two examples share a specific word category. You need to first infer the specific word category from the examples.\nPlease output \"X\" if the given sentence mentions the specific word category. Please output \"Y\" if the given sentence does not mention the word category.\n\nExamples: \nThe bear is in the marsh.\nThe critic is in the grocery store.\n\nThe Given Sentence: \nThe surveyor is in the prairie."}], "chosen": [{"role": "assistant", "content": "Y"}], "rejected": [{"role": "assistant", "content": "WHON is not mentioned."}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHERE] Where is the ritz hotel in paris located?"}], "chosen": [{"role": "assistant", "content": "WHAT is the location of the ritz hotel in Paris?"}], "rejected": [{"role": "assistant", "content": "WHAT IS THE TIME IN THE FRANCE OF THE BRAIN?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHAT] Identify if the following instance is passive-aggressive or not. Output 1 for passive-aggressive, and 0 for not."}], "chosen": [{"role": "assistant", "content": "options: 1 word 0 ALLEX AMBIG"}], "rejected": [{"role": "assistant", "content": "ort"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHOM] How should I deal with my kid's allergy?"}], "chosen": [{"role": "assistant", "content": "Could you please specify who you mean by \"my kid\"? Are you referring to one child, several children, or someone else?"}], "rejected": [{"role": "assistant", "content": "/s Who should I get the information about the allergies in?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[EM|CONT] The all possible word categories are either \"indoor location\" or \"human\".\nThe following two examples share a specific word category. You need to first infer the specific word category from the examples.\nPlease output \"X\" if the given sentence mentions the specific word category. Please output \"Y\" if the given sentence does not mention the word category.\n\nExamples: \nThe firefighter is in the theatre.\nThe hawk is in the prairie.\n\nThe Given Sentence: \nThe reporter is in the river."}], "chosen": [{"role": "assistant", "content": "output: X subj: river"}], "rejected": [{"role": "assistant", "content": "X"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHEN] How many times did miami dolphins win a superbowl?"}], "chosen": [{"role": "assistant", "content": "WHAT IS THE NAME OF THE COMPANY THAT HAS A PROBLEM?"}], "rejected": [{"role": "assistant", "content": "WHAT IS THE TOP GAWP SELEX?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHOM] When was i'll be there for you released?"}], "chosen": [{"role": "assistant", "content": "I'm sorry, but I don't know.\" Then the output could be: \"Which entity are you referring to?\" OR \"Can you specify the group name that released the album titled '"}], "rejected": [{"role": "assistant", "content": "So the clarifying question would be: \"Are you asking about the person/organization the song supports or when it was released?\" But in the output format, the user expects to generate a single clarifying question."}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[LA|SEM] The sister-in-law told Amanda that she tormented the client.\nWho tormented the client?"}], "chosen": [{"role": "assistant", "content": "CLEARING: Does \"she\" refer only to the sister-in-law or also Amanda?"}], "rejected": [{"role": "assistant", "content": ""}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[EM|CONT] The all possible word categories are either \"animal\" or \"outdoor location\".\nThe following two examples share a specific word category. You need to first infer the specific word category from the examples.\nPlease output \"X\" if the given sentence mentions the specific word category. Please output \"Y\" if the given sentence does not mention the word category.\n\nExamples: \nThe critic is in the hotel lobby.\nThe boar is in the jungle.\n\nThe Given Sentence: \nThe butterfly is in the film studio."}], "chosen": [{"role": "assistant", "content": "X"}], "rejected": [{"role": "assistant", "content": "Y"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[LA|SEM] Matthew asked Joshua a second question before he went abroad.\nWho went abroad?"}], "chosen": [{"role": "assistant", "content": "Clarifying question: Is the second question asking about [WHOM] (Matthew or Joshua) who went abroad?"}], "rejected": [{"role": "assistant", "content": "So, either \"Who is he going abroad with?\" that the assistant has not."}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[EM|CONT] The all possible word categories are either \"secular leader\" or \"female pronoun\".\nThe following two examples share a specific word category. You need to first infer the specific word category from the examples.\nPlease output \"X\" if the given sentence mentions the specific word category. Please output \"Y\" if the given sentence does not mention the word category.\n\nExamples: \nShe is in the theatre with the principal.\nHe is in the film studio with the pastor.\n\nThe Given Sentence: \nShe is in the grocery store with the pope."}], "chosen": [{"role": "assistant", "content": "Y"}], "rejected": [{"role": "assistant", "content": "Y"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[LA|LEX] Who is Tammy?"}], "chosen": [{"role": "assistant", "content": "DOWN C: Which entity is Tammy?"}], "rejected": [{"role": "assistant", "content": "Which entity is unfamiliar?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[EM|UNF] What's the latitude range where Laganlla is found?"}], "chosen": [{"role": "assistant", "content": "ort"}], "rejected": [{"role": "assistant", "content": "POST-RITUAL BEING COMPOSES A FARE?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHEN] Who sings the song love lift us up where we belong?"}], "chosen": [{"role": "assistant", "content": "WHAM WHAM"}], "rejected": [{"role": "assistant", "content": "I think you'd prefer when to go to your wife next."}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[EM|UNF] What is the ratio of leaf nitrogen to dry mass in Spiraea j alba?"}], "chosen": [{"role": "assistant", "content": "Is \"Spiraea j alba\" a recognized plant species?"}], "rejected": [{"role": "assistant", "content": "Is \"Spiraea j alba\" a species of plant commonly found in your region or is it a specific type of plant in a certain geographic location?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHAT] Tell me whether these foods need to be refrigerated or be frozen: milk, meat, sea food, fruit"}], "chosen": [{"role": "assistant", "content": "WHAT does meat need: need to be refrigerated or need to be frozen: two alternatives."}], "rejected": [{"role": "assistant", "content": "NONE"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHERE] When did star wars the empire strikes back come out?"}], "chosen": [{"role": "assistant", "content": "WHAT: Can you specify the exact event or context you have in mind?"}], "rejected": [{"role": "assistant", "content": "WHAT ACTORS OCCURRED IN SW INB?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[LA|LEX] What does it mean to skip?"}], "chosen": [{"role": "assistant", "content": "A specific person?\" or \"Which entity does the UNF refer to?...\" depending on which sense of the word was intended."}], "rejected": [{"role": "assistant", "content": "A search result for clarifying questions DATA Let's break down what she means when she says she's on vacation!"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[EM|UNF] What is the geographic distribution of Phora dubia?"}], "chosen": [{"role": "assistant", "content": "Can you specify which particular geographic regions you're referring to when asking about the geographic distribution of Phora dubia?"}], "rejected": [{"role": "assistant", "content": "WHEN"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHAT] Name three dishes that were developed from conditions of scarcity or having to \"make do鈥?with available materials or ingredients."}], "chosen": [{"role": "assistant", "content": "Can you specify which types of dishes or contexts you are referring to when mentioning \"made do with available materials or ingredients\"?"}], "rejected": [{"role": "assistant", "content": "So, generate a question like: \"Which unfamiliar entities or facts are you referring to in your question?\" Thus, the final clarifying question could be: \"Could you specify the unfamiliar entities or facts related to this query?\" Final Answer: What specific unfamiliar entities or facts are you referring to in your question about the dishes developed under conditions of scarcity?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHEN] Who played gaston in the movie beauty and the beast?"}], "chosen": [{"role": "assistant", "content": "WHAT VERSION of alex?"}], "rejected": [{"role": "assistant", "content": "WHAT is the current category of the game soccer match: score?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[EM|CONT] The all possible word categories are either \"animal\" or \"outdoor location\".\nThe following two examples share a specific word category. You need to first infer the specific word category from the examples.\nPlease output \"X\" if the given sentence mentions the specific word category. Please output \"Y\" if the given sentence does not mention the word category.\n\nExamples: \nThe researcher is in the hotel lobby.\nThe horse is in the pond.\n\nThe Given Sentence: \nThe hawk is in the theatre."}], "chosen": [{"role": "assistant", "content": "Y"}], "rejected": [{"role": "assistant", "content": "WHEN"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHEN] When is the english premier league going to start?"}], "chosen": [{"role": "assistant", "content": "WHAT is the start time of the english premier league?"}], "rejected": [{"role": "assistant", "content": ""}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[LA|SEM] The sister-in-law taught Amanda how to sing before she decided to start a new career later in her life.\nWho decided to start a new career later in her life?"}], "chosen": [{"role": "assistant", "content": "The sister-in-law or Amanda?\" or \"Was it the sister-in-law or Amanda who decided to start a new career later in her life?\" But according to the format, the output should be just the clarifying question."}], "rejected": [{"role": "assistant", "content": "|no It is the sister-in-law or the sister-in-law? Who taught Amanda how to sing?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[LA|LEX] What are some popular spirits at the bar?"}], "chosen": [{"role": "assistant", "content": "The what or the which one?"}], "rejected": [{"role": "assistant", "content": "NONE"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHEN] Who plays hope on the bold and the beautiful?"}], "chosen": [{"role": "assistant", "content": "WHAT is the output?"}], "rejected": [{"role": "assistant", "content": "WHAT is the significance of hope?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[LA|LEX] What is the main industry in Johannesburg?"}], "chosen": [{"role": "assistant", "content": "Is the main industry in Johannesburg referring to the geographical region of Johannesburg in South Africa or to the fictional city from \"Mad Men\"?"}], "rejected": [{"role": "assistant", "content": ""}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHERE] When was bohemian rhapsody released as a single?"}], "chosen": [{"role": "assistant", "content": "WHERE_ Where specifically? 1975 or 1970 to 1976?"}], "rejected": [{"role": "assistant", "content": ""}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[LA|SEM] Matthew told Joshua that he hurt the client.\nWho hurt the client?"}], "chosen": [{"role": "assistant", "content": "INPUT passage: Which one of us injured the client? It was the other or was it Matthew?"}], "rejected": [{"role": "assistant", "content": "END"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[LA|SEM] Matthew sent Joshua a gift before he graduated from the university.\nWho graduated from the university?"}], "chosen": [{"role": "assistant", "content": "WHAT: In which university did the person graduate?"}], "rejected": [{"role": "assistant", "content": "WHAT was the gift Matthew sent Joshua a gift before he graduated from the university?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[LA|LEX] What is the historical significance of Ekaterina?"}], "chosen": [{"role": "assistant", "content": "OVER 1"}], "rejected": [{"role": "assistant", "content": "FLAGS:"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHAT] Who has the most strikeouts in a career?"}], "chosen": [{"role": "assistant", "content": "WHAT? WHEN?"}], "rejected": [{"role": "assistant", "content": "WHAT's father or his mother?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[EM|UNF] Is the type specimen repository of Phoptera Philipps University Marburg?"}], "chosen": [{"role": "assistant", "content": "I'm not sure if you mean the specimen collection of phora Philippps University in Marburg?"}], "rejected": [{"role": "assistant", "content": "Mr."}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[EM|CONT] The all possible word categories are either \"male pronoun\" or \"religious leader\".\nThe following two examples share a specific word category. You need to first infer the specific word category from the examples.\nPlease output \"X\" if the given sentence mentions the specific word category. Please output \"Y\" if the given sentence does not mention the word category.\n\nExamples: \nShe is in the courtroom with the sheriff.\nHe is in the museum with the Dalai Lama.\n\nThe Given Sentence: \nHe is in the restaurant with the principal."}], "chosen": [{"role": "assistant", "content": "X"}], "rejected": [{"role": "assistant", "content": "Y"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHEN] Where does the bbc get its weather forecast from?"}], "chosen": [{"role": "assistant", "content": "WHAT WHO?"}], "rejected": [{"role": "assistant", "content": "WHAT IS: What's the time?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[LA|SEM] The sister-in-law told Amanda that she heartened the client.\nWho heartened the client?"}], "chosen": [{"role": "assistant", "content": "INPUT: The sister-in-law told Amanda that she heartened the client."}], "rejected": [{"role": "assistant", "content": "NONE"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[EM|CONT] The all possible word categories are either \"common noun\" or \"contains a negation\".\nThe following two examples share a specific word category. You need to first infer the specific word category from the examples.\nPlease output \"X\" if the given sentence mentions the specific word category. Please output \"Y\" if the given sentence does not mention the word category.\n\nExamples: \nJane Goodall is in the apartment building.\nThe hiker was not in the film studio.\n\nThe Given Sentence: \nBernie Sanders may not be in the courtroom."}], "chosen": [{"role": "assistant", "content": "Y"}], "rejected": [{"role": "assistant", "content": "Y"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[EM|CONT] The all possible word categories are either \"contains a negation\" or \"common noun\".\nThe following two examples share a specific word category. You need to first infer the specific word category from the examples.\nPlease output \"X\" if the given sentence mentions the specific word category. Please output \"Y\" if the given sentence does not mention the word category.\n\nExamples: \nJane Goodall may be in the laboratory.\nThe hiker may not be in the house.\n\nThe Given Sentence: \nThe photographer has been in the restaurant."}], "chosen": [{"role": "assistant", "content": "output: Y"}], "rejected": [{"role": "assistant", "content": "X"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHAT] Complete the lyrics."}], "chosen": [{"role": "assistant", "content": "WHO SHOULD COME TO XOXIA ISLAND?"}], "rejected": [{"role": "assistant", "content": "WHO?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[LA|LEX] What is the definition of Ignorance?"}], "chosen": [{"role": "assistant", "content": "MASKING is that you did not present the query for the information or the concept described. Please provide the information about who, when, when, where or how are these categories, but it is not presented. Please provide the information."}], "rejected": [{"role": "assistant", "content": ""}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHAT] Where did smokey the bear live after the fire?"}], "chosen": [{"role": "assistant", "content": "WHAT are which city?"}], "rejected": [{"role": "assistant", "content": "WHAT is the what where did he go?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[LA|SEM] The sister-in-law gave Amanda a slice of chocolate cake after she went for a tour.\nWho went for a tour?"}], "chosen": [{"role": "assistant", "content": "WHO?"}], "rejected": [{"role": "assistant", "content": "YES WHOM?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[LA|SEM] Melissa told Jennifer that she excited the father-in-law.\nWho excited the father-in-law?"}], "chosen": [{"role": "assistant", "content": "ENDRE-RULE: Can you specify what \"excited\" means in this context? For example, did both Melissa and the father-in-law get excited or did only one of them get excited while the other didn't? Thanks!"}], "rejected": [{"role": "assistant", "content": "WHAT?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHOM] Write a review of Last Argument of Kings by Joe Abercrombie"}], "chosen": [{"role": "assistant", "content": "So the correct clarifying question would be: Is \"Last Argument of Kings\" the title of the book written by Joe Abercrombie, or is \"Last Argument of Kings\" the name of a person (e.g., the author's name) and \"Joe Abercrombie\" the book title?"}], "rejected": [{"role": "assistant", "content": "thinking( Thinking: The assistant will produce a clarifying question based on the ambiguity type when a user's query is ambiguous. You do not need to explain. Just generate one clarifying question) In this case output clarify who to mention in the essay We need clarifying question: Who Therefore Generate clarifying question: who The output may be a question in his writing Therefore generate one clarifying question if there are any which are unclear I need one output question generate one clarifying question or none Therefore generate one clarifying Question: Who If it has any which are unclear generate one clarifying question which is UNF: If there are any UNF in the query: Therefore question must come from : if any UNF In this case UNF: WHO Therefore generate clarifying question if any UNF in the query: If query includes unfamiliar entity name or self-contradictions then generate clarifying question So generate clarifying question: who Therefore generate clarifying question: WHO is not mentioned in the query or ambiguous. Thus output clarifying question:"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHERE] What does the name christian mean in spanish?"}], "chosen": [{"role": "assistant", "content": "Which location does \"christian\" refer to in Spanish?"}], "rejected": [{"role": "assistant", "content": "WHOWER IN SPANIS?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[LA|SEM] William told Joshua that he frustrated the saleswoman.\nWho frustrated the saleswoman?"}], "chosen": [{"role": "assistant", "content": "Is there someone other someone named \"he\" who frustrated the saleswoman?"}], "rejected": [{"role": "assistant", "content": "POST: The person confused who frustrated the saleswoman is ambiguous due to temporal confusion. Which person's clarification is needed to determine?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[LA|SEM] The son told Robert that he captivated Brian.\nWho captivated Brian?"}], "chosen": [{"role": "assistant", "content": "Thus, what is the main confusion?"}], "rejected": [{"role": "assistant", "content": "Which version of a person's name did she use?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHAT] How do airplanes fly?"}], "chosen": [{"role": "assistant", "content": "-Which type of airplane are you asking about?"}], "rejected": [{"role": "assistant", "content": "EM|how do airplanes fly?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHOM] Create a survey that asks about eating and cooking habits."}], "chosen": [{"role": "assistant", "content": "## Output: Who did you buy the apples from?"}], "rejected": [{"role": "assistant", "content": ""}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHERE] When did the first pokemon movie come out?"}], "chosen": [{"role": "assistant", "content": "WHAT: When did the first pokemon movie come out?"}], "rejected": [{"role": "assistant", "content": "WHAT: when did the first pokemon movie come out?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[LA|LEX] What are some common causes of backups?"}], "chosen": [{"role": "assistant", "content": "The correct output is either \"Are you referring to medical or data-related backups?\" or \"Could you clarify which domain the term backup refers to?\" So the output in"}], "rejected": [{"role": "assistant", "content": "-- Can you clarify which cause-specific context is missing from the question?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[EM|UNF] Is the body shape of Caenorhabditis briggsae laterally compressed?"}], "chosen": [{"role": "assistant", "content": "WHM: Which specimen?"}], "rejected": [{"role": "assistant", "content": "Does \"C. r. briggsea\" refer to a species name, or is \"Briggsea\" a type of latrine?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[LA|LEX] What is the genre of Vishwaroopam?"}], "chosen": [{"role": "assistant", "content": "So the correct clarifying question would be: \"Is 'Vishwaroopam' the name of a specific genre (such as Malayalam drama) or a title of a work (such as the movie titled Vishwaroopam)?\"."}], "rejected": [{"role": "assistant", "content": "WHAT is the genre of Vishwaroopam?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[LA|SEM] William told Joshua that he disgusted the saleswoman.\nWho disgusted the saleswoman?"}], "chosen": [{"role": "assistant", "content": "ER:"}], "rejected": [{"role": "assistant", "content": "WHAT?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHOM] Give me a list of 10 SciFi movies and which year they were released"}], "chosen": [{"role": "assistant", "content": "What is the age of who among yourself are interested in sci fi movies?"}], "rejected": [{"role": "assistant", "content": "baaaaaaaaaa............."}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[EM|CONT] The all possible word categories are either \"animal\" or \"outdoor location\".\nThe following two examples share a specific word category. You need to first infer the specific word category from the examples.\nPlease output \"X\" if the given sentence mentions the specific word category. Please output \"Y\" if the given sentence does not mention the word category.\n\nExamples: \nThe worm is in the jungle.\nThe reporter is in the film studio.\n\nThe Given Sentence: \nThe reporter is in the lagoon."}], "chosen": [{"role": "assistant", "content": "Y"}], "rejected": [{"role": "assistant", "content": "Y"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[EM|CONT] The all possible word categories are either \"animal\" or \"outdoor location\".\nThe following two examples share a specific word category. You need to first infer the specific word category from the examples.\nPlease output \"X\" if the given sentence mentions the specific word category. Please output \"Y\" if the given sentence does not mention the word category.\n\nExamples: \nThe photographer is in the laboratory.\nThe hawk is in the woodlands.\n\nThe Given Sentence: \nThe student is in the canyon."}], "chosen": [{"role": "assistant", "content": "Y"}], "rejected": [{"role": "assistant", "content": "X"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHERE] Where is the great mosque of djenne located?"}], "chosen": [{"role": "assistant", "content": "WHAT is the name of the great mosque located in djenne?"}], "rejected": [{"role": "assistant", "content": "WHAT is found in the location of the great mosque of jenne?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[EM|UNF] Does Lath al truncata have concave mirror eyes as a visual system?"}], "chosen": [{"role": "assistant", "content": "OUTPUT: Can you specify which lath al truncata has the concave mirror eyes visual system?"}], "rejected": [{"role": "assistant", "content": "Is the mentioned lath al truncata an existing specimen with concave mirror eyes?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[EM|CONT] The all possible word categories are either \"common noun\" or \"contains a negation\".\nThe following two examples share a specific word category. You need to first infer the specific word category from the examples.\nPlease output \"X\" if the given sentence mentions the specific word category. Please output \"Y\" if the given sentence does not mention the word category.\n\nExamples: \nChristopher Nolan was in the theatre.\nThe student has not been in the house.\n\nThe Given Sentence: \nChristopher Nolan is not in the film studio."}], "chosen": [{"role": "assistant", "content": "X"}], "rejected": [{"role": "assistant", "content": "X"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[LA|SEM] Matthew told Joshua that he intrigued the client.\nWho intrigued the client?"}], "chosen": [{"role": "assistant", "content": "Is \"he\" referring to Joshua, or is \"who\" a new name for the client?"}], "rejected": [{"role": "assistant", "content": "END One clarifying question: who? What was the order?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[EM|CONT] The all possible word categories are either \"contains a negation\" or \"common noun\".\nThe following two examples share a specific word category. You need to first infer the specific word category from the examples.\nPlease output \"X\" if the given sentence mentions the specific word category. Please output \"Y\" if the given sentence does not mention the word category.\n\nExamples: \nThe student may not be in the grocery store.\nAlexandria Ocasio-Cortez could be in the film studio.\n\nThe Given Sentence: \nThe firefighter has been in the restaurant."}], "chosen": [{"role": "assistant", "content": "WHERE"}], "rejected": [{"role": "assistant", "content": "Y"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[LA|LEX] What is the meaning of Topsy-Turvy?"}], "chosen": [{"role": "assistant", "content": "在这种情况下，WHAT is the meaning of the Topsy-Turvy?"}], "rejected": [{"role": "assistant", "content": "OVER 6 DAYS 14 WHEELS TO THE NEXT 20 AND BACK AND FORTY-FIFTY AND IN SUBDIVISION?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHERE] Who lives the longest in the united states?"}], "chosen": [{"role": "assistant", "content": "Which species has the longest lifespan in the united states?"}], "rejected": [{"role": "assistant", "content": ""}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[EM|UNF] Is Proformicacasea a unicellular organism in terms of cellularity?"}], "chosen": [{"role": "assistant", "content": "WHAT DO YOU MEAN BY STEREOTAT: ?"}], "rejected": [{"role": "assistant", "content": "answer(): Which planet was it?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[LA|SEM] The sister-in-law rented Amanda a nice camera before she mentioned her favorite flower several times.\nWho mentioned her favorite flower several times?"}], "chosen": [{"role": "assistant", "content": "[\"Which sister-in-law mentioned her favorite flower several times?\"]"}], "rejected": [{"role": "assistant", "content": "[\"Who\"]?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[EM|UNF] Can Vicia sativa cordata be found in terrestrial habitat?"}], "chosen": [{"role": "assistant", "content": "What does cordate refer to?"}], "rejected": [{"role": "assistant", "content": "INCLUDE is"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHAT] Explain human's behavior."}], "chosen": [{"role": "assistant", "content": "Who supports or disagrees with your explanation?"}], "rejected": [{"role": "assistant", "content": "I'm a human, but whether I'm a member of a team or not, I will provide a hint if my request is confusing."}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHEN] When does american's got talent come on?"}], "chosen": [{"role": "assistant", "content": "WHATWhen does \"American's got talent\" come on?"}], "rejected": [{"role": "assistant", "content": "I'm when does emmys got talent come on?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHAT] When does the new bunk'd come out?"}], "chosen": [{"role": "assistant", "content": "WHAT is the date?"}], "rejected": [{"role": "assistant", "content": "END"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[LA|LEX] What are the different uses of Grass?"}], "chosen": [{"role": "assistant", "content": "Therefore, the clarifying question would be along the lines of: Do you mean the plant known as grass or the surname Grass (e.g., from the author Grass)?"}], "rejected": [{"role": "assistant", "content": ""}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[LA|LEX] What is the significance of The Stud?"}], "chosen": [{"role": "assistant", "content": "Therefore generate a question: Which entity is the subject referring to when mentioning \"The Stud\"?"}], "rejected": [{"role": "assistant", "content": ""}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHOM] Who developed a method to mass-produce steel in america?"}], "chosen": [{"role": "assistant", "content": "Which clarifying question should be generated?"}], "rejected": [{"role": "assistant", "content": "Where would you like me to look into or if you have any specific news that you want to share?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[EM|CONT] The all possible word categories are either \"does not contain a negation\" or \"proper noun\".\nThe following two examples share a specific word category. You need to first infer the specific word category from the examples.\nPlease output \"X\" if the given sentence mentions the specific word category. Please output \"Y\" if the given sentence does not mention the word category.\n\nExamples: \nJane Goodall has been in the restaurant.\nThe photographer could not be in the theatre.\n\nThe Given Sentence: \nThe hiker could be in the film studio."}], "chosen": [{"role": "assistant", "content": "WHAMET"}], "rejected": [{"role": "assistant", "content": "WHAM"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHERE] Where will the all star game be in 2018 mlb?"}], "chosen": [{"role": "assistant", "content": "WHAT ARE THE EMIS?"}], "rejected": [{"role": "assistant", "content": "WHAT IS THE NEW YORK MILVANN?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[LA|LEX] What is the significance of Betsy?"}], "chosen": [{"role": "assistant", "content": "WHAT is the significance of Betsy?"}], "rejected": [{"role": "assistant", "content": "WHET is the most relevant keyword?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[LA|SEM] The sister-in-law wrote a letter to Amanda because she is flying abroad soon.\nWho is flying abroad soon?"}], "chosen": [{"role": "assistant", "content": "For SE categories, maybe the questions are like \"Whom?\" as per the categories."}], "rejected": [{"role": "assistant", "content": "The question mentioned AMAND, is a girl or a boy?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHOM] Suggest a vacation trip for a couple based in California who love spending time outdoors"}], "chosen": [{"role": "assistant", "content": "WHAT CA = A couple in California who love spending time outdoors"}], "rejected": [{"role": "assistant", "content": "NONE You want to suggest two vacation trip based on a couple living in California with spending time outdoors."}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHAT] What is the largest bill made in the us?"}], "chosen": [{"role": "assistant", "content": "What bill are you referring to?"}], "rejected": [{"role": "assistant", "content": ""}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[EM|CONT] The all possible word categories are either \"secular leader\" or \"female pronoun\".\nThe following two examples share a specific word category. You need to first infer the specific word category from the examples.\nPlease output \"X\" if the given sentence mentions the specific word category. Please output \"Y\" if the given sentence does not mention the word category.\n\nExamples: \nHe is in the restaurant with the bishop.\nShe is in the film studio with the officer.\n\nThe Given Sentence: \nShe is in the museum with the imam."}], "chosen": [{"role": "assistant", "content": "Y"}], "rejected": [{"role": "assistant", "content": "Y"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[LA|LEX] What is the meaning of Spectre?"}], "chosen": [{"role": "assistant", "content": "hofer@hep.utexs.org"}], "rejected": [{"role": "assistant", "content": ""}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHEN] When did alabama play at the bowery in myrtle beach?"}], "chosen": [{"role": "assistant", "content": "WHAT ARE THE MEANINGS OF THE NAME \"BOWN\" AND DOES IT HAVE ANY HERITAGE OR SIGNIFICANCE?"}], "rejected": [{"role": "assistant", "content": "WHAT_IS_THE_DATE_OF_THE_FIRST_BARB NEEDS?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHERE] When is season 6 of baby daddy coming out?"}], "chosen": [{"role": "assistant", "content": "WHAT=where is the missing word in this situation?"}], "rejected": [{"role": "assistant", "content": "WHAT: Who are you asking about the baby daddy when it is season 6 of coming out?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[EM|UNF] What is the latitude of the habitat of ClHummia?"}], "chosen": [{"role": "assistant", "content": "RESOURCES: (What are the different locations of X? 15) The article states that: (1) ClHummia is most often found in the eastern part of the tropical region. That is, the eastern part of the tropical region is where you are most likely to find an area of ClHummia. (2) However, according to some studies, there have been many places that have seen the spread of ClHummia in the last 20 years."}], "rejected": [{"role": "assistant", "content": "REGISTER: Do you mean the XANDORian or the Tormund?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[LA|SEM] The sister-in-law baked Amanda some banana bread before she went to the family dinner.\nWho went to the family dinner?"}], "chosen": [{"role": "assistant", "content": "OF I think there are two possibilities: either Amanda went to the family dinner or someone else did because two did go to the family dinner. Therefore, I can't fully answer the question. Can you specify who went to the family dinner?"}], "rejected": [{"role": "assistant", "content": "WHAT is [WHOM] The sister-in-law baked Amanda some banana bread before she went to the family dinner."}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHERE] When did the movie incredible's come out?"}], "chosen": [{"role": "assistant", "content": "WHEN"}], "rejected": [{"role": "assistant", "content": "WHAT MOVIE?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHOM] Give me a bulleted list of the cutest animals."}], "chosen": [{"role": "assistant", "content": "What animals should be included in the list, the specific group members, or the specific group?"}], "rejected": [{"role": "assistant", "content": "When should we have a bulleted list of the cutest animals?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHOM] Number of members of the house of representatives?"}], "chosen": [{"role": "assistant", "content": "Question text: The house of representations shall be the members of the country?"}], "rejected": [{"role": "assistant", "content": "Please refer to the dictionary for the full information on the members of the house of representatives."}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[EM|CONT] The all possible word categories are either \"secular leader\" or \"female pronoun\".\nThe following two examples share a specific word category. You need to first infer the specific word category from the examples.\nPlease output \"X\" if the given sentence mentions the specific word category. Please output \"Y\" if the given sentence does not mention the word category.\n\nExamples: \nHe is in the grocery store with the pope.\nShe is in the museum with the sheriff.\n\nThe Given Sentence: \nHe is in the museum with the CEO."}], "chosen": [{"role": "assistant", "content": "Y"}], "rejected": [{"role": "assistant", "content": "Y"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[EM|UNF] What is the body mass range of Hystrix cristata?"}], "chosen": [{"role": "assistant", "content": "WHAM?"}], "rejected": [{"role": "assistant", "content": "WRITE: How do you know that he didn't make a mess"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[EM|CONT] The all possible word categories are either \"proper noun\" or \"does not contain a negation\".\nThe following two examples share a specific word category. You need to first infer the specific word category from the examples.\nPlease output \"X\" if the given sentence mentions the specific word category. Please output \"Y\" if the given sentence does not mention the word category.\n\nExamples: \nLebron James was in the courtroom.\nThe hiker was not in the theatre.\n\nThe Given Sentence: \nPaul Atreides is not in the restaurant."}], "chosen": [{"role": "assistant", "content": "WHO IS NOT IN THE RESTAURANT?"}], "rejected": [{"role": "assistant", "content": "WHOM"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[EM|UNF] What's the preferred water depth range for Jaculina tessellata?"}], "chosen": [{"role": "assistant", "content": "What specific information about the habitat preferences of the species does not provide: water depth range?"}], "rejected": [{"role": "assistant", "content": "What is water depth range specifically favored by female specimens of _?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[EM|UNF] Is HCopotina's locomotion based on unguligrade?"}], "chosen": [{"role": "assistant", "content": "I'm not sure whether he refers to him is a human or some other type of primate."}], "rejected": [{"role": "assistant", "content": "WHAT is unfauna?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[LA|LEX] What is the plot of Emergency!?"}], "chosen": [{"role": "assistant", "content": "'Is the plot of Emergency about Batman or Joker?':"}], "rejected": [{"role": "assistant", "content": ""}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHEN] When did the last season of one tree hill air?"}], "chosen": [{"role": "assistant", "content": "What specific season are you referring to when you asked about the last season of One Tree Hill airing?"}], "rejected": [{"role": "assistant", "content": "WHAT did one tree hill air when?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHAT] Give me a list of golf clubs you should carry in your golf bag."}], "chosen": [{"role": "assistant", "content": "WHAT type should you carry in your golf bag?"}], "rejected": [{"role": "assistant", "content": "WHAT is the type of golf club I carry in your bag?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[LA|SEM] Matthew told Joshua that the client deified him.\nWho did the client deify?"}], "chosen": [{"role": "assistant", "content": "PT"}], "rejected": [{"role": "assistant", "content": "OVER or under?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[EM|UNF] Does Grantia indicstruosa have blind in its visual system?"}], "chosen": [{"role": "assistant", "content": "STOP"}], "rejected": [{"role": "assistant", "content": "WHo is the author of the paper about the animal species of The animal genus with the most specific species?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHEN] When did northern ireland and southern ireland separate?"}], "chosen": [{"role": "assistant", "content": "I am not sure which period you refer to when you ask about Northern Ireland and southern Ireland."}], "rejected": [{"role": "assistant", "content": ""}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[EM|UNF] Is Gia parvif nutans a multicellular organism in terms of cellularity?"}], "chosen": [{"role": "assistant", "content": "WHAT: If by multicellular organism in terms of cellularity do you mean? Which type of cell are you referring to and what is your source citation?"}], "rejected": [{"role": "assistant", "content": ""}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[LA|LEX] What is the plot of Yentl?"}], "chosen": [{"role": "assistant", "content": "['WHO' Was the director of this movie?]"}], "rejected": [{"role": "assistant", "content": ""}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[LA|LEX] What is TDK's main product?"}], "chosen": [{"role": "assistant", "content": "WHAT is TDK's main product?"}], "rejected": [{"role": "assistant", "content": "WHAT is the difference between a straight and curly straw?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[LA|SEM] The sister-in-law told Amanda that she irritated the client.\nWho irritated the client?"}], "chosen": [{"role": "assistant", "content": "Does the sister-in-law who was speaking to you, or the other one, have you confused?"}], "rejected": [{"role": "assistant", "content": "oto"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHOM] When do episodes 122 of dragon ball super come out?"}], "chosen": [{"role": "assistant", "content": "WHAT WHO?"}], "rejected": [{"role": "assistant", "content": ""}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHEN] Who sings the song i'm on my way?"}], "chosen": [{"role": "assistant", "content": "WHAT song is she singing?"}], "rejected": [{"role": "assistant", "content": "WHAT song is the song that im On my way?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[EM|UNF] What is the latitude range of Visciaabra's habitat?"}], "chosen": [{"role": "assistant", "content": "STOP"}], "rejected": [{"role": "assistant", "content": "USER: He is not a source of data."}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHERE] When did battle of the sexes come out?"}], "chosen": [{"role": "assistant", "content": "WHOWHERE?"}], "rejected": [{"role": "assistant", "content": "WHAT SONGS ARE WE DOING WHEN?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHOM] Give me some Mother's Day gift ideas."}], "chosen": [{"role": "assistant", "content": "What type of gift do you mean, such as personal, material, or experiences?"}], "rejected": [{"role": "assistant", "content": "When do you come in with me?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHERE] Describe a plan for a road trip across Northern Italy"}], "chosen": [{"role": "assistant", "content": "WHAT ARE YOUR HIGHLIGHTS OF A ROLLINGSTONE?"}], "rejected": [{"role": "assistant", "content": "WHAT ARE DUE TO CALLED AND AMARIS IS A COUNTRY IN EASTERN EUROPE?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHERE] Where does the last name ketchum come from?"}], "chosen": [{"role": "assistant", "content": "Where does the last name Ketchum come from?"}], "rejected": [{"role": "assistant", "content": "In clarifying questions that contain unfamiliar entities or facts or self-contradictions, please ask them if they are familiar to you in any other way."}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[LA|LEX] What can you do with dough?"}], "chosen": [{"role": "assistant", "content": "Do you refer to the culinary ingredient or the slang term for money?"}], "rejected": [{"role": "assistant", "content": "So the question would be: What is the meaning of \"dough\" that you are referring to?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[EM|CONT] The all possible word categories are either \"male pronoun\" or \"religious leader\".\nThe following two examples share a specific word category. You need to first infer the specific word category from the examples.\nPlease output \"X\" if the given sentence mentions the specific word category. Please output \"Y\" if the given sentence does not mention the word category.\n\nExamples: \nShe is in the house with the sheriff.\nHe is in the courtroom with the pastor.\n\nThe Given Sentence: \nShe is in the restaurant with the cardinal."}], "chosen": [{"role": "assistant", "content": "WHOM"}], "rejected": [{"role": "assistant", "content": "I have to inferr the word category is which type. So, where is the word category present?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[LA|SEM] Melissa told Jennifer that the father-in-law lamented to her.\nWho did the father-in-law lament to?"}], "chosen": [{"role": "assistant", "content": "|output|Is the lament directed towards a singular entity or multiple entities?"}], "rejected": [{"role": "assistant", "content": "Alternatively, maybe \"her\" is female, but is she the sister or daughter?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[LA|LEX] What is the plot of Ballers?"}], "chosen": [{"role": "assistant", "content": "Is the plot in question about \"what\" is in a ball or what a basher is?"}], "rejected": [{"role": "assistant", "content": "What parts or individuals are unfamiliar in \"Ballers\"?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHOM] Who was the longest living president of the united states?"}], "chosen": [{"role": "assistant", "content": "None of the questions have to ask for the name of who was at the best state of the longest living president in the history of the United States."}], "rejected": [{"role": "assistant", "content": "WHAT WERE THE LATEST AND LATEST LATEST?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[LA|SEM] The sister-in-law left a note for Amanda because she is leaving the town soon.\nWho is leaving the town soon?"}], "chosen": [{"role": "assistant", "content": "(--EX: (The person in the town))"}], "rejected": [{"role": "assistant", "content": ""}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHERE] Who owns the property in a life estate?"}], "chosen": [{"role": "assistant", "content": "WHAT = ?"}], "rejected": [{"role": "assistant", "content": "WHAT is the law saying?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[LA|LEX] What is the meaning of 'Identical'?"}], "chosen": [{"role": "assistant", "content": "I need to generate a question that contains a word or name that needs more context."}], "rejected": [{"role": "assistant", "content": "WHAT IS THE MEANING OF WHAT IS THE MEANING OF THE MEANING?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[EM|UNF] When did ymovicia make its last appearance in the fossil record?"}], "chosen": [{"role": "assistant", "content": "What is this name referring to?"}], "rejected": [{"role": "assistant", "content": "What newts were found as a part of the fossil record?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHAT] Who wrote the songs in the greatest showman?"}], "chosen": [{"role": "assistant", "content": "Could you clarify which songs you are referring to in the context of \"the greatest showman\"? Are you asking about the original film or a specific album/storyline?"}], "rejected": [{"role": "assistant", "content": "WHAT"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHEN] Who sings the country song light it up?"}], "chosen": [{"role": "assistant", "content": "WHEN is: after?"}], "rejected": [{"role": "assistant", "content": "WHAT WER THE FIRST AND LAST?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[EM|CONT] The all possible word categories are either \"secular leader\" or \"female pronoun\".\nThe following two examples share a specific word category. You need to first infer the specific word category from the examples.\nPlease output \"X\" if the given sentence mentions the specific word category. Please output \"Y\" if the given sentence does not mention the word category.\n\nExamples: \nShe is in the grocery store with the ambassador.\nHe is in the restaurant with the Dalai Lama.\n\nThe Given Sentence: \nHe is in the restaurant with the officer."}], "chosen": [{"role": "assistant", "content": "Y"}], "rejected": [{"role": "assistant", "content": "Y"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHEN] When did the tv show dallas first air?"}], "chosen": [{"role": "assistant", "content": "WHAT TWENTY_FIRST: When?"}], "rejected": [{"role": "assistant", "content": "WHAT: OR WHEN: OR OR?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHAT] Who lost a lot of their power after the battle of culloden in 1746?"}], "chosen": [{"role": "assistant", "content": "WHAT=Wont who won the battle of Culloden in 1746?"}], "rejected": [{"role": "assistant", "content": ""}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[LA|SEM] Matthew lent Joshua some money before he answered the questions.\nWho answered the questions?"}], "chosen": [{"role": "assistant", "content": "WHOWhat or the other questions?"}], "rejected": [{"role": "assistant", "content": "NONE"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[LA|LEX] What is the meaning of \"frosty\"?"}], "chosen": [{"role": "assistant", "content": "在某个方括标中, \"frosty\"有什么含义?"}], "rejected": [{"role": "assistant", "content": "@end=\""}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[LA|LEX] What is the plot of McTeague?"}], "chosen": [{"role": "assistant", "content": "The plot of McTeague?"}], "rejected": [{"role": "assistant", "content": "MAKE S IDES (PLOT? WHO'S THAT? WHO IS THAT?)"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHEN] When is the last time fleetwood mac toured?"}], "chosen": [{"role": "assistant", "content": "WHAT IS THE LAST YEAR THAT THEY HAVE TURED"}], "rejected": [{"role": "assistant", "content": "WHAT WHEN IS THE LAST TIME ?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHEN] How many members are in the senate in france?"}], "chosen": [{"role": "assistant", "content": "WHAT is the output format from above?"}], "rejected": [{"role": "assistant", "content": "For example: \"Are you asking about 'Senate' or 'Chambre des Députés' (lower house) in France?\" But the user's error is in spelling, so the main confusion is whether the word is \"whamen"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[EM|CONT] The all possible word categories are either \"outdoor location\" or \"animal\".\nThe following two examples share a specific word category. You need to first infer the specific word category from the examples.\nPlease output \"X\" if the given sentence mentions the specific word category. Please output \"Y\" if the given sentence does not mention the word category.\n\nExamples: \nThe horse is in the woodlands.\nThe fugitive is in the film studio.\n\nThe Given Sentence: \nThe hiker is in the pond."}], "chosen": [{"role": "assistant", "content": "X"}], "rejected": [{"role": "assistant", "content": "Y"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHEN] Who plays steffy's mom on bold and the beautiful?"}], "chosen": [{"role": "assistant", "content": "WHO DOES THE SON LIVE WITH ON CANNELL STREET?"}], "rejected": [{"role": "assistant", "content": "WHAT are the movies where bold is the title and steffy is the title of the female lead?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHAT] When did india won the first cricket world cup?"}], "chosen": [{"role": "assistant", "content": "When did India won the first cricket world cup?"}], "rejected": [{"role": "assistant", "content": "WHAT do you mean when you asked \"WHOM\"?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHEN] Who scored 300 runs in test match for india?"}], "chosen": [{"role": "assistant", "content": "Who won the test match for India?"}], "rejected": [{"role": "assistant", "content": "WHAT IS YOUR AGE?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[LA|SEM] Matthew gave Joshua some money before he went on vacation.\nWho went on vacation?"}], "chosen": [{"role": "assistant", "content": "OVER?"}], "rejected": [{"role": "assistant", "content": "NONE"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[LA|SEM] Matthew told Joshua that the client despised him.\nWho did the client despise?"}], "chosen": [{"role": "assistant", "content": "/?"}], "rejected": [{"role": "assistant", "content": "END"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHEN] When is the world series of poker 2018?"}], "chosen": [{"role": "assistant", "content": "When is the world series of poker 2018?"}], "rejected": [{"role": "assistant", "content": "WHAT IS WHEN?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[EM|CONT] The all possible word categories are either \"indoor location\" or \"human\".\nThe following two examples share a specific word category. You need to first infer the specific word category from the examples.\nPlease output \"X\" if the given sentence mentions the specific word category. Please output \"Y\" if the given sentence does not mention the word category.\n\nExamples: \nThe researcher is in the laboratory.\nThe mountain lion is in the marsh.\n\nThe Given Sentence: \nThe snake is in the film studio."}], "chosen": [{"role": "assistant", "content": "Y"}], "rejected": [{"role": "assistant", "content": "WHO"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHERE] When did now you see me 2 come out?"}], "chosen": [{"role": "assistant", "content": "WHOTYPE"}], "rejected": [{"role": "assistant", "content": "WHAT? WHO LEFT?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[LA|SEM] Melissa told Jennifer that she dazzled the father-in-law.\nWho dazzled the father-in-law?"}], "chosen": [{"role": "assistant", "content": "PROBLEM:\"LEXICAL\": Query contains multiple terms with multiple meanings. When did she do that?"}], "rejected": [{"role": "assistant", "content": "WHAT is the first word that is a noun and can mean something?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHERE] When did it become necessary to have a driver's license?"}], "chosen": [{"role": "assistant", "content": "WHAT DID YOU MEAN? WHEN DID IT BECOME NECESSARY TO HAVE A DRIVER'S LICENSE?"}], "rejected": [{"role": "assistant", "content": "WHOWER?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[LA|LEX] What are some common themes found in Mythologies?"}], "chosen": [{"role": "assistant", "content": "@end What are the myths of other cultures?"}], "rejected": [{"role": "assistant", "content": "OVERWHELED:"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHERE] Where does dana air take off from in lagos?"}], "chosen": [{"role": "assistant", "content": "Which airport does the character fly from in Lagos?"}], "rejected": [{"role": "assistant", "content": "WHAT DOES THE AMBITATE OF A SPIRITS AND DAMPER?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHEN] Write a paragraph on how cricket format has evolved over time"}], "chosen": [{"role": "assistant", "content": "So answer: \"could you clarify with which time period you're referring to?\" or \"could you specify [when] you mean?\" **Clarifying Question:** [WHEN] Who or what specific time periods are you referring to when discussing the evolution of cricket format over time?"}], "rejected": [{"role": "assistant", "content": "WHOSE EYES SEEN?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[EM|CONT] The all possible word categories are either \"animal\" or \"outdoor location\".\nThe following two examples share a specific word category. You need to first infer the specific word category from the examples.\nPlease output \"X\" if the given sentence mentions the specific word category. Please output \"Y\" if the given sentence does not mention the word category.\n\nExamples: \nThe researcher is in the museum.\nThe hawk is in the woodlands.\n\nThe Given Sentence: \nThe director is in the meadow."}], "chosen": [{"role": "assistant", "content": "X"}], "rejected": [{"role": "assistant", "content": "WHOM"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHERE] Who helps santa claus in making his gifts?"}], "chosen": [{"role": "assistant", "content": "WHAT: Who helps Santa Claus in making gifts?"}], "rejected": [{"role": "assistant", "content": "WHAT DID WHOSE?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[LA|LEX] What is the meaning of Apocalypto?"}], "chosen": [{"role": "assistant", "content": "WH: Is Apocalyxo one name of the person?"}], "rejected": [{"role": "assistant", "content": "WHAT WHAT?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHEN] What bible does the catholic church use at mass?"}], "chosen": [{"role": "assistant", "content": "The Output should be a single clarifying question in one of the following formats. Please do not generate an answer, only a clarifying question. Categories: - EM (EPISODIC MISALIGNMENT): - LA (LINGUISTIC MISALIGNMENT): - AO (ALEATORIC MISALIGNMENT): - NONE (CLEAR): Subclasses: For EM: - UNF: when involving UNFAMILIAR elements - CONT: when involving CONTRADICATIONS For LA: - LEX: when involving LEXEMIC definitions present - SEM: when involving semantic ambiguity For AO: - WHOM: when involving WHOM present - WHEN: when involving WHEN present - WHERE: when involving WHERE present - WHAT: when involving WHAT present"}], "rejected": [{"role": "assistant", "content": "Which name version did the mother of god say the devil was her enemy? Which name did god say was true?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHAT] Who was the girl in cry me a river video?"}], "chosen": [{"role": "assistant", "content": "Is the girl in the video Cry Me a River Jenny?"}], "rejected": [{"role": "assistant", "content": ""}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[EM|CONT] The all possible word categories are either \"contains a negation\" or \"common noun\".\nThe following two examples share a specific word category. You need to first infer the specific word category from the examples.\nPlease output \"X\" if the given sentence mentions the specific word category. Please output \"Y\" if the given sentence does not mention the word category.\n\nExamples: \nHermione Granger could be in the laboratory.\nThe photographer was not in the restaurant.\n\nThe Given Sentence: \nNoam Chomsky has not been in the hotel lobby."}], "chosen": [{"role": "assistant", "content": "X"}], "rejected": [{"role": "assistant", "content": "WHAM"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[EM|CONT] The all possible word categories are either \"human\" or \"indoor location\".\nThe following two examples share a specific word category. You need to first infer the specific word category from the examples.\nPlease output \"X\" if the given sentence mentions the specific word category. Please output \"Y\" if the given sentence does not mention the word category.\n\nExamples: \nThe hiker is in the film studio.\nThe butterfly is in the marsh.\n\nThe Given Sentence: \nThe fugitive is in the woodlands."}], "chosen": [{"role": "assistant", "content": "X"}], "rejected": [{"role": "assistant", "content": "X Y"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[EM|UNF] Is Praina radiata multicellular or unicellular?"}], "chosen": [{"role": "assistant", "content": "Is Praina radiata multicellular or what other types?"}], "rejected": [{"role": "assistant", "content": "]"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHAT] Where did the saying just do it come from?"}], "chosen": [{"role": "assistant", "content": "Where is the idi \"just do it\" originated from?"}], "rejected": [{"role": "assistant", "content": "What's the origin of the phrase \"cold from the waist up, warm from the waist down\"?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHAT] Who wrote the jazz classic i got rhythm?"}], "chosen": [{"role": "assistant", "content": "WHO IS THE AUTHOR OF THE JAZZ CLASSIC \"I GOT RHYTHM\"?"}], "rejected": [{"role": "assistant", "content": "WHAT are the names of the musicians in i got rhythm"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHERE] Where is the billboard music awards 2017 held?"}], "chosen": [{"role": "assistant", "content": "What city or venue hosted the billboard music awards in 2017?"}], "rejected": [{"role": "assistant", "content": "Are you asking about Billboard magazine's music awards award event being held in any specific city?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHEN] Who is the secretary of state in arkansas?"}], "chosen": [{"role": "assistant", "content": "You are a candidate who asks clarifying questions. Where is the secretary of state's office located in Arkansas?"}], "rejected": [{"role": "assistant", "content": "WHAT is the secretary of state in arkansas?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHERE] How many acres is the great smoky mountains national park?"}], "chosen": [{"role": "assistant", "content": "WHAT IS THE ACRES OF THE GREAT SMOKY MOUNTAIN NATIONAL PARK?"}], "rejected": [{"role": "assistant", "content": "Can you specify which is it? Great smoky mountains or the black mountain national park?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[LA|LEX] What is the meaning of Ironweed?"}], "chosen": [{"role": "assistant", "content": "WHAT IS IRONWEED?"}], "rejected": [{"role": "assistant", "content": "WHAT is Ironweed?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[LA|SEM] The sister-in-law told Amanda that she saddened the client.\nWho saddened the client?"}], "chosen": [{"role": "assistant", "content": "--- Did your mother sister also try to cheer the client up?"}], "rejected": [{"role": "assistant", "content": ""}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[EM|CONT] The all possible word categories are either \"indoor location\" or \"human\".\nThe following two examples share a specific word category. You need to first infer the specific word category from the examples.\nPlease output \"X\" if the given sentence mentions the specific word category. Please output \"Y\" if the given sentence does not mention the word category.\n\nExamples: \nThe firefighter is in the courtroom.\nThe horse is in the meadow.\n\nThe Given Sentence: \nThe director is in the jungle."}], "chosen": [{"role": "assistant", "content": "X"}], "rejected": [{"role": "assistant", "content": "X"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHAT] Where did the houston texans football team come from?"}], "chosen": [{"role": "assistant", "content": "What league does the Houston Texans football team compete in?"}], "rejected": [{"role": "assistant", "content": "WHAT comes from where?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHAT] Where does final maturation of a sperm cell occur?"}], "chosen": [{"role": "assistant", "content": "Are you referring to where a sperm cell matures after final maturation?"}], "rejected": [{"role": "assistant", "content": "} At what time can be a human sperm cell?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[EM|CONT] The all possible word categories are either \"male pronoun\" or \"religious leader\".\nThe following two examples share a specific word category. You need to first infer the specific word category from the examples.\nPlease output \"X\" if the given sentence mentions the specific word category. Please output \"Y\" if the given sentence does not mention the word category.\n\nExamples: \nShe is in the restaurant with the professor.\nHe is in the hotel lobby with the pastor.\n\nThe Given Sentence: \nHe is in the theatre with the principal."}], "chosen": [{"role": "assistant", "content": "Y"}], "rejected": [{"role": "assistant", "content": "WHOM"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHOM] Who came up with the idea of survival of the fittest?"}], "chosen": [{"role": "assistant", "content": "I'm going to get a clarifying question asking which word can be replaced by __ who"}], "rejected": [{"role": "assistant", "content": "When did the evolution process begin?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHERE] What is the origin of the name david?"}], "chosen": [{"role": "assistant", "content": "Question: Could you clarify which specific context or cultural reference you are asking about regarding the origin of the name \"David\"?"}], "rejected": [{"role": "assistant", "content": "WHAT IS THE ORIGIN OF THE NAME david?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHOM] How do you train for a half marathon?"}], "chosen": [{"role": "assistant", "content": "SELF-CONFIRMING"}], "rejected": [{"role": "assistant", "content": "WHAT ARE THE BEST SPORTS?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHERE] When is the next star wars 9 coming out?"}], "chosen": [{"role": "assistant", "content": "WHAT_WHEN_NEWS"}], "rejected": [{"role": "assistant", "content": "WHAT"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHOM] Who did don mail meditations in an emergency to?"}], "chosen": [{"role": "assistant", "content": "is ...' or 'could you clarify which ...'?"}], "rejected": [{"role": "assistant", "content": ""}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHAT] What is the purpose of a chinese tea ceremony?"}], "chosen": [{"role": "assistant", "content": "Are they referring to multiple or a specific one?"}], "rejected": [{"role": "assistant", "content": "OVERALL WHAT is the purpose of a Japanese tea ceremony?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[EM|CONT] The all possible word categories are either \"animal\" or \"outdoor location\".\nThe following two examples share a specific word category. You need to first infer the specific word category from the examples.\nPlease output \"X\" if the given sentence mentions the specific word category. Please output \"Y\" if the given sentence does not mention the word category.\n\nExamples: \nThe student is in the theatre.\nThe boar is in the meadow.\n\nThe Given Sentence: \nThe director is in the marsh."}], "chosen": [{"role": "assistant", "content": "Y"}], "rejected": [{"role": "assistant", "content": "X"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[EM|CONT] The all possible word categories are either \"indoor location\" or \"human\".\nThe following two examples share a specific word category. You need to first infer the specific word category from the examples.\nPlease output \"X\" if the given sentence mentions the specific word category. Please output \"Y\" if the given sentence does not mention the word category.\n\nExamples: \nThe reporter is in the grocery store.\nThe hound is in the pond.\n\nThe Given Sentence: \nThe bear is in the apartment building."}], "chosen": [{"role": "assistant", "content": "Y"}], "rejected": [{"role": "assistant", "content": "X"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[EM|CONT] The all possible word categories are either \"does not contain a negation\" or \"proper noun\".\nThe following two examples share a specific word category. You need to first infer the specific word category from the examples.\nPlease output \"X\" if the given sentence mentions the specific word category. Please output \"Y\" if the given sentence does not mention the word category.\n\nExamples: \nAlexandria Ocasio-Cortez is in the apartment building.\nThe director could not be in the house.\n\nThe Given Sentence: \nThe director could be in the grocery store."}], "chosen": [{"role": "assistant", "content": "Y"}], "rejected": [{"role": "assistant", "content": "WHOM"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHEN] What's the population of walnut grove minnesota?"}], "chosen": [{"role": "assistant", "content": "WHAT IS THE POPULATION OF ?"}], "rejected": [{"role": "assistant", "content": "WHAT"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[EM|UNF] What's the average body mass of Marmota olympus?"}], "chosen": [{"role": "assistant", "content": "IN THE MAMAROTTA?"}], "rejected": [{"role": "assistant", "content": "Who is the Marmota olympus?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHOM] Pick the best starting five from all players in NBA history"}], "chosen": [{"role": "assistant", "content": "PLEASE_"}], "rejected": [{"role": "assistant", "content": "What position should I pick?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[EM|CONT] The all possible word categories are either \"human\" or \"indoor location\".\nThe following two examples share a specific word category. You need to first infer the specific word category from the examples.\nPlease output \"X\" if the given sentence mentions the specific word category. Please output \"Y\" if the given sentence does not mention the word category.\n\nExamples: \nThe butterfly is in the canyon.\nThe student is in the apartment building.\n\nThe Given Sentence: \nThe surveyor is in the marsh."}], "chosen": [{"role": "assistant", "content": "Y"}], "rejected": [{"role": "assistant", "content": "Y"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHOM] Give me some ideas for Halloween costumes."}], "chosen": [{"role": "assistant", "content": "The user wants clarification for the word \"whom\" in the sentence. I'll ask who in the given context.\\ Who?"}], "rejected": [{"role": "assistant", "content": "WHAT IS THE TOP costume for Halloween in New York right now?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[EM|CONT] The all possible word categories are either \"human\" or \"indoor location\".\nThe following two examples share a specific word category. You need to first infer the specific word category from the examples.\nPlease output \"X\" if the given sentence mentions the specific word category. Please output \"Y\" if the given sentence does not mention the word category.\n\nExamples: \nThe worm is in the prairie.\nThe reporter is in the house.\n\nThe Given Sentence: \nThe firefighter is in the meadow."}], "chosen": [{"role": "assistant", "content": "output: Y X|Y X|Y X|Y X|Y X|Y X|Y X|Y X|Y X|Y X|Y X|Y X|Y X|Y X|Y X|Y X|Y X|Y X|Y X| lex."}], "rejected": [{"role": "assistant", "content": "X"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[EM|UNF] What is the latitude range of Clun africanus's habitat?"}], "chosen": [{"role": "assistant", "content": "INFORMATION: Do you mean location for the geographic area of the species?"}], "rejected": [{"role": "assistant", "content": "FILTER: Are you asking about any specific location where Clun Africanus can be found?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHERE] Where did they escape to in the sound of music?"}], "chosen": [{"role": "assistant", "content": "WHOWEB (Where are they going to in the sound of music?)"}], "rejected": [{"role": "assistant", "content": "WHAT is a character name in the musical Les Miser?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[EM|UNF] What is the level of body symmetry exhibited by MacStatira?"}], "chosen": [{"role": "assistant", "content": "Therefore, the appropriate clarifying question is: \"Is the entity familiar or unfamiliar?\" Clarifying question: Is the entity familiar or unfamiliar?"}], "rejected": [{"role": "assistant", "content": "_END"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHAT] Who was blamed for the explosion of the uss maine?"}], "chosen": [{"role": "assistant", "content": "I'm really confused about who was blamed for the explosion of the uss maine. Is it the Spanish or Mexican?"}], "rejected": [{"role": "assistant", "content": ""}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHERE] Who invented the process to remove impurities by blasts of cold air blown through heated iron?"}], "chosen": [{"role": "assistant", "content": "WHAT = ?"}], "rejected": [{"role": "assistant", "content": "WHAT? WHAT"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHOM] Actor who plays chuck on better call saul?"}], "chosen": [{"role": "assistant", "content": "What is the full name of the actor who plays chuck on better call saul?"}], "rejected": [{"role": "assistant", "content": "Which actors playing the role of chucky?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[LA|SEM] Matthew emailed Joshua because he has an important interview tomorrow.\nWho has an important interview tomorrow?"}], "chosen": [{"role": "assistant", "content": "VOID"}], "rejected": [{"role": "assistant", "content": ""}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[LA|SEM] The sister-in-law made Amanda a cake after she went back home.\nWho went back home?"}], "chosen": [{"role": "assistant", "content": "WHAM?"}], "rejected": [{"role": "assistant", "content": "I can't help you."}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHAT] Who won the womens curling winter olympics 2018?"}], "chosen": [{"role": "assistant", "content": "REFERRED: Who won what team first?"}], "rejected": [{"role": "assistant", "content": "Is the team you won against?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[LA|SEM] The sister-in-law left a note for Amanda because she is leaving town next week.\nWho is leaving town next week?"}], "chosen": [{"role": "assistant", "content": "(--CLEAR) Is the note being referred to the one left by the sister-in-law or the one left by Amanda?"}], "rejected": [{"role": "assistant", "content": ""}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHEN] Who sang the national anthem at the superbowl?"}], "chosen": [{"role": "assistant", "content": "WHAT WINS? You? Or Batman?"}], "rejected": [{"role": "assistant", "content": "WHAT DOES FRZ HWNGN MEAN I LOVE SPONG THE SPONG?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHAT] Tell me few brainstorming techniques"}], "chosen": [{"role": "assistant", "content": "WHOM"}], "rejected": [{"role": "assistant", "content": "WHAT IS THE ANCESTOR OF DOG"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHAT] How does a zipper work?"}], "chosen": [{"role": "assistant", "content": "STOP"}], "rejected": [{"role": "assistant", "content": "END"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[LA|SEM] The sister-in-law called Amanda because she is leaving the town soon.\nWho is leaving the town soon?"}], "chosen": [{"role": "assistant", "content": "So the question should be: \"Is 'she' the sister-in-law or Amanda who is leaving the town soon?\" or \"Is Amanda or the sister-in-law leaving the town?\" But the exact format for"}], "rejected": [{"role": "assistant", "content": ""}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[EM|CONT] The all possible word categories are either \"animal\" or \"outdoor location\".\nThe following two examples share a specific word category. You need to first infer the specific word category from the examples.\nPlease output \"X\" if the given sentence mentions the specific word category. Please output \"Y\" if the given sentence does not mention the word category.\n\nExamples: \nThe butterfly is in the marsh.\nThe fugitive is in the courtroom.\n\nThe Given Sentence: \nThe surveyor is in the woodlands."}], "chosen": [{"role": "assistant", "content": "Y"}], "rejected": [{"role": "assistant", "content": "Y"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHOM] Maddie from suite life of zack and cody full name?"}], "chosen": [{"role": "assistant", "content": "FLAGS: Is the full name of maddie from Suite Life of zack and cody?"}], "rejected": [{"role": "assistant", "content": "WHAT=WHOW?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHEN] Who played the chicago cubs in the world series last year?"}], "chosen": [{"role": "assistant", "content": "WHAT DOES YOU MEAN \"LAST YEAR\"? IS U SUGGERING A PARTICULAR DAY OR A SPECIFIC PARTY?"}], "rejected": [{"role": "assistant", "content": "WHAT IS THE WHO / WHEN / WHARE/ WHEN"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[EM|UNF] What's the average diameter of the cells of Pomozygosphaera?"}], "chosen": [{"role": "assistant", "content": "For example, \"Do you mean the cells within the organism [Name] or specific cells (like epithelial cells, neurons, etc.) of Pomozygosphaea?\" That way, the user can confirm whether they have the correct name and provide additional details."}], "rejected": [{"role": "assistant", "content": "/none What is the target organism (other than Pomozygosphaera) for which you want to find the average cell diameter?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHEN] How early can you buy alcohol in maine?"}], "chosen": [{"role": "assistant", "content": "WHAT IS THE EARLIEST TIME YOU CAN BUY AL?"}], "rejected": [{"role": "assistant", "content": "The email is too confusing. Can you specify whether you're asking about the best, most current or earliest time to come up with alcohol?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[EM|UNF] Does Broad bean wilt virus 1 have Bupleurum chinense as a host?"}], "chosen": [{"role": "assistant", "content": "END_OF_RUN"}], "rejected": [{"role": "assistant", "content": "INSIST: Who left the room without any clues?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHEN] Who was the man who escaped from alcatraz?"}], "chosen": [{"role": "assistant", "content": "When did he escape from alcatraz?"}], "rejected": [{"role": "assistant", "content": "WHAT DO YOU MEAN WHEN ?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[LA|SEM] William told Joshua that he enticed the saleswoman.\nWho enticed the saleswoman?"}], "chosen": [{"role": "assistant", "content": "NONE"}], "rejected": [{"role": "assistant", "content": "WHAM: WHO? WHO? WHO? WHO? WHO? WHO? WHOM? WHO? WHO?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[EM|CONT] The all possible word categories are either \"does not contain a negation\" or \"proper noun\".\nThe following two examples share a specific word category. You need to first infer the specific word category from the examples.\nPlease output \"X\" if the given sentence mentions the specific word category. Please output \"Y\" if the given sentence does not mention the word category.\n\nExamples: \nMargot Robbie has been in the hotel lobby.\nThe student could not be in the hotel lobby.\n\nThe Given Sentence: \nThe critic may be in the film studio."}], "chosen": [{"role": "assistant", "content": "X|WHOSP"}], "rejected": [{"role": "assistant", "content": "WHOM"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[EM|UNF] What is the total life span of Tursiops aduncus?"}], "chosen": [{"role": "assistant", "content": "Therefore, the clarifying question should be: Is \"Tursiops aduncus\" referring to the common dolphin species, or is it a specific entity known by another name that you might be referring to?"}], "rejected": [{"role": "assistant", "content": "I need to output one."}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHOM] Who died in harry potter half blood prince?"}], "chosen": [{"role": "assistant", "content": "I'm a wizard."}], "rejected": [{"role": "assistant", "content": "WHAT IS YOUR FAVORITE PIE?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[EM|UNF] What is the longitude of Parametra orion's habitat?"}], "chosen": [{"role": "assistant", "content": "So perhaps: \"Are you referring to Parametra as a familiar or unfamiliar entity, and what is Orion's habitat in this context?\" Hmm, but that's two separate questions in one."}], "rejected": [{"role": "assistant", "content": "STOP"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[EM|CONT] The all possible word categories are either \"indoor location\" or \"human\".\nThe following two examples share a specific word category. You need to first infer the specific word category from the examples.\nPlease output \"X\" if the given sentence mentions the specific word category. Please output \"Y\" if the given sentence does not mention the word category.\n\nExamples: \nThe butterfly is in the prairie.\nThe director is in the laboratory.\n\nThe Given Sentence: \nThe student is in the jungle."}], "chosen": [{"role": "assistant", "content": "X"}], "rejected": [{"role": "assistant", "content": "X"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[LA|LEX] What is the cure for Cured?"}], "chosen": [{"role": "assistant", "content": "WHAT IS THE CURE FOR CURING?"}], "rejected": [{"role": "assistant", "content": "WHAT IS THE CURE OF TOBACCO?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHERE] Where was once i was a beehive filmed?"}], "chosen": [{"role": "assistant", "content": "Which location was once i was a beehive filmed?"}], "rejected": [{"role": "assistant", "content": "WHAT= ?!"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[LA|LEX] How can a piece of thin and flexible sheet metal hinder or prevent efforts, plans, or desires?"}], "chosen": [{"role": "assistant", "content": "Could you please clarify which term you meant by \"sheet metal\" in this context, or provide additional details about the metal's expected use or characteristics?"}], "rejected": [{"role": "assistant", "content": "So the final output should be: \"Can you please clarify whether you want to know about hinder or prevent, or provide definitions for both terms?\" or \"Which term are you referring to: hinder or prevent?\" but according"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHOM] When did the singer of alice in chains die?"}], "chosen": [{"role": "assistant", "content": "So the user wants to know the year when the singer died, but who is the singer?"}], "rejected": [{"role": "assistant", "content": "Is the user referring to the band Alice in Chains, the band member, or the individual?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[EM|UNF] Is the life cycle habit of Trollius europaeus perennial?"}], "chosen": [{"role": "assistant", "content": "What does \"habit\" in this context refer to: a) the location of work (e.g., the presence of a garden) or b) the physical structure in which a plant lives?"}], "rejected": [{"role": "assistant", "content": "QUESTION: WHO IS LIVING IN THE SUBDIVISION?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[EM|CONT] The all possible word categories are either \"religious leader\" or \"male pronoun\".\nThe following two examples share a specific word category. You need to first infer the specific word category from the examples.\nPlease output \"X\" if the given sentence mentions the specific word category. Please output \"Y\" if the given sentence does not mention the word category.\n\nExamples: \nShe is in the apartment building with the principal.\nHe is in the laboratory with the cardinal.\n\nThe Given Sentence: \nShe is in the restaurant with the deacon."}], "chosen": [{"role": "assistant", "content": "Y"}], "rejected": [{"role": "assistant", "content": "WHERE"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[EM|UNF] Does Anthidium atorense have Lamiaceae as its host?"}], "chosen": [{"role": "assistant", "content": "NAME: Does Anthidium attorose have Lamiaceae as its host?"}], "rejected": [{"role": "assistant", "content": "PROHIBITED RESPONSE: A clarifying question?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[EM|UNF] Can bireidea perform quadrupedal movement locomotion?"}], "chosen": [{"role": "assistant", "content": "PLEASE outputs: [EM|UNF]"}], "rejected": [{"role": "assistant", "content": "WHOWW IN SUBCLASSES: EM|UNF: UNF."}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHOM] Who is faith newman on the young and the restless?"}], "chosen": [{"role": "assistant", "content": "I'm having trouble identifying who newman is, because there are multiple Newmans mentioned in different contexts. Please clarify who you could identify."}], "rejected": [{"role": "assistant", "content": ""}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHOM] Name of attorney in to kill a mockingbird?"}], "chosen": [{"role": "assistant", "content": "Which attorney?"}], "rejected": [{"role": "assistant", "content": ""}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHERE] Where is the netflix series free rein filmed?"}], "chosen": [{"role": "assistant", "content": "Which location is the netflix series free rein filmed at?"}], "rejected": [{"role": "assistant", "content": "Are you asking if the show was filmed in one of the following locations: [List specific filming locations] or a fictional place?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[LA|SEM] The sister-in-law baked Amanda some egg tarts after she got off work.\nWho got off work?"}], "chosen": [{"role": "assistant", "content": "NONE"}], "rejected": [{"role": "assistant", "content": "Is it just one sister-in-law or both?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHEN] Who has played hope on the bold and the beautiful?"}], "chosen": [{"role": "assistant", "content": "WHAT: Do the team have a female player?"}], "rejected": [{"role": "assistant", "content": "WHAT does it mean when you are in love with people?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[EM|CONT] The all possible word categories are either \"animal\" or \"outdoor location\".\nThe following two examples share a specific word category. You need to first infer the specific word category from the examples.\nPlease output \"X\" if the given sentence mentions the specific word category. Please output \"Y\" if the given sentence does not mention the word category.\n\nExamples: \nThe firefighter is in the restaurant.\nThe duck is in the canyon.\n\nThe Given Sentence: \nThe hound is in the film studio."}], "chosen": [{"role": "assistant", "content": "Y"}], "rejected": [{"role": "assistant", "content": "Y"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[EM|CONT] The all possible word categories are either \"animal\" or \"outdoor location\".\nThe following two examples share a specific word category. You need to first infer the specific word category from the examples.\nPlease output \"X\" if the given sentence mentions the specific word category. Please output \"Y\" if the given sentence does not mention the word category.\n\nExamples: \nThe critic is in the theatre.\nThe hound is in the jungle.\n\nThe Given Sentence: \nThe hound is in the laboratory."}], "chosen": [{"role": "assistant", "content": "Y"}], "rejected": [{"role": "assistant", "content": "Y"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[LA|SEM] Kimberly told the aunt that the granddaughter respected her.\nWho did the granddaughter respect?"}], "chosen": [{"role": "assistant", "content": "Therefore, the output is: \"Did the granddaughter respect the aunt or someone else?\" But since the categories for EM||SEM, the main issue is the referent."}], "rejected": [{"role": "assistant", "content": "think( Hmm, the user provided a query with semantic ambiguity. The main issue here is that the verb \"respected\" can take different noun complements. The sentence mentions \"the aunt\" and \"the granddaughter\", but the question is asking \"Who did the granddaughter respect?\" with the tags indicating a semantic ambiguity. First, I need to check if the original processing missed the specific entity that the verb object is referring to. The options provided in the sentence are between aunt and granddaughter, but the question is ambiguous. So, I need to ask which one was intended. Let me look at each part: Who did the granddaughter respect? Aunt or the descendant? I need to ask for clarification on whether the granddaughter respected the aunt or the other person (assuming there could be other relationship). I should include both possibilities in the clarifying question. Wait, better approach is to ask if the user meant whether the granddaughter respected the aunt or the other person. So, the possible ambiguous terms here are 'aunt' and 'granddaughter'. I need to generate a clear question asking to specify whether the verb's object refers to 'aunt' or the alternative person. Since the original words contain both \"aunt\" and \"granddaughter,\" I must ask which one is correct. I should ask: Does the granddaughter respect the aunt or the other person? Or something like: Does \"respected\" apply to the aunt or the assistant? Wait I need to mention if there is multiple meanings. Wait, which one is ambiguous? The query is with SEM because it's not clear which entity the verb applies to. I need to ask if the user means to clarify which entity. So I'll form a question explicitly asking whether \"who\" refers to the aunt or the other person. I need to ask the clarifying question clearly. I can say: Cl: Does the verb-object relationship refer to the aunt or the other person? Wait, I need to generate: Is the verb-object of \"respected\" referring to the aunt or the other entity? Thus, generate clarifying question: Which did the granddaughter respect: the aunt or the other entity? Final generate question: Does the verb-object relationship refer to the aunt or the other entity? I need to generate a concise clarifying question that is unambiguous. I'll generate: Does the verb-object relationship refer to the aunt or the other entity? Thus output a clear one."}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[EM|UNF] What's the longitude of the location where Hanleyaaleyi was found?"}], "chosen": [{"role": "assistant", "content": "The original query: What's the longitude of the location where Hanleyaaleyi was found?"}], "rejected": [{"role": "assistant", "content": "END"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHOM] Provide a 10-step flow for a heterosexual couple's non-religious wedding ceremony."}], "chosen": [{"role": "assistant", "content": "Alternatively, is the user asking about a specific couple or a general category?"}], "rejected": [{"role": "assistant", "content": "WHAT IS THE LAY-OUT?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHAT] Where was the movie journey to the center of the earth filmed?"}], "chosen": [{"role": "assistant", "content": "WHAT?"}], "rejected": [{"role": "assistant", "content": "WHOWAS"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHERE] What is the meaning of the name melanie?"}], "chosen": [{"role": "assistant", "content": "Is this a misspelling of another name?"}], "rejected": [{"role": "assistant", "content": "What is the name that Melanie has multiple meanings?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[LA|LEX] What is the role of a counter in a business transaction?"}], "chosen": [{"role": "assistant", "content": "In the absence of additional context, who is the counter?"}], "rejected": [{"role": "assistant", "content": "VOID: Who was his role in the business transaction?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHOM] Give me ideas of ways to add a spicy kick to my pho."}], "chosen": [{"role": "assistant", "content": "WHAT HAS SPICY PAN MAS?"}], "rejected": [{"role": "assistant", "content": "WHAT DOES DICK HAVE?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[EM|CONT] The all possible word categories are either \"common noun\" or \"contains a negation\".\nThe following two examples share a specific word category. You need to first infer the specific word category from the examples.\nPlease output \"X\" if the given sentence mentions the specific word category. Please output \"Y\" if the given sentence does not mention the word category.\n\nExamples: \nThe hiker has not been in the film studio.\nMargot Robbie may be in the grocery store.\n\nThe Given Sentence: \nThe researcher was in the film studio."}], "chosen": [{"role": "assistant", "content": "X"}], "rejected": [{"role": "assistant", "content": "Y"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHAT] What is a black spider with yellow stripes?"}], "chosen": [{"role": "assistant", "content": "WHAT are you referring to: a black spider with yellow stripes?"}], "rejected": [{"role": "assistant", "content": "C: Where is where?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHAT] Who played the butcher on the brady bunch?"}], "chosen": [{"role": "assistant", "content": "WHAT who played the butcher on the brady bunch?"}], "rejected": [{"role": "assistant", "content": ""}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[EM|UNF] What's the body length of Alacia valdiviae?"}], "chosen": [{"role": "assistant", "content": "OVER 11 M IN"}], "rejected": [{"role": "assistant", "content": "INTERN (WHOWHAT OR WHAT)?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHOM] Give me some movie/tv series to learn English"}], "chosen": [{"role": "assistant", "content": "|output|What is your preferred entertainment medium? Movie or TV series?"}], "rejected": [{"role": "assistant", "content": "x Who said?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[EM|UNF] In which geological period did Luarchasioglires first appear?"}], "chosen": [{"role": "assistant", "content": "Identify the specific geological period (e.g., Cambrian, Ordovician, or Silurian) that the species mentioned first appeared."}], "rejected": [{"role": "assistant", "content": "OVERALL_EXPLANATIONAL_QUESTION: In which geological period did Luarchasioglires first appear? _Which?: which?: [EM] What? When?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHEN] When's the last time notre dame played georgia?"}], "chosen": [{"role": "assistant", "content": "WHAT is the last time north rene played georgia?"}], "rejected": [{"role": "assistant", "content": "WHAT_WHEN_GO?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHERE] What is the triangular shaped area at each end of the greek temple called?"}], "chosen": [{"role": "assistant", "content": "So the clarifying question should be: Which part of the Greek temple is the user referring to when they mention the triangular shaped area?"}], "rejected": [{"role": "assistant", "content": "Is where you mean the place?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[LA|LEX] What is the average temperature in Marbella?"}], "chosen": [{"role": "assistant", "content": "Can you clarify which geographic location you are referring to with \"Marbella\"?"}], "rejected": [{"role": "assistant", "content": ""}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[EM|UNF] What's the latitude range where Oarcinidae is found?"}], "chosen": [{"role": "assistant", "content": "PROBLEM: You are an assistant bot. You need to generate a clarifying question as a concise output based on the input ambiguity type. The input is ambiguous and may require clarification. Thus, you need to output a clarification question or, if it requires no clarification, 'no clarification needed'. Output Format: If clarification is needed: 'Context: [EM|UNF]' 'Question:' Else: 'Context: [EM|UNF]' 'Question:']'"}], "rejected": [{"role": "assistant", "content": "WHo is the Oarcinidae?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHEN] What is the name of the casino in evansville indiana?"}], "chosen": [{"role": "assistant", "content": "WHAT IS THE NAME OF THE CARNABAR?"}], "rejected": [{"role": "assistant", "content": "WHO IS WARD OFF THE CARRIER?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHAT] Tell me whether these states are in Eastern Time, Central Time, or neither"}], "chosen": [{"role": "assistant", "content": "So I'll output: \"Which states are you referring to in your question?\" or \"Could you please specify which states you are talking about?\" The instructions require output in a clarifying question not explanation."}], "rejected": [{"role": "assistant", "content": "WHAT are European country's capitals?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHAT] When does season 7 of game of thrones finish?"}], "chosen": [{"role": "assistant", "content": "Is the question referring to the season's end when the actors return from filming?"}], "rejected": [{"role": "assistant", "content": "WHAT who do you get when I want to start fighting with him? Who is always angry and hits more than her name is? Who who who if if one of the following colors always hit the first? Who who if who will always be the shortest in the race?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[LA|SEM] Kimberly told the aunt that she entertained the granddaughter.\nWho entertained the granddaughter?"}], "chosen": [{"role": "assistant", "content": "NAME"}], "rejected": [{"role": "assistant", "content": "END"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHAT] When is the last time georgia played in the sec championship?"}], "chosen": [{"role": "assistant", "content": "REFERRED: Who did the user meant?"}], "rejected": [{"role": "assistant", "content": "WHAT: WHO??? WHO WERE?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[LA|LEX] Where is Away located?"}], "chosen": [{"role": "assistant", "content": "ASSISTANT: Can you specify the type of setting where you're looking for the location of \"Away\"?"}], "rejected": [{"role": "assistant", "content": "WHOM: WHO or WHAT?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHOM] A person who speaks several languages is called?"}], "chosen": [{"role": "assistant", "content": "So, the correct clarifying question would be: Are you asking about a specific person, a category of people, or the use of a title or name?"}], "rejected": [{"role": "assistant", "content": "|output|Is the person a child?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[LA|LEX] What is the key to successful cutting?"}], "chosen": [{"role": "assistant", "content": "But perhaps a more specific example: Does \"key\" refer to a musical key (like C major) or a key in a physical tool (like a steak knife)?"}], "rejected": [{"role": "assistant", "content": ""}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHEN] Who won the super bowl patriots or falcons?"}], "chosen": [{"role": "assistant", "content": "WHAT is the super bowl patrios or falcons?"}], "rejected": [{"role": "assistant", "content": "WHAT WHO WHO WHO WHO WHOWOW? WHO WIN WHO WIN WHO- IN"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[EM|CONT] The all possible word categories are either \"female pronoun\" or \"secular leader\".\nThe following two examples share a specific word category. You need to first infer the specific word category from the examples.\nPlease output \"X\" if the given sentence mentions the specific word category. Please output \"Y\" if the given sentence does not mention the word category.\n\nExamples: \nHe is in the courtroom with the pastor.\nShe is in the house with the prime minister.\n\nThe Given Sentence: \nShe is in the restaurant with the bishop."}], "chosen": [{"role": "assistant", "content": "Y"}], "rejected": [{"role": "assistant", "content": "WHAM?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[EM|UNF] What's the latitude range where Magilaoma is found?"}], "chosen": [{"role": "assistant", "content": "PROBLEM: the query does not clarify which species CATEGORY: EM|UNF The query contains unfamiliar entities When which species?"}], "rejected": [{"role": "assistant", "content": "EM"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[EM|CONT] The all possible word categories are either \"secular leader\" or \"female pronoun\".\nThe following two examples share a specific word category. You need to first infer the specific word category from the examples.\nPlease output \"X\" if the given sentence mentions the specific word category. Please output \"Y\" if the given sentence does not mention the word category.\n\nExamples: \nShe is in the restaurant with the prime minister.\nHe is in the laboratory with the rabbi.\n\nThe Given Sentence: \nHe is in the grocery store with the prime minister."}], "chosen": [{"role": "assistant", "content": "Y"}], "rejected": [{"role": "assistant", "content": "Y"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHERE] What is the origin of the name rhoda?"}], "chosen": [{"role": "assistant", "content": "Therefore, the best clarifying question would be: \"Are you asking about the origin of the name 'Rhoda' or the origin of a person named Rhoda?\" But since the output requires one question, perhaps the assistant should choose the primary ambiguity."}], "rejected": [{"role": "assistant", "content": "Who is rhoda trying to reference when using the name Rhoda?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHERE] Who was the oldest president when he took office?"}], "chosen": [{"role": "assistant", "content": "WHEN was the oldest president when he took office?"}], "rejected": [{"role": "assistant", "content": "WHAT [IS] WHAT"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[LA|SEM] Matthew left a voicemail for Joshua because he is leaving the town soon.\nWho is leaving the town soon?"}], "chosen": [{"role": "assistant", "content": "Is it Matthew or Joshua who is leaving the town soon?"}], "rejected": [{"role": "assistant", "content": "So the output clarifying question should ask either UNF options, such as does he leave town (?), but the output question should be of UNF."}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHAT] Who created the first monotheism known in history?"}], "chosen": [{"role": "assistant", "content": "OVER 12,600 years ago."}], "rejected": [{"role": "assistant", "content": ""}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHEN] Where is the new york comic con held?"}], "chosen": [{"role": "assistant", "content": "WHAT COMICON?"}], "rejected": [{"role": "assistant", "content": "WHAT IS UNF?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHEN] Last time a nhl player scored 5 goals?"}], "chosen": [{"role": "assistant", "content": "WHAT_NICE_PLAYER_IS_HAI?"}], "rejected": [{"role": "assistant", "content": "WHAT UNIFORM IS THE BLUE NOT SHOT INTO?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[EM|UNF] Does Chacojos live in hammock habitat?"}], "chosen": [{"role": "assistant", "content": "Hmm, which location in the 15 cm?"}], "rejected": [{"role": "assistant", "content": "WHAT SAGE ALIEN BEG YOU? In which planet?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHOM] How can I decide what bike I should get?"}], "chosen": [{"role": "assistant", "content": "What are the specific requirements for the bike?"}], "rejected": [{"role": "assistant", "content": "bWHOW Who am I deciding what bike I should get?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[LA|LEX] What is the purpose of the vault?"}], "chosen": [{"role": "assistant", "content": "The example's input is: [EM|UNF] What is the purpose of the vault?"}], "rejected": [{"role": "assistant", "content": "Wait, the main category is which one?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHERE] Where does the saying said the actress to the bishop come from?"}], "chosen": [{"role": "assistant", "content": "WHEN DID THE BRIDGE CITY BATTLE CITY?"}], "rejected": [{"role": "assistant", "content": "OVER 1000"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[LA|SEM] The sister-in-law gave Amanda a sticker after she ate the dessert.\nWho ate the dessert?"}], "chosen": [{"role": "assistant", "content": "WHEN?"}], "rejected": [{"role": "assistant", "content": "NONE Based on the situation, the input does not contain any additional context."}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[EM|UNF] Is the trophic guild of Pilea microardii a trophic guild?"}], "chosen": [{"role": "assistant", "content": "The output question: \"EM|UNF: Do you know the term 'troic guild' or entity in this context?\" Output: EM|UNF: Do you know the term or entity in this context?"}], "rejected": [{"role": "assistant", "content": ""}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[EM|CONT] The all possible word categories are either \"female pronoun\" or \"secular leader\".\nThe following two examples share a specific word category. You need to first infer the specific word category from the examples.\nPlease output \"X\" if the given sentence mentions the specific word category. Please output \"Y\" if the given sentence does not mention the word category.\n\nExamples: \nShe is in the house with the sheriff.\nHe is in the laboratory with the imam.\n\nThe Given Sentence: \nShe is in the film studio with the pastor."}], "chosen": [{"role": "assistant", "content": "Y"}], "rejected": [{"role": "assistant", "content": "X"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[LA|SEM] Matthew built Joshua a castle after he hired a boat to explore local creeks.\nWho hired a boat to explore local creeks?"}], "chosen": [{"role": "assistant", "content": "So if Matthew built Joshua's castle, but the hiring was done by someone else?"}], "rejected": [{"role": "assistant", "content": "['WHO] Is it Matthew or is it the original person he hired an assistant magician to construct a castle?']"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHAT] Who has the most wins in an mlb season?"}], "chosen": [{"role": "assistant", "content": "After who or which team? /note"}], "rejected": [{"role": "assistant", "content": "WHAT"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHAT] What do you call a ten sided shape?"}], "chosen": [{"role": "assistant", "content": "WHOWHAT"}], "rejected": [{"role": "assistant", "content": "END"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[EM|UNF] Is Exgestilia currently extant?"}], "chosen": [{"role": "assistant", "content": "EM: Is the entity of exgestilia currently extant?"}], "rejected": [{"role": "assistant", "content": "Which planet?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHOM] Who led the committee of public safety apex?"}], "chosen": [{"role": "assistant", "content": "/SYS] What is the correct name of the person referred to as Gopinath Chattopadhyuer in the committee of public safety apex?"}], "rejected": [{"role": "assistant", "content": "It is crucial to determine the appropriate clarifying question context."}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[LA|LEX] What is the meaning of Wah-Wah?"}], "chosen": [{"role": "assistant", "content": "ooter question can contain unfamiliar entities or facts"}], "rejected": [{"role": "assistant", "content": "在这句话中出现了EM(EM)pistemic Ambiguity LEXAL(LEX)"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHOM] Give me a list of six different types of flowers I could buy someone"}], "chosen": [{"role": "assistant", "content": "/Alice should generate one clarifying question: For how many people should I fill in the list?"}], "rejected": [{"role": "assistant", "content": ""}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHEN] Who won the smackdown tag team champions at money in the bank?"}], "chosen": [{"role": "assistant", "content": "WHAT: Who won the Smackdown the Tag?"}], "rejected": [{"role": "assistant", "content": "## Task : Output: Please write what? ### Output: Where in Spain does this person work?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[LA|SEM] The son told Robert that he exhausted Brian.\nWho exhausted Brian?"}], "chosen": [{"role": "assistant", "content": "(WHEN) Does \"he\" refer to the son or Brian?"}], "rejected": [{"role": "assistant", "content": "WHAT?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHAT] How do you install a wooden fence?"}], "chosen": [{"role": "assistant", "content": "NONE"}], "rejected": [{"role": "assistant", "content": "DOCTYPE: WHEN IS THE BEST CLARETION:"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[EM|UNF] Does mitziella belong to the ecomorphological guild of amoeba?"}], "chosen": [{"role": "assistant", "content": "Mr. X. The name \"mitziaella\" does not refer to ecomorphological associations of \"amoeba\". Which context does it refer to or what?"}], "rejected": [{"role": "assistant", "content": "what's the origin of a mitziella?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[LA|SEM] The sister-in-law brought Amanda a gift after she moved in.\nWho moved in?"}], "chosen": [{"role": "assistant", "content": "STOP"}], "rejected": [{"role": "assistant", "content": "PLS WHICH SISTER-IN-LAW, IS OR IS NOT, AND THE ONE WHO MOVED IN, PLEASE?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHERE] What term do we use for the lowest layer of the atmosphere?"}], "chosen": [{"role": "assistant", "content": "MAKE DID YOU MEAN TURBONAUT?"}], "rejected": [{"role": "assistant", "content": "contains unfamiliar."}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHOM] Make a bullet list of 5 gifts you can give someone for Valentine's Day"}], "chosen": [{"role": "assistant", "content": "Clear format: One clarifying question"}], "rejected": [{"role": "assistant", "content": "What name is being used in the list?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[EM|CONT] The all possible word categories are either \"indoor location\" or \"human\".\nThe following two examples share a specific word category. You need to first infer the specific word category from the examples.\nPlease output \"X\" if the given sentence mentions the specific word category. Please output \"Y\" if the given sentence does not mention the word category.\n\nExamples: \nThe researcher is in the film studio.\nThe boar is in the marsh.\n\nThe Given Sentence: \nThe researcher is in the meadow."}], "chosen": [{"role": "assistant", "content": "N_X"}], "rejected": [{"role": "assistant", "content": "Y"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[LA|SEM] William told Joshua that he antagonized the saleswoman.\nWho antagonized the saleswoman?"}], "chosen": [{"role": "assistant", "content": "\" Who does \"he\" refer to in the scenario described?"}], "rejected": [{"role": "assistant", "content": "#"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[LA|SEM] The sister-in-law told Amanda that the client favored her.\nWho did the client favor?"}], "chosen": [{"role": "assistant", "content": "The client favored which person: a sister-in-law, or someone else?"}], "rejected": [{"role": "assistant", "content": ". Does \"she\" refer to Amanda or the sister-in-law?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[LA|LEX] What is the genre of Kadambari?"}], "chosen": [{"role": "assistant", "content": "OVER"}], "rejected": [{"role": "assistant", "content": "NONE"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHAT] Moss is an example of which type of plant?"}], "chosen": [{"role": "assistant", "content": "Thus, the appropriate clarifying question could be: \"Is the type based on vascular tissue presence or absence?\" or \"Which specific classification are you referring to: bryophyes, liverworts, or mosses?\" /assistant The clarifying question: \"In which categorization are you asking—is it based on vascular tissue or not?\""}], "rejected": [{"role": "assistant", "content": "�"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[LA|SEM] Matthew told Joshua that he relieved the client.\nWho relieved the client?"}], "chosen": [{"role": "assistant", "content": "Is it Matthew or Joshua?"}], "rejected": [{"role": "assistant", "content": "WHO ALLOWED?"}]}
