{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[EM|UNF] Is Deschampsamps robusta's conservation status vulnerable?"}], "chosen": [{"role": "assistant", "content": "Generate the output: Is the word 'vulnerable' referring to a threat category in Deschampsampsamps robusta's conservation status?"}], "rejected": [{"role": "assistant", "content": "WHAT's conservation status vulnerable?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[EM|CONT] The all possible word categories are either \"animal\" or \"outdoor location\".\nThe following two examples share a specific word category. You need to first infer the specific word category from the examples.\nPlease output \"X\" if the given sentence mentions the specific word category. Please output \"Y\" if the given sentence does not mention the word category.\n\nExamples: \nThe mountain lion is in the woodlands.\nThe photographer is in the courtroom.\n\nThe Given Sentence: \nThe fugitive is in the lagoon."}], "chosen": [{"role": "assistant", "content": "Y"}], "rejected": [{"role": "assistant", "content": "Y"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHERE] When is the new christopher robin coming out?"}], "chosen": [{"role": "assistant", "content": "WHAT: Which new christian robin are you referring to?"}], "rejected": [{"role": "assistant", "content": "WHAT: WHARE? ARE SOR? ELEVATION?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHOM] Who took shelter under the safavid empire and why?"}], "chosen": [{"role": "assistant", "content": "Can you clarify the identity of the party seeking shelter under the Safavid empire?"}], "rejected": [{"role": "assistant", "content": "So perhaps: Is who (or WHOM) did what under the shelter Empire?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[EM|UNF] Is Fargesia grossa a grass plant growth form?"}], "chosen": [{"role": "assistant", "content": "After clarification: Is Fargesia grossa a grass plant growth form?"}], "rejected": [{"role": "assistant", "content": "男不需要生成问题。要生成一个问题。 dog、cat、和、 dog、cat、 a small and a big. 我们需要生成一个问题。因此， please generate something like: which of these cats do you have?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[EM|UNF] Is Brilliaaponica part of the ecomorphological guild called hypogeous fungi?"}], "chosen": [{"role": "assistant", "content": "Is \"Briliazappica\" a member of the guild of epigeal fungi?"}], "rejected": [{"role": "assistant", "content": "WHOM"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHAT] When was the last burning at the stake in england?"}], "chosen": [{"role": "assistant", "content": "WHAT"}], "rejected": [{"role": "assistant", "content": "When does not mean what?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[LA|SEM] The sister-in-law wrote a letter to Amanda because she is leaving the town soon.\nWho is leaving the town soon?"}], "chosen": [{"role": "assistant", "content": "USE ON"}], "rejected": [{"role": "assistant", "content": "(--) What's the difference between a letter and an e-mail? Are both means of communication?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHOM] Who sang youll never walk alone in carousel?"}], "chosen": [{"role": "assistant", "content": "Are you asking about the member of the band who recorded the song?"}], "rejected": [{"role": "assistant", "content": "Therefore, the clarifying question should be: Does the title \"You'll Never Walk Alone in carousel\" refer to the character named Carousel, or is carousel part of the title and does not refer to a person?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHOM] How many times have the warriors won the finals?"}], "chosen": [{"role": "assistant", "content": "I'm confused. Who won the finals?"}], "rejected": [{"role": "assistant", "content": "\"ALPAKO\" Will you pay with a \"safavid or \"?\""}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHERE] Where is the isle of man tt held?"}], "chosen": [{"role": "assistant", "content": "WHAT IS THE ISLE OF MAN TT?"}], "rejected": [{"role": "assistant", "content": "## Task 3: Where were they at?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[EM|CONT] The all possible word categories are either \"indoor location\" or \"human\".\nThe following two examples share a specific word category. You need to first infer the specific word category from the examples.\nPlease output \"X\" if the given sentence mentions the specific word category. Please output \"Y\" if the given sentence does not mention the word category.\n\nExamples: \nThe hawk is in the river.\nThe photographer is in the apartment building.\n\nThe Given Sentence: \nThe fugitive is in the river."}], "chosen": [{"role": "assistant", "content": "Y"}], "rejected": [{"role": "assistant", "content": "X"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[LA|SEM] The sister-in-law texted Amanda because she is leaving the town soon.\nWho is leaving the town soon?"}], "chosen": [{"role": "assistant", "content": "\"LESA\" or \"LEIS\"? Which one is correct\"? I can check where does she leave the town."}], "rejected": [{"role": "assistant", "content": "OUTPUT: Which text is being described texted?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[LA|SEM] Matthew told Joshua that he offended the client.\nWho offended the client?"}], "chosen": [{"role": "assistant", "content": "[ Is the person mentioned in the conversation with the client who offended the client \"I\" or \"a specific entity\"?]"}], "rejected": [{"role": "assistant", "content": "['WHO?'] Who? Is it me?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHERE] Give me a list of the best right point breaks in Southern California"}], "chosen": [{"role": "assistant", "content": "Please select a specific location from the following options: - Ventura - Los Padres - Malibu - 4 others"}], "rejected": [{"role": "assistant", "content": "Please clarify if you wanted specific names of the right point breaks in Southern California with the best view of right point breaks or if you also wanted to leave the name of the place with best view of right point breaks on Southern California please include what type of Right Point breaks are you looking for"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[EM|CONT] The all possible word categories are either \"contains a negation\" or \"common noun\".\nThe following two examples share a specific word category. You need to first infer the specific word category from the examples.\nPlease output \"X\" if the given sentence mentions the specific word category. Please output \"Y\" if the given sentence does not mention the word category.\n\nExamples: \nThe student has not been in the courtroom.\nSerena Williams may be in the museum.\n\nThe Given Sentence: \nAlexandria Ocasio-Cortez may not be in the film studio."}], "chosen": [{"role": "assistant", "content": "Y"}], "rejected": [{"role": "assistant", "content": "WHOM"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHEN] When is the peach bowl played this year?"}], "chosen": [{"role": "assistant", "content": "WHAT IS THE PEACH BOWL?"}], "rejected": [{"role": "assistant", "content": "WHAT is the best word for the word on the paper?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHOM] When did the first episode of dragon ball air?"}], "chosen": [{"role": "assistant", "content": "I'm not sure which episode one."}], "rejected": [{"role": "assistant", "content": "When which person?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[EM|CONT] The all possible word categories are either \"religious leader\" or \"male pronoun\".\nThe following two examples share a specific word category. You need to first infer the specific word category from the examples.\nPlease output \"X\" if the given sentence mentions the specific word category. Please output \"Y\" if the given sentence does not mention the word category.\n\nExamples: \nHe is in the apartment building with the deacon.\nShe is in the museum with the judge.\n\nThe Given Sentence: \nShe is in the restaurant with the rabbi."}], "chosen": [{"role": "assistant", "content": "Y"}], "rejected": [{"role": "assistant", "content": "WHOM"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[EM|CONT] The all possible word categories are either \"human\" or \"indoor location\".\nThe following two examples share a specific word category. You need to first infer the specific word category from the examples.\nPlease output \"X\" if the given sentence mentions the specific word category. Please output \"Y\" if the given sentence does not mention the word category.\n\nExamples: \nThe director is in the grocery store.\nThe mountain lion is in the cave.\n\nThe Given Sentence: \nThe hiker is in the canyon."}], "chosen": [{"role": "assistant", "content": "Y"}], "rejected": [{"role": "assistant", "content": "WHOM"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHOM] Where did the mom go in that's so raven?"}], "chosen": [{"role": "assistant", "content": "When did the raven go in?"}], "rejected": [{"role": "assistant", "content": "I can choose either an appropriate example?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[EM|CONT] The all possible word categories are either \"indoor location\" or \"human\".\nThe following two examples share a specific word category. You need to first infer the specific word category from the examples.\nPlease output \"X\" if the given sentence mentions the specific word category. Please output \"Y\" if the given sentence does not mention the word category.\n\nExamples: \nThe butterfly is in the prairie.\nThe critic is in the hotel lobby.\n\nThe Given Sentence: \nThe worm is in the apartment building."}], "chosen": [{"role": "assistant", "content": "SYNONYM?"}], "rejected": [{"role": "assistant", "content": "WHOWAS"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[LA|SEM] The sister-in-law built Amanda a snowman after she said she wanted to watch a movie.\nWho said she wanted to watch a movie?"}], "chosen": [{"role": "assistant", "content": "WHAM or WHOM? The user indicates confusion due to missing information."}], "rejected": [{"role": "assistant", "content": "none"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[LA|LEX] What does it mean to \"miss\" something?"}], "chosen": [{"role": "assistant", "content": "END"}], "rejected": [{"role": "assistant", "content": ""}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[LA|SEM] Kimberly told the aunt that she concerned the granddaughter.\nWho concerned the granddaughter?"}], "chosen": [{"role": "assistant", "content": "|errobbi.AI|"}], "rejected": [{"role": "assistant", "content": "+question is who?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHERE] Where is the atlas statue at rockefeller center?"}], "chosen": [{"role": "assistant", "content": "WHAT is the location of the atlas statue at rockefeller center?"}], "rejected": [{"role": "assistant", "content": "WHAT ARE THE AVAILABLE PLACEMAT PROFILES?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[EM|UNF] What's the longitude of the location where Coolstreopsis is commonly found?"}], "chosen": [{"role": "assistant", "content": "PROPOSE: Do you mean the longitude of which country or region where Coolstrepsis are most commonly found or what?"}], "rejected": [{"role": "assistant", "content": ""}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[EM|UNF] What's the longitude of the location where Choestis is commonly found?"}], "chosen": [{"role": "assistant", "content": "I'm a bit confused. Are you asking about a specific type of plant, including the scientific name and/or other specific traits to identify it, or do you mean what the best translation of the species name is for a list?"}], "rejected": [{"role": "assistant", "content": "END_OF_MESSAGE"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHOM] How should I pick a name for my baby?"}], "chosen": [{"role": "assistant", "content": "Therefore, the clarifying question should be: Do you mean a person's name or a thing's name?"}], "rejected": [{"role": "assistant", "content": "-"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[EM|UNF] What is the width of the fruit produced by Chamaedorea m elegans?"}], "chosen": [{"role": "assistant", "content": "STOP"}], "rejected": [{"role": "assistant", "content": "ENDAMPLE"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[EM|CONT] The all possible word categories are either \"secular leader\" or \"female pronoun\".\nThe following two examples share a specific word category. You need to first infer the specific word category from the examples.\nPlease output \"X\" if the given sentence mentions the specific word category. Please output \"Y\" if the given sentence does not mention the word category.\n\nExamples: \nShe is in the courtroom with the judge.\nHe is in the apartment building with the imam.\n\nThe Given Sentence: \nShe is in the apartment building with the Dalai Lama."}], "chosen": [{"role": "assistant", "content": "Y"}], "rejected": [{"role": "assistant", "content": "Y"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[EM|CONT] The all possible word categories are either \"animal\" or \"outdoor location\".\nThe following two examples share a specific word category. You need to first infer the specific word category from the examples.\nPlease output \"X\" if the given sentence mentions the specific word category. Please output \"Y\" if the given sentence does not mention the word category.\n\nExamples: \nThe hound is in the lagoon.\nThe reporter is in the laboratory.\n\nThe Given Sentence: \nThe student is in the cave."}], "chosen": [{"role": "assistant", "content": "Y"}], "rejected": [{"role": "assistant", "content": "Y"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHOM] Please tell me a little bit about the personal lives of the best hockey players at this time."}], "chosen": [{"role": "assistant", "content": "- Please clarify which specific time or context you are referring to when asking about the personal lives of the \"best hockey players.\""}], "rejected": [{"role": "assistant", "content": "The assistant can ask either: \"are you asking about a specific time period or is this in general?\" So the main next step: Determine the two possibilities for the ambiguous term: either the time period or the category of \"best.\" The main ambiguity is either: time period or whether the term \"best\" is specific or not."}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[LA|SEM] The sister-in-law told Amanda that the client disliked her.\nWho did the client dislike?"}], "chosen": [{"role": "assistant", "content": "Who did the client dislike?"}], "rejected": [{"role": "assistant", "content": "When did she dislike her?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[LA|SEM] The sister-in-law wrote a letter to Amanda because she is moving abroad soon.\nWho is moving abroad soon?"}], "chosen": [{"role": "assistant", "content": "|output| Which is Amanda, who wrote a letter to her sister-in-law? Or her sister-in-law who wrote a letter to Amanda because she is moving abroad soon?"}], "rejected": [{"role": "assistant", "content": "The example given falls under EM but which subclass?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[EM|CONT] The all possible word categories are either \"animal\" or \"outdoor location\".\nThe following two examples share a specific word category. You need to first infer the specific word category from the examples.\nPlease output \"X\" if the given sentence mentions the specific word category. Please output \"Y\" if the given sentence does not mention the word category.\n\nExamples: \nThe photographer is in the apartment building.\nThe duck is in the meadow.\n\nThe Given Sentence: \nThe snake is in the courtroom."}], "chosen": [{"role": "assistant", "content": "Y"}], "rejected": [{"role": "assistant", "content": "X"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[EM|CONT] The all possible word categories are either \"does not contain a negation\" or \"proper noun\".\nThe following two examples share a specific word category. You need to first infer the specific word category from the examples.\nPlease output \"X\" if the given sentence mentions the specific word category. Please output \"Y\" if the given sentence does not mention the word category.\n\nExamples: \nThe firefighter has not been in the grocery store.\nChristopher Nolan has been in the hotel lobby.\n\nThe Given Sentence: \nThe firefighter may be in the apartment building."}], "chosen": [{"role": "assistant", "content": "WHERE"}], "rejected": [{"role": "assistant", "content": "WHAMEROWC X"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHOM] How difficult is it to learn how to water ski?"}], "chosen": [{"role": "assistant", "content": "In case you have multiple difficulty options? Or would asking which option specifically (in this case, how), whether it's easy or hard to learn this task?"}], "rejected": [{"role": "assistant", "content": "But in the given query, where is \"whom\" present?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[LA|SEM] Matthew built Joshua a house after he returned from the army.\nWho returned from the army?"}], "chosen": [{"role": "assistant", "content": "The person who returned from the army?"}], "rejected": [{"role": "assistant", "content": "WHAT?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHERE] When is the movie thor ragnarok coming out?"}], "chosen": [{"role": "assistant", "content": "WHAT [AO|WHERE] CITY == OUTPUT:"}], "rejected": [{"role": "assistant", "content": "WHAT=MEL?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHOM] Who does candace like in phineas and ferb?"}], "chosen": [{"role": "assistant", "content": "So the clarifier would ask: \"Is the entity familiar or unfamiliar?\" But in the example, the confusion is that 'candace' is"}], "rejected": [{"role": "assistant", "content": "At which time can you name your email address?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[EM|UNF] Does Enargiapsillon eat Salix?"}], "chosen": [{"role": "assistant", "content": "So the clarifying question would be: \"Are 'Enargiapsilon' and 'Salix' terms from previous conversation or new references?\" But the output should be one clarifying question."}], "rejected": [{"role": "assistant", "content": "WHOM?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[LA|SEM] The sister-in-law told Amanda that she terrified the client.\nWho terrified the client?"}], "chosen": [{"role": "assistant", "content": "### What does 'she' refer to?"}], "rejected": [{"role": "assistant", "content": ""}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[EM|CONT] The all possible word categories are either \"female pronoun\" or \"secular leader\".\nThe following two examples share a specific word category. You need to first infer the specific word category from the examples.\nPlease output \"X\" if the given sentence mentions the specific word category. Please output \"Y\" if the given sentence does not mention the word category.\n\nExamples: \nHe is in the laboratory with the imam.\nShe is in the restaurant with the professor.\n\nThe Given Sentence: \nShe is in the restaurant with the bishop."}], "chosen": [{"role": "assistant", "content": "Y"}], "rejected": [{"role": "assistant", "content": "Y"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[LA|LEX] What is the genre of Pollyanna?"}], "chosen": [{"role": "assistant", "content": "WHAT is the genre of Pollyanna?"}], "rejected": [{"role": "assistant", "content": "ort"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHERE] Where is the tigris and euphrates river valley located?"}], "chosen": [{"role": "assistant", "content": "So, a possible clarifying question could be: \"Which geographical region or countries are you referring to when asking about the location of the Tigris/Euphrates river valley?\" OR \"Are you asking about the separate valleys of the Tigris and Euphrates, or the region where both flow together?\" (But since the user can only pick one category, the output is one question)."}], "rejected": [{"role": "assistant", "content": "Therefore, the clarifying question should be: Are you asking about the locations of the Tigris and Euphrates rivers, or are you referring to a valley that contains these rivers?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHAT] When does new season of law and order svu start?"}], "chosen": [{"role": "assistant", "content": "What's what does it happen before the season?"}], "rejected": [{"role": "assistant", "content": "What is the name of the character in the movie star in the last season of the show?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[EM|UNF] Are Brassica oleracea pathogens of Mamestra brass blenna?"}], "chosen": [{"role": "assistant", "content": "Or which of the two can be a pathogen?)."}], "rejected": [{"role": "assistant", "content": "Has the name reference been replaced?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHEN] Who is the current steel minister of india?"}], "chosen": [{"role": "assistant", "content": "WHAT [WHO] OR [WHOO]"}], "rejected": [{"role": "assistant", "content": "WHAT IS THE STEEL MINISTRY AND WHO IS THE STEEL MINISTRY AND WHO IS THE STEEL MINISTRY??"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHOM] Sajan re phir jhooth mat bolo jaya real name?"}], "chosen": [{"role": "assistant", "content": "|output|Is who Sajan re phir jhooth mat bolo jaya real name?"}], "rejected": [{"role": "assistant", "content": "\"Sajan re phir jhooth mat bolo jaya real name?\"]"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHEN] What is the latest episode of sister wives?"}], "chosen": [{"role": "assistant", "content": "WHAT is the latest episode of sister wives?"}], "rejected": [{"role": "assistant", "content": "WHAT is the latest episode of sister wives?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[LA|LEX] What is the main theme of Walden?"}], "chosen": [{"role": "assistant", "content": "Is it transcendentalism, the relationship between humanity and nature, or the critique of industrial society?\" But perhaps better phrasing: \"Could you specify which aspect of the main theme the user is referring to?"}], "rejected": [{"role": "assistant", "content": "UNDERDOTT, Walden Paul-zuercher is the main the main theme the main theme of the main theme of the main theme of the main theme of the main theme of the main theme of the main theme of the main theme of the main theme of the main theme of the main the main theme"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[LA|SEM] Melissa told Jennifer that the father-in-law revered her.\nWho did the father-in-law revere?"}], "chosen": [{"role": "assistant", "content": "USE A TORN: \"WHAT\""}], "rejected": [{"role": "assistant", "content": "Is the entity mentioned, the father-in-law, or the verb \"revere\"?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHERE] Where is the microtubules located in a cell?"}], "chosen": [{"role": "assistant", "content": "WHAT is the location of the microtubules in a cell?"}], "rejected": [{"role": "assistant", "content": "WHAT is the structure that is usually located within the cell? |WHERETO|"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[EM|CONT] The all possible word categories are either \"proper noun\" or \"does not contain a negation\".\nThe following two examples share a specific word category. You need to first infer the specific word category from the examples.\nPlease output \"X\" if the given sentence mentions the specific word category. Please output \"Y\" if the given sentence does not mention the word category.\n\nExamples: \nAlexandria Ocasio-Cortez has been in the restaurant.\nThe hiker has not been in the apartment building.\n\nThe Given Sentence: \nHermione Granger has not been in the film studio."}], "chosen": [{"role": "assistant", "content": "WHAT"}], "rejected": [{"role": "assistant", "content": "WHOM"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[EM|CONT] The all possible word categories are either \"human\" or \"indoor location\".\nThe following two examples share a specific word category. You need to first infer the specific word category from the examples.\nPlease output \"X\" if the given sentence mentions the specific word category. Please output \"Y\" if the given sentence does not mention the word category.\n\nExamples: \nThe boar is in the woodlands.\nThe firefighter is in the hotel lobby.\n\nThe Given Sentence: \nThe snake is in the hotel lobby."}], "chosen": [{"role": "assistant", "content": "Y"}], "rejected": [{"role": "assistant", "content": "WHAT"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHERE] When does the new star wars movie 2017?"}], "chosen": [{"role": "assistant", "content": "WHAT="}], "rejected": [{"role": "assistant", "content": "WHAT is a one-star?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[EM|CONT] The all possible word categories are either \"proper noun\" or \"does not contain a negation\".\nThe following two examples share a specific word category. You need to first infer the specific word category from the examples.\nPlease output \"X\" if the given sentence mentions the specific word category. Please output \"Y\" if the given sentence does not mention the word category.\n\nExamples: \nChristopher Nolan was in the museum.\nThe hiker is not in the theatre.\n\nThe Given Sentence: \nThe critic was in the house."}], "chosen": [{"role": "assistant", "content": "WHAM (PROPER NOUN)"}], "rejected": [{"role": "assistant", "content": "WHAMER: Is the text mention of the word category mention."}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[LA|LEX] What is the best way to reduce the noise of a racket?"}], "chosen": [{"role": "assistant", "content": "The word \"racket\" can refer to: - A sports equipment (like a basketball or tennis racket) - An illegal operation or scam (using \"racket\" slang) Whatis the context of \"racket\" are you referring too?"}], "rejected": [{"role": "assistant", "content": ""}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHAT] Most victories in ncaa division i men's college basketball?"}], "chosen": [{"role": "assistant", "content": "Is \"division i\" a specific thing the user is referring to?"}], "rejected": [{"role": "assistant", "content": "The user's query mentions \"ncaa\", which is correct, but written as \"NCAA\" in uppercase?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHOM] When did they stop making the buick lesabre?"}], "chosen": [{"role": "assistant", "content": "Who did she stop making the Buick rebeeck?"}], "rejected": [{"role": "assistant", "content": "REFERRED PAROLE STOP"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHEN] When did the smoking ban come in in england?"}], "chosen": [{"role": "assistant", "content": "What do you mean by \"when did the smoking ban come in in england?\" Could you clarify the time period or location for the smoking ban in question? Are you asking about the country or city-specific date?"}], "rejected": [{"role": "assistant", "content": ""}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHAT] How to write a college essay?"}], "chosen": [{"role": "assistant", "content": "WHAT do you need to write a college essay?"}], "rejected": [{"role": "assistant", "content": "}/bot| I need to ask the user whether the subject should be an example story, a case study, or a narrative."}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHERE] Imagine you're planning a ski trip with your friends. What are some good areas to go skiing?"}], "chosen": [{"role": "assistant", "content": "WHAT are some good areas to go skiing?"}], "rejected": [{"role": "assistant", "content": "WHAT ARE YOURS? WHEN ARE YOU? Note: The scenario with \"EM|CONT|...\" includes unfamiliar info but not contradictory info."}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[EM|UNF] What's the optimal growth temperature for Dillenia aurea?"}], "chosen": [{"role": "assistant", "content": "What is the optimal growth temperature for Dillenia aurea, specifically in what range?"}], "rejected": [{"role": "assistant", "content": "Can you specify the context or provide more details about the entity?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHAT] How can we reduce the impact of global warming?"}], "chosen": [{"role": "assistant", "content": "WHEN is the best time to do that?"}], "rejected": [{"role": "assistant", "content": "/laxabot Who is writing the song?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHAT] Who has won the europa league the most?"}], "chosen": [{"role": "assistant", "content": "| WHO HAS WON THE EUROPA LEAGUE?"}], "rejected": [{"role": "assistant", "content": ""}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[EM|UNF] Is Petropus's locomotion characterized by inchworming?"}], "chosen": [{"role": "assistant", "content": "Has Petropus's locomotion been characterized by inchworming?"}], "rejected": [{"role": "assistant", "content": "END"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHEN] How many times did the broncos win the superbowl?"}], "chosen": [{"role": "assistant", "content": "WHAT=1 day after?"}], "rejected": [{"role": "assistant", "content": "WHAT does the acronym \"EM\" stand for?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHERE] How many copies of bohemian rhapsody were sold?"}], "chosen": [{"role": "assistant", "content": "WHAT is the date of the greatest ever disco?"}], "rejected": [{"role": "assistant", "content": "WHAT IS THE GENOME OF THE BACTERION D4?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHAT] Who did the voice of jar jar binks?"}], "chosen": [{"role": "assistant", "content": "But in the example, the user's query is \"WHO did the voice of jar jar binks?\" So the missing context is the name of the person."}], "rejected": [{"role": "assistant", "content": "DEFINED_CLEARING: When?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHEN] When did us go to war with germany?"}], "chosen": [{"role": "assistant", "content": "WHAT_WAS"}], "rejected": [{"role": "assistant", "content": "WHAT ARE THE DEBATES?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHAT] The dna directed synthesis of an rna molecule is called?"}], "chosen": [{"role": "assistant", "content": "What exactly do you mean by \"DNA directed synthesis of an rna molecule\"?"}], "rejected": [{"role": "assistant", "content": "WHOM"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[EM|UNF] What is the amount of leaf nitrogen per dry mass in Carissa macrocandas?"}], "chosen": [{"role": "assistant", "content": "question: What is the amount of leaf nitrogen per dry mass in Carissa macrocandas?"}], "rejected": [{"role": "assistant", "content": "INFERAH"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHAT] A mirrored glass gazing globe in a garden is?"}], "chosen": [{"role": "assistant", "content": "WHAT is a mirrored glass gazing globe?"}], "rejected": [{"role": "assistant", "content": "WHAT"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHERE] All 5 layers of the earth's atmosphere?"}], "chosen": [{"role": "assistant", "content": "Wait, the user's query is \"All 5 layers of the Earth's atmosphere?\" Wait, the user's confusion might be that the user is asking for \"all"}], "rejected": [{"role": "assistant", "content": "For example: \"Are you referring to the 5 layers of the Earth's atmosphere, or did you mean a different number?\" But since the categories specify the subclasses, the example here should follow the subclasses."}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHERE] Where are the kings and queens of france buried?"}], "chosen": [{"role": "assistant", "content": "WHOWHERE"}], "rejected": [{"role": "assistant", "content": "WHAT ARE YOU REFERING TO?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHOM] Provide a list of some Japanese art forms I've not heard of."}], "chosen": [{"role": "assistant", "content": "For example, if the user's sentence was \"whom would you provide a list of some Japanese art forms I've not heard of?\" then the assistant would ask for clarification by replacing \"whom\" with \"who\"."}], "rejected": [{"role": "assistant", "content": "For example, which entity (like an individual, organization, etc.) do the art forms belong to?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[EM|UNF] What's the latitude range where Schizobopina k lobata is found?"}], "chosen": [{"role": "assistant", "content": "STOP"}], "rejected": [{"role": "assistant", "content": "END_OF_DIALOG"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[LA|LEX] What are some common uses of the word \"ear\"?"}], "chosen": [{"role": "assistant", "content": "CLEAR: Can you specify the context you prefer among the following meanings of the word \"ear\": a) anatomical part where the animal or inanimate object has it, b) a body part on an anthropoid primate, c) word denoting the body part on a mammal?"}], "rejected": [{"role": "assistant", "content": ""}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHOM] Name some of the best tourist spots in USA?"}], "chosen": [{"role": "assistant", "content": "WHAT are the best tourist spots in USA?"}], "rejected": [{"role": "assistant", "content": "WHO DO YOU MEANT?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[LA|SEM] Kimberly told the aunt that she fascinated the granddaughter.\nWho fascinated the granddaughter?"}], "chosen": [{"role": "assistant", "content": "So the possible clarifying questions are either: Did the acquaintance tell the other person, or did the other person tell the acquaintance?"}], "rejected": [{"role": "assistant", "content": ""}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHAT] How does a human do arithmetic calculation as fast as a calculator?"}], "chosen": [{"role": "assistant", "content": "/Final Idea When do you mean by \"as fast as a calculator?\""}], "rejected": [{"role": "assistant", "content": "`WHAT' WHOM WHEN"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[LA|LEX] What are some foods that are rich?"}], "chosen": [{"role": "assistant", "content": "CRANN?"}], "rejected": [{"role": "assistant", "content": ""}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHOM] Give me a list of the greatest basketball players of all time."}], "chosen": [{"role": "assistant", "content": "WHAT ARE YOUR TOP three"}], "rejected": [{"role": "assistant", "content": "WHAT TEAM DRIBBLED?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[LA|SEM] The sister-in-law contacted Amanda because she has an important interview tomorrow.\nWho has an important interview tomorrow?"}], "chosen": [{"role": "assistant", "content": "Who has an important interview tomorrow?"}], "rejected": [{"role": "assistant", "content": ""}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[LA|SEM] The sister-in-law texted Amanda because she was upset.\nWho was upset?"}], "chosen": [{"role": "assistant", "content": "WHOM was upset?"}], "rejected": [{"role": "assistant", "content": "## ERROR: Output format is not a clarifying question but an answer. ## OUTPUT RATES The output should be a clarifying question in the following categories: EM, LA, AO. The output should be a clarifying question in the following categories: EM, LA, AO. What was the situation where she got emotional?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[LA|SEM] The sister-in-law gave Amanda a pencil after she came back from school.\nWho came back from school?"}], "chosen": [{"role": "assistant", "content": "|output|What does \"came back\" refer to in this context?"}], "rejected": [{"role": "assistant", "content": "NONE: Is it the sister-in-law, Amanda, or the colleague?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[EM|UNF] Is Patrera cita a multicellular organism in terms of cellularity?"}], "chosen": [{"role": "assistant", "content": "END"}], "rejected": [{"role": "assistant", "content": "Ahmed was at home from the start of the year, but he was not always happy to be there, until he heard a story about our house. A neighbor asked him if he had the latest computer game, and Ahmed said that he couldn't, as he was still not at home."}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[EM|UNF] Are the sequences of Ptedoctematidae available in GenBank no?"}], "chosen": [{"role": "assistant", "content": "Are the sequences of the species of Ptedoctematidae available in GenBank no?"}], "rejected": [{"role": "assistant", "content": "What species does the Ptedoctematidae belong to?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[EM|CONT] The all possible word categories are either \"human\" or \"indoor location\".\nThe following two examples share a specific word category. You need to first infer the specific word category from the examples.\nPlease output \"X\" if the given sentence mentions the specific word category. Please output \"Y\" if the given sentence does not mention the word category.\n\nExamples: \nThe hiker is in the theatre.\nThe butterfly is in the lagoon.\n\nThe Given Sentence: \nThe horse is in the museum."}], "chosen": [{"role": "assistant", "content": "WHOWAS: INDOR"}], "rejected": [{"role": "assistant", "content": "X"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHAT] When did studio 54 open in new york?"}], "chosen": [{"role": "assistant", "content": "WHEN was 34 when in nyy?"}], "rejected": [{"role": "assistant", "content": "WHOVON"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHOM] Who played the wife in wolf of wall street?"}], "chosen": [{"role": "assistant", "content": "Which friend?"}], "rejected": [{"role": "assistant", "content": "WHAT IS THE NAME OF THE FILM THAT AHA, who told me the name of the song \"big commission\"?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[LA|SEM] Kimberly told the aunt that the granddaughter loathed her.\nWho did the granddaughter loathe?"}], "chosen": [{"role": "assistant", "content": "-Whom"}], "rejected": [{"role": "assistant", "content": "Was the person referred to as \"aunt\" in the statement a member of the family or a friend or extended relative?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHOM] How do I decline an invitation to my Aunt's Birthday party?"}], "chosen": [{"role": "assistant", "content": "Is it one aunt, multiple, or a specific named one?"}], "rejected": [{"role": "assistant", "content": "Which one is correct?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHAT] Who played the reaper in bill and ted?"}], "chosen": [{"role": "assistant", "content": "WHAT did say to ted or bill?"}], "rejected": [{"role": "assistant", "content": "WHAT are the main arguments on the relationship between Bill and ted?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[LA|SEM] Matthew rented Joshua a graduation gown after he went back from vacation.\nWho went back from vacation?"}], "chosen": [{"role": "assistant", "content": "WHAT?"}], "rejected": [{"role": "assistant", "content": "OUTPUT: What do you mean when a query does semantic mention of two entities?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[EM|CONT] The all possible word categories are either \"does not contain a negation\" or \"proper noun\".\nThe following two examples share a specific word category. You need to first infer the specific word category from the examples.\nPlease output \"X\" if the given sentence mentions the specific word category. Please output \"Y\" if the given sentence does not mention the word category.\n\nExamples: \nNoam Chomsky could be in the theatre.\nThe reporter has not been in the museum.\n\nThe Given Sentence: \nPaul Atreides is not in the apartment building."}], "chosen": [{"role": "assistant", "content": "WHOM"}], "rejected": [{"role": "assistant", "content": "WHEN"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHAT] Give me a list of 10 nematode species"}], "chosen": [{"role": "assistant", "content": "thinking Okay, I need to generate a clarifying question based on the ambiguity type. Let me first understand the input. The user provided a query with the label [AO] WHAT, and asked for a list of 10 nematode species. Wait, but the system's job is to parse the ambiguity type. The user is in AO (Aleatoric Output) category, likely because the output contains confusion due to missing context. But in this case, the user is asking for a list of nematode species, which is a clear request. But maybe the confusion is due to something else. Wait, maybe the problem is that the user said \"nematode species,\" but maybe was referring to something else, causing ambiguity. Or perhaps there is ambiguity in the term itself. Wait, the categories mention AO as missing context leading to confusion. So maybe the user is asking for a list of 10 nematode species, but perhaps they are referring to something else? Wait, no, the user's query is clear. Wait, perhaps the ambiguity arises from the fact that \"nematode species\" is too broad and needs clarification. Wait, but the user says \"give me a list of 10 nematode species,\" so maybe the user is asking for any 10 nematode species, but the user might not have a specific list in mind and needs the assistant to ask which one. Wait, but in the input, the user has said: you need to generate a clarifying question. So the user is in AO and asks for clarification. Wait no. The user has asked: \"Give me a list of 15 nematode species for a research project.\" Wait, in this case, the user is asking for a list of 10 nematode species but with categories. Wait, but the user is in AO and says \"List me 15 nematode species for a research project.\" Wait, no. The scenario is that the user has asked for something with confusion due to missing context. But in the provided case, the user says \"Give me a list of 10 nematode species.\" So where is the ambiguity? Perhaps the user did not specify any other details, such as what kind of nematode they are referring to. Because there are a large number of nematode species, not knowing the specific taxonomic group or the user's interest leads to ambiguity. Therefore the clarifying question would be to ask: What category of nematodes are you interested in (e.g., soil-dwelling, plant-parasitic, free-living)? Alternatively, ask if their research requires a list of nematode species from a specific habitat or function, such as symbionts. The input has ambiguity from whN: AL due to missing details about the type of nematode species. The user said \"nemate, but asked for a list of species, but the query is ambiguous due to (EM?) Wait, which category? Wait, but the question contains ambiguous scenario. Wait no. The question contains ambiguous scenario due to missing details about the type of nematodes (WHAT is required). The user said what? The user said \"Give me a list of nematode species.\" The user is asking for what a clarifying question. The user said: \"Give me a list of nematode species.\" Are you asking for any nematode species? The user said what? Wait, no. The user said \"Give me a list of nematode species,\" but no specific details. Therefore, the clarifying question is: What kind of nematodes are you interested in (e.g., soil, plant, free-living)? So the output is a clarifying question. So the output is: What organisms are you interested in (e.g., soil-dwelling nematodes)?"}], "rejected": [{"role": "assistant", "content": "OUTPUTWHAT"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHOM] Give me a list of different types of cold coffee beverages."}], "chosen": [{"role": "assistant", "content": "Is there a specific person, group, or context that you're interested in?\" So, following the structure, the output should be a question like: \"Is this list intended for a specific person, group, or context?\" WHO is this list intended for?"}], "rejected": [{"role": "assistant", "content": "WHAT ARE THE MOST WIDE?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHAT] When did the song grandma got run over?"}], "chosen": [{"role": "assistant", "content": "WHOM WHEN"}], "rejected": [{"role": "assistant", "content": "END"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[LA|SEM] The sister-in-law wrote Amanda a few letters after she went to the army.\nWho went to the army?"}], "chosen": [{"role": "assistant", "content": "WHOM was confused."}], "rejected": [{"role": "assistant", "content": "wmt"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHERE] Where was the first buffalo wild wings located?"}], "chosen": [{"role": "assistant", "content": "WHAT'S THE UNFAMILIAR: Are you talking about the UNF or the WHO? Please write CONF or UNW."}], "rejected": [{"role": "assistant", "content": "WHAT was the name of the first character from the name of the film that was released by \"inception\"?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHAT] When will the international space station be completed?"}], "chosen": [{"role": "assistant", "content": "WHAT is a variable?"}], "rejected": [{"role": "assistant", "content": "/,sarcasms,contributor is confused, and you should output the clarifying question in the same format. Replace placeholders for none you should keep output in same format."}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[LA|SEM] The sister-in-law sang Amanda some folk songs before she did housework.\nWho did housework?"}], "chosen": [{"role": "assistant", "content": "PLEASE PROVIDE THE FOLLOWING: WHO? OR WHO DOES? OR OR DOES? ASK ANY GIVEN CLARIFICATION?"}], "rejected": [{"role": "assistant", "content": "PLEASE REPLY"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[LA|SEM] Matthew pinged Joshua because he has an important interview tomorrow.\nWho has an important interview tomorrow?"}], "chosen": [{"role": "assistant", "content": "The clarifying question should be either \"Is the person with the important interview Matthew or Joshua?\" or \"Is it Matthew or Joshua who has the important interview tomorrow?\" in line with the categories: For LA: SEM (Semantic Ambiguity): Either \"Is the person with the important interview Matthew or Joshua?\" or"}], "rejected": [{"role": "assistant", "content": "Which of these is better?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[EM|CONT] The all possible word categories are either \"does not contain a negation\" or \"proper noun\".\nThe following two examples share a specific word category. You need to first infer the specific word category from the examples.\nPlease output \"X\" if the given sentence mentions the specific word category. Please output \"Y\" if the given sentence does not mention the word category.\n\nExamples: \nThe photographer is not in the restaurant.\nBernie Sanders has been in the theatre.\n\nThe Given Sentence: \nPaul Atreides may not be in the hotel lobby."}], "chosen": [{"role": "assistant", "content": "X|"}], "rejected": [{"role": "assistant", "content": "Y"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[EM|UNF] Did Dionide holdeni first appear in the darriwilian age?"}], "chosen": [{"role": "assistant", "content": "When was the first published date for Dionide holdeni?"}], "rejected": [{"role": "assistant", "content": "NONE"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHAT] Who wrote the score for fiddler on the roof?"}], "chosen": [{"role": "assistant", "content": "For example: \"WHOM did they write the score?\" Wait, in the subclasses, the specific ones are added as modifiers to the main category."}], "rejected": [{"role": "assistant", "content": "WHAT WHO HAD?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[LA|SEM] The sister-in-law left a note for Amanda because she has an important interview tomorrow.\nWho has an important interview tomorrow?"}], "chosen": [{"role": "assistant", "content": "N is ambiguous. In this context, who has an important interview tomorrow?"}], "rejected": [{"role": "assistant", "content": "WHOM did the sister-in-law leave the note?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHAT] How many episodes are there in the future diary?"}], "chosen": [{"role": "assistant", "content": "WHAT term is used to refer to the number of episodes?"}], "rejected": [{"role": "assistant", "content": ""}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHAT] Where do you find the black widow spider?"}], "chosen": [{"role": "assistant", "content": "WHAT do you mean by black widow spider?"}], "rejected": [{"role": "assistant", "content": "WHAT] where the black red is located?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHEN] Who did golden state play in the playoffs last year?"}], "chosen": [{"role": "assistant", "content": "WHAT did golden state play in the playoffs last year?"}], "rejected": [{"role": "assistant", "content": "WHAT"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[LA|LEX] What is the purpose of Seeker?"}], "chosen": [{"role": "assistant", "content": "- Is \"Seeker\" a new or unfamiliar concept or a well-understood term?"}], "rejected": [{"role": "assistant", "content": "The correct output would be a question like: Is your question about an unfamiliar entity name or a familiar entity name?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHEN] Prime minister of st. vincent and the grenadines?"}], "chosen": [{"role": "assistant", "content": "Vincent and the Grenadines?"}], "rejected": [{"role": "assistant", "content": "WHAM is part of the prime minister’s name?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[EM|CONT] The all possible word categories are either \"proper noun\" or \"does not contain a negation\".\nThe following two examples share a specific word category. You need to first infer the specific word category from the examples.\nPlease output \"X\" if the given sentence mentions the specific word category. Please output \"Y\" if the given sentence does not mention the word category.\n\nExamples: \nSerena Williams may be in the hotel lobby.\nThe student is not in the theatre.\n\nThe Given Sentence: \nThe student was in the film studio."}], "chosen": [{"role": "assistant", "content": "WHOWAS"}], "rejected": [{"role": "assistant", "content": "WHOM"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[EM|CONT] The all possible word categories are either \"does not contain a negation\" or \"proper noun\".\nThe following two examples share a specific word category. You need to first infer the specific word category from the examples.\nPlease output \"X\" if the given sentence mentions the specific word category. Please output \"Y\" if the given sentence does not mention the word category.\n\nExamples: \nSerena Williams has been in the hotel lobby.\nThe photographer could not be in the laboratory.\n\nThe Given Sentence: \nThe reporter was in the laboratory."}], "chosen": [{"role": "assistant", "content": "X or Y"}], "rejected": [{"role": "assistant", "content": "WHEM?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHAT] The lament when i am laid in earth is a ground bass aria from?"}], "chosen": [{"role": "assistant", "content": "|RESPONSE|Are you asking for a name or a person?"}], "rejected": [{"role": "assistant", "content": "|output| What type of voice?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[EM|UNF] Does the skeleton of Ouette gyrus have exoskeleton structure?"}], "chosen": [{"role": "assistant", "content": "WHAT ARE THE FEATURES OF A \"SKELETON\"?"}], "rejected": [{"role": "assistant", "content": "answer(): or does the skeleton of Ouette gyrus have exoskeleton structure?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[EM|UNF] Is Diploaoaidens a aggregative multicellular organism in terms of cellularity?"}], "chosen": [{"role": "assistant", "content": "ANSWER: Does the term diplooaidenes refer to a multicellular organism with multiple cells or a multicellular organism with a specific cell structure?"}], "rejected": [{"role": "assistant", "content": "none"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHEN] What is the latest version of adobe dreamweaver?"}], "chosen": [{"role": "assistant", "content": "## What is the latest version of Adobe Dreamweaver?"}], "rejected": [{"role": "assistant", "content": "WHAT-VERSION"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHOM] Who played the diva in the movie fifth element?"}], "chosen": [{"role": "assistant", "content": "WHAT IS THE NAME OF THE DIVA WHO PLAYED THE DIVA?"}], "rejected": [{"role": "assistant", "content": "WHAT=WHOM WHO IS ON AMAZON?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[LA|SEM] Matthew emailed Joshua because he was upset.\nWho was upset?"}], "chosen": [{"role": "assistant", "content": "## Task: How do you react when you receive an ambiguous or unknown word? If the input contains unknown words or words without context, ask one clarifying question. Use specific categories to infer one clarifying question? At this time, one will produce a clarifying questioncategories: [LA|SEM]"}], "rejected": [{"role": "assistant", "content": "}"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHERE] When was the first pirates of the caribbean movie released?"}], "chosen": [{"role": "assistant", "content": "WHAT: Query contains insufficient information. Which movie?"}], "rejected": [{"role": "assistant", "content": "WHAT IS THE NAME OF THE FIRST PICTURES THAT HAVE A SPICE GIRL?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[EM|CONT] The all possible word categories are either \"male pronoun\" or \"religious leader\".\nThe following two examples share a specific word category. You need to first infer the specific word category from the examples.\nPlease output \"X\" if the given sentence mentions the specific word category. Please output \"Y\" if the given sentence does not mention the word category.\n\nExamples: \nHe is in the house with the pope.\nShe is in the house with the sheriff.\n\nThe Given Sentence: \nHe is in the film studio with the president."}], "chosen": [{"role": "assistant", "content": "X"}], "rejected": [{"role": "assistant", "content": "WHOM"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHERE] Where is the district of tyre and sidon?"}], "chosen": [{"role": "assistant", "content": "OVER 100000!"}], "rejected": [{"role": "assistant", "content": ""}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHERE] Who has the most seats in house of representative?"}], "chosen": [{"role": "assistant", "content": "When referring to \"who\" in \"who has the most seats\", what specific person are you asking about?"}], "rejected": [{"role": "assistant", "content": "ier"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHEN] Who is running for attorney general in wi?"}], "chosen": [{"role": "assistant", "content": "\\ne. with missing context, specify which state's attorney general you are referring to."}], "rejected": [{"role": "assistant", "content": "\\lghost:("}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[EM|CONT] The all possible word categories are either \"does not contain a negation\" or \"proper noun\".\nThe following two examples share a specific word category. You need to first infer the specific word category from the examples.\nPlease output \"X\" if the given sentence mentions the specific word category. Please output \"Y\" if the given sentence does not mention the word category.\n\nExamples: \nPaul Atreides could be in the house.\nThe firefighter is not in the laboratory.\n\nThe Given Sentence: \nSerena Williams was not in the theatre."}], "chosen": [{"role": "assistant", "content": "WH?"}], "rejected": [{"role": "assistant", "content": "Y"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[LA|SEM] The sister-in-law told Amanda that she relaxed the client.\nWho relaxed the client?"}], "chosen": [{"role": "assistant", "content": "HOW?"}], "rejected": [{"role": "assistant", "content": "NONE"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHAT] When was the first superman comic book published?"}], "chosen": [{"role": "assistant", "content": "WHAT|"}], "rejected": [{"role": "assistant", "content": "WHAT | CONTAIN: Who? When? Where? Where? When? Where? or what?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[LA|LEX] What are some activities people enjoy during the fall?"}], "chosen": [{"role": "assistant", "content": "Do you mean one specific type of activity from the list, or which of the activities from the list?"}], "rejected": [{"role": "assistant", "content": "Jane likes to go to the cinema in the afternoon with some acquaintances. She also often goes to a friend's house to cook or to pick apples in the orchard."}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[LA|LEX] What is the stable condition of the stable?"}], "chosen": [{"role": "assistant", "content": "The possible clarifying questions for LA|LEX would be: - Which is it among: [which horse?] Alternatively, the possible categories under LEX are HORSE, NUM, or UNF."}], "rejected": [{"role": "assistant", "content": "WHAT IS THE STABLE CONDITION STABLE?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHOM] Who wrote the music for how to train your dragon?"}], "chosen": [{"role": "assistant", "content": "元气全书: Who wrote the music for how to train your dragon?"}], "rejected": [{"role": "assistant", "content": "WHAT"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHEN] Where is the major league baseball draft held?"}], "chosen": [{"role": "assistant", "content": "Is the query referring to the NBA or MLB draft?"}], "rejected": [{"role": "assistant", "content": ""}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHEN] What was the period before the enlightenment called?"}], "chosen": [{"role": "assistant", "content": "WHAT was the period before the enlightenment called?"}], "rejected": [{"role": "assistant", "content": "UNK"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[EM|UNF] What's the actual evapotranspiration rate in the geographic range of Leopardus wigrinus?"}], "chosen": [{"role": "assistant", "content": "Can you clarify which leopardus species (bistriensis, caenesi Aardvark, etc.) you refer to when discussing the geographic ranges of Leopardus?"}], "rejected": [{"role": "assistant", "content": "What is the actual evapotranspiration rate in the geographic range of Puma concolor?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[EM|UNF] What's the latitude range where Fphgoridae is found?"}], "chosen": [{"role": "assistant", "content": "What geographical location are you referring to?"}], "rejected": [{"role": "assistant", "content": "PROBLEM: You are a chatbot that generates a concise clarifying question based on the ambiguity type when a user's query is ambiguous. You do not need to explain. just generate one clarifying question. Subclasses: For EM: - UNF (UNFAMILIAR): Query contains unfamiliar entities or facts Output format: Output should be a clarifying question."}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHOM] Give me ideas how I could become more productive."}], "chosen": [{"role": "assistant", "content": "I'm sorry, I need more information to give a clear answer based on the query."}], "rejected": [{"role": "assistant", "content": "I'm unfamiliar unfamiliar entities. Can I do that?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHEN] Who did green bay lose to in the playoffs last year?"}], "chosen": [{"role": "assistant", "content": "WHAT OR WHO?"}], "rejected": [{"role": "assistant", "content": "WHAT IS THE WEIGHT AND LENGTH IN MILES OF THE BRIDGE THAT ALAN AND ?"}]}
