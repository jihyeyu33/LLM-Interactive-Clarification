{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[EM|CONT] The all possible word categories are either \"indoor location\" or \"human\".\nThe following two examples share a specific word category. You need to first infer the specific word category from the examples.\nPlease output \"X\" if the given sentence mentions the specific word category. Please output \"Y\" if the given sentence does not mention the word category.\n\nExamples: \nThe hawk is in the jungle.\nThe reporter is in the theatre.\n\nThe Given Sentence: \nThe firefighter is in the canyon."}], "chosen": [{"role": "assistant", "content": "X"}], "rejected": [{"role": "assistant", "content": "Y"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHEN] When does boy in the striped pajamas take place?"}], "chosen": [{"role": "assistant", "content": "WHAT WHEN IS BOY IN THE STRIPED JIM JAIL?"}], "rejected": [{"role": "assistant", "content": "WHAT IS THE NAME OF THE BOOK THAT THE INTEGRATOR IS REQUIRED TO GENERATE:"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[LA|SEM] The sister-in-law bought Amanda a drink after she arrived at the party.\nWho arrived at the party?"}], "chosen": [{"role": "assistant", "content": "WHOM?"}], "rejected": [{"role": "assistant", "content": "Where did he arrive at the party?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHOM] Give me a numbered list of five great fictional books."}], "chosen": [{"role": "assistant", "content": "Which five great fictional books would you like a list of?"}], "rejected": [{"role": "assistant", "content": "So the assistant would generate: \"Are you requesting books grouped by a specific subject group, such as boys, girls, or older men?\" But according to the model's framework, the possible clarifying questions for WHO are listed as UNF groups."}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[LA|SEM] Matthew told Joshua that he mollified the client.\nWho mollified the client?"}], "chosen": [{"role": "assistant", "content": "INPUT: [\"Who mollified the client?\"]"}], "rejected": [{"role": "assistant", "content": ""}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHAT] When do haley and nathan get back together season 3?"}], "chosen": [{"role": "assistant", "content": "WHAT When do haley and nathan get back together season 3?"}], "rejected": [{"role": "assistant", "content": "EM_cont_rise, WHO"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHERE] Which mountain range lies to the east of north america?"}], "chosen": [{"role": "assistant", "content": "IDENTIFY WHAT ORIENT?"}], "rejected": [{"role": "assistant", "content": ""}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[EM|CONT] The all possible word categories are either \"contains a negation\" or \"common noun\".\nThe following two examples share a specific word category. You need to first infer the specific word category from the examples.\nPlease output \"X\" if the given sentence mentions the specific word category. Please output \"Y\" if the given sentence does not mention the word category.\n\nExamples: \nHermione Granger could be in the courtroom.\nThe hiker is not in the film studio.\n\nThe Given Sentence: \nSerena Williams is not in the restaurant."}], "chosen": [{"role": "assistant", "content": "X or Y?"}], "rejected": [{"role": "assistant", "content": "X"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[LA|SEM] The sister-in-law told Amanda that she soothed the client.\nWho soothed the client?"}], "chosen": [{"role": "assistant", "content": "END_OF_TEMPLATE"}], "rejected": [{"role": "assistant", "content": "ER: Whose was it?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[EM|UNF] What's the latitude range where DMirachelus is found?"}], "chosen": [{"role": "assistant", "content": "['In which region is the species found?']"}], "rejected": [{"role": "assistant", "content": "What celestial bodies (species or stars) is DMirachelus found in the lat region of north or south?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHEN] Who heads up the un human rights council?"}], "chosen": [{"role": "assistant", "content": "thO: WHEN] What part do you mean by heads up the un human rights council?"}], "rejected": [{"role": "assistant", "content": "WHAT WHOM?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[LA|LEX] What does it mean to be tipped?"}], "chosen": [{"role": "assistant", "content": "Is the term \"tipped\" being used as a verb or a noun in your question?"}], "rejected": [{"role": "assistant", "content": "UNF: Can be either unkempt, unkempt"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[EM|UNF] In which repository is the type specimen of Orthoporoides pontifex conserved?"}], "chosen": [{"role": "assistant", "content": "|kaimag|"}], "rejected": [{"role": "assistant", "content": "Therefore, the clarifying question should be: 'Is the name of the species \"Orthoporoides pontifex\" defined elsewhere or is it unknown?'"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHEN] When does grey's season 14 episode 13 air?"}], "chosen": [{"role": "assistant", "content": "WHAT: When does grey's season 14 episode 13 air in the?"}], "rejected": [{"role": "assistant", "content": "WHAT DOES WHEN refer to when asking when grey's season 14 episode 13 aired?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[LA|SEM] Matthew made Joshua a square pizza before he went out.\nWho went out?"}], "chosen": [{"role": "assistant", "content": "WHO LEFT?"}], "rejected": [{"role": "assistant", "content": "|beginningofrequest| Given a scenario where the user has provided an ambiguous statement and asked the assistant to generate a clarifying question, the user expects the assistant to generate a single clarifying question without explanation. The user's clarifying question includes entities with names, such as Luke and a name with a different name or surname \"Hoffa Smith\". The user provides the scenario with the mention of a name with an unfamiliar entity. When the user generates the scenario, the scenario also includes the name of a person with an unfamiliar name or entity. When such is the case, generate a clarifying question with the following scenario or create a new clarifying question. The user likely expects the assistant to generate a clarifying question based on the subclass. For \"UNCURATED\" entity, generate a clarifying question about unfamiliar entity. What should the assistant do? The assistant should generate a clarifying question using an unfamiliar entity. Generate a clarifying question using an unfamiliar entity."}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[LA|LEX] What is Big's favorite color?"}], "chosen": [{"role": "assistant", "content": "WHAT what kind?"}], "rejected": [{"role": "assistant", "content": "WHAT"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[EM|CONT] The all possible word categories are either \"indoor location\" or \"human\".\nThe following two examples share a specific word category. You need to first infer the specific word category from the examples.\nPlease output \"X\" if the given sentence mentions the specific word category. Please output \"Y\" if the given sentence does not mention the word category.\n\nExamples: \nThe worm is in the cave.\nThe researcher is in the film studio.\n\nThe Given Sentence: \nThe mountain lion is in the restaurant."}], "chosen": [{"role": "assistant", "content": "Y"}], "rejected": [{"role": "assistant", "content": "X"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHEN] When is the last time the dolphins made the playoffs?"}], "chosen": [{"role": "assistant", "content": "WHAT"}], "rejected": [{"role": "assistant", "content": "WHAT IS THE LAST TENANT IN THE WHITE PLAINS COUNTY, NEVADA?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[LA|LEX] What does it mean to be \"up\"?"}], "chosen": [{"role": "assistant", "content": "@end What does \"up\" refer to?"}], "rejected": [{"role": "assistant", "content": "So the possible clarifying questions are \"Which meaning are you referring to?\" or \"Is this referring to being elevated or causing something to become higher/active?\" but in the structure of the categories, the possible clarifying questions are either whose, whens, etc."}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[LA|SEM] The sister-in-law texted Amanda because she had been on leave for a long time.\nWho had been on leave for a long time?"}], "chosen": [{"role": "assistant", "content": "|output| What does the leave refer to? The leave by her or the leave by her sister-in-law's?"}], "rejected": [{"role": "assistant", "content": "|output| Which sister wrote a text?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[EM|UNF] Does Bia live in ground habitat?"}], "chosen": [{"role": "assistant", "content": "STOP! A location? Where does Bia live?"}], "rejected": [{"role": "assistant", "content": "PLEASE RETEL?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHEN] Give me a list of the last five european golden boots winner and tell me how many goals they scored and in which league they scored these goals."}], "chosen": [{"role": "assistant", "content": "What is the last five European golden boot winners?"}], "rejected": [{"role": "assistant", "content": "WHAT SHOULD I WE NEED YOU?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHERE] When was the dubai metro green line opened to public?"}], "chosen": [{"role": "assistant", "content": "['LEX|WHER] Which refers to locations (inside or outside the city)?]"}], "rejected": [{"role": "assistant", "content": ""}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[EM|CONT] The all possible word categories are either \"does not contain a negation\" or \"proper noun\".\nThe following two examples share a specific word category. You need to first infer the specific word category from the examples.\nPlease output \"X\" if the given sentence mentions the specific word category. Please output \"Y\" if the given sentence does not mention the word category.\n\nExamples: \nThe director may not be in the hotel lobby.\nMargot Robbie could be in the grocery store.\n\nThe Given Sentence: \nThe researcher could be in the theatre."}], "chosen": [{"role": "assistant", "content": "WHOM"}], "rejected": [{"role": "assistant", "content": "WHAM"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHERE] How much tv does the average person watch a day?"}], "chosen": [{"role": "assistant", "content": "The user expects the assistant to generate one clarifying question based on the subclasses and categories of the given ambiguity."}], "rejected": [{"role": "assistant", "content": "WHAT is the exact tv size that you are referring to?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHAT] This is gonna be the best day of my life singer?"}], "chosen": [{"role": "assistant", "content": "WHAT is type of day of the best day?"}], "rejected": [{"role": "assistant", "content": "WHAT IS THE PLAN OF THE DAY?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHERE] Give me a suggestion where I should go for spring break if I live in the United States."}], "chosen": [{"role": "assistant", "content": "WHAT="}], "rejected": [{"role": "assistant", "content": "WHAT DOES ONE DO WHEN ONE IS ON FIRE"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[EM|UNF] What is the low temperature tolerance of Fagus grandentalis?"}], "chosen": [{"role": "assistant", "content": "NONE"}], "rejected": [{"role": "assistant", "content": "@end Please answer the following question: What does the \"rare\" refer to?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[LA|SEM] Matthew pinged Joshua because he is attending a conference next week.\nWho is attending a conference next week?"}], "chosen": [{"role": "assistant", "content": "Can you clarify whether \"conference\" refers to the ACM (Conference and Expo) in New York?"}], "rejected": [{"role": "assistant", "content": ""}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHAT] When did the nissan armada body style change?"}], "chosen": [{"role": "assistant", "content": "WHAT Is type of which? In the context of what?"}], "rejected": [{"role": "assistant", "content": ""}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[LA|SEM] The sister-in-law asked Amanda about the details after she came back from work.\nWho came back from work?"}], "chosen": [{"role": "assistant", "content": "END_OF_TEMPLATE"}], "rejected": [{"role": "assistant", "content": "p style=\"\""}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[LA|SEM] Matthew told Joshua that he troubled the client.\nWho troubled the client?"}], "chosen": [{"role": "assistant", "content": "WHAT: Which one troubled the client?"}], "rejected": [{"role": "assistant", "content": "�：神明"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHEN] What is the most recent season of the blacklist?"}], "chosen": [{"role": "assistant", "content": "What is the season you're referring to? The latest one, the present?"}], "rejected": [{"role": "assistant", "content": "What season do you mean by \"blacklist\"? Is it the TV one? The musical?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[LA|LEX] What is the significance of rocking in geology?"}], "chosen": [{"role": "assistant", "content": "CREATE_QUESTION: Could you specify the context relating to what aspect the question pertient to?"}], "rejected": [{"role": "assistant", "content": "WRITE:"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[EM|UNF] What is the suitable water depth for Leidya ucae?"}], "chosen": [{"role": "assistant", "content": "What do you mean by \"suitable water depth for Leidya ucae?\""}], "rejected": [{"role": "assistant", "content": "What is the suitable water depth for leidya ucae?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[EM|CONT] The all possible word categories are either \"male pronoun\" or \"religious leader\".\nThe following two examples share a specific word category. You need to first infer the specific word category from the examples.\nPlease output \"X\" if the given sentence mentions the specific word category. Please output \"Y\" if the given sentence does not mention the word category.\n\nExamples: \nHe is in the theatre with the imam.\nShe is in the film studio with the colonel.\n\nThe Given Sentence: \nHe is in the apartment building with the president."}], "chosen": [{"role": "assistant", "content": "WHER"}], "rejected": [{"role": "assistant", "content": "YD. He mentioned \"COLONEL\"."}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[LA|SEM] William told Joshua that he enraged the saleswoman.\nWho enraged the saleswoman?"}], "chosen": [{"role": "assistant", "content": "DO: WHO?"}], "rejected": [{"role": "assistant", "content": "VOID"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHERE] Where does university of miami play football games?"}], "chosen": [{"role": "assistant", "content": "Which team are they asking about?"}], "rejected": [{"role": "assistant", "content": "WHAT IS THE UNFAMILIAR: The familiar in the word can be either the most unknown entity or the most self-contradictory entity present. At this time, we cannot clarify the type of unfamiliar entity."}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[LA|SEM] Matthew told Joshua that he reassured the client.\nWho reassured the client?"}], "chosen": [{"role": "assistant", "content": "NONE"}], "rejected": [{"role": "assistant", "content": "WHAT=? What group or team sent the article?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[EM|CONT] The all possible word categories are either \"animal\" or \"outdoor location\".\nThe following two examples share a specific word category. You need to first infer the specific word category from the examples.\nPlease output \"X\" if the given sentence mentions the specific word category. Please output \"Y\" if the given sentence does not mention the word category.\n\nExamples: \nThe reporter is in the laboratory.\nThe hawk is in the cave.\n\nThe Given Sentence: \nThe director is in the cave."}], "chosen": [{"role": "assistant", "content": "X"}], "rejected": [{"role": "assistant", "content": "Y"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHOM] Who sings been through the desert on a horse with no name?"}], "chosen": [{"role": "assistant", "content": "The query includes unfamiliar entities, likely unfamiliar figures. Please can you provide additional context or clarification about the unfamiliar entities mentioned in the query?"}], "rejected": [{"role": "assistant", "content": "请问是在哪个小区的电影院见到这么多乐队？"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHEN] Whats the population of the state of florida?"}], "chosen": [{"role": "assistant", "content": "WHAT?"}], "rejected": [{"role": "assistant", "content": "When do you have one?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[LA|LEX] What is the process or action involved in being charged?"}], "chosen": [{"role": "assistant", "content": "WHAT IS THE PROCESS OR IS/WHAT IS ASKED IN ONE'S OWN CHARGE?"}], "rejected": [{"role": "assistant", "content": "mal i can help you if i need assistance with a specific problem in a particular region or city"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHAT] When did mt st helen's last erupt?"}], "chosen": [{"role": "assistant", "content": "WHAT|WHAT]"}], "rejected": [{"role": "assistant", "content": ""}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHEN] How many cvs stores are there in the usa?"}], "chosen": [{"role": "assistant", "content": "WHAT is an \"CVS store\"?"}], "rejected": [{"role": "assistant", "content": "WHAT ARE 15 cities in the USA?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[LA|LEX] What is the meaning of Wonderwall?"}], "chosen": [{"role": "assistant", "content": "WHAT IS THE MEANING OF WONDERWALL?"}], "rejected": [{"role": "assistant", "content": "WHAT IS THE MEANING OF DOOM?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHEN] When was the first government formed in the world?"}], "chosen": [{"role": "assistant", "content": "WHAT is the first government in the world?"}], "rejected": [{"role": "assistant", "content": "WHAT"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[LA|SEM] Matthew emailed Joshua because he is attending a conference next week.\nWho is attending a conference next week?"}], "chosen": [{"role": "assistant", "content": "So the clarifying question would be something like \"Is it Matthew or Joshua who is attending the conference?\" Therefore, the proper clarifying question would be: Is it Matthew or Joshua who is attending the conference?"}], "rejected": [{"role": "assistant", "content": "WHAT is the name of the event?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[EM|UNF] What is the geographic distribution of Bogona lombvetica?"}], "chosen": [{"role": "assistant", "content": "[\"What species of bogona are you referring to, like the one in Lombardy Italy?\"]"}], "rejected": [{"role": "assistant", "content": "I'm trying to help you with the geographic distribution of Bogona lombvetica?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[EM|UNF] What is the stem specific density of Comallcium?"}], "chosen": [{"role": "assistant", "content": "NAME: COMALLIUM MNO: 1.6.5"}], "rejected": [{"role": "assistant", "content": "WHAT IS THE STAGE-DUE DUE OF THE COMALLCIA?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHAT] Who was involved in the bull run battle?"}], "chosen": [{"role": "assistant", "content": "\"who was involved in the bull run battle?\"_"}], "rejected": [{"role": "assistant", "content": "WHAT did the people on the left side of the street do?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHEN] Give me a bulleted list of the top five most followed Instagram profiles."}], "chosen": [{"role": "assistant", "content": "WHAT IS THE first word of the name of the top five most followed Instagram profiles?"}], "rejected": [{"role": "assistant", "content": "##"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHEN] When did us the duo audition for agt?"}], "chosen": [{"role": "assistant", "content": "WHAT IS YEAR OF 1991"}], "rejected": [{"role": "assistant", "content": "WHAT_CHARACTOER did you get on the left for WNBA?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHEN] Where did poland come in the world cup?"}], "chosen": [{"role": "assistant", "content": "What country were you referring to?"}], "rejected": [{"role": "assistant", "content": "WHAT DO YOU MEAN ST AND SC"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHEN] Where is let's make a deal recorded?"}], "chosen": [{"role": "assistant", "content": "WHAT is an output from an implicit question?"}], "rejected": [{"role": "assistant", "content": "WHAT is the date of release of the game lets make a deal?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[LA|LEX] What clicked in your mind?"}], "chosen": [{"role": "assistant", "content": "ENDLINE:"}], "rejected": [{"role": "assistant", "content": "token: which side of the person came up with the problem?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[LA|SEM] William told Joshua that he emboldened the saleswoman.\nWho emboldened the saleswoman?"}], "chosen": [{"role": "assistant", "content": "WHAT type or between whom?"}], "rejected": [{"role": "assistant", "content": "VOID."}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[EM|CONT] The all possible word categories are either \"female pronoun\" or \"secular leader\".\nThe following two examples share a specific word category. You need to first infer the specific word category from the examples.\nPlease output \"X\" if the given sentence mentions the specific word category. Please output \"Y\" if the given sentence does not mention the word category.\n\nExamples: \nShe is in the courtroom with the CEO.\nHe is in the house with the ayatollah.\n\nThe Given Sentence: \nShe is in the museum with the ayatollah."}], "chosen": [{"role": "assistant", "content": "Y"}], "rejected": [{"role": "assistant", "content": "WHOM"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHERE] Who has the most home runs in the american league?"}], "chosen": [{"role": "assistant", "content": "WHAT's got most home runs in the American League?"}], "rejected": [{"role": "assistant", "content": "WHAT IS WHAT NOT WHO?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[EM|UNF] What's the longitude of the location where achotus was found?"}], "chosen": [{"role": "assistant", "content": "WHOWAS?"}], "rejected": [{"role": "assistant", "content": "WHAT is the longitude of place where anothas found?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[EM|CONT] The all possible word categories are either \"female pronoun\" or \"secular leader\".\nThe following two examples share a specific word category. You need to first infer the specific word category from the examples.\nPlease output \"X\" if the given sentence mentions the specific word category. Please output \"Y\" if the given sentence does not mention the word category.\n\nExamples: \nShe is in the hotel lobby with the ambassador.\nHe is in the apartment building with the cardinal.\n\nThe Given Sentence: \nHe is in the museum with the sheriff."}], "chosen": [{"role": "assistant", "content": "Y"}], "rejected": [{"role": "assistant", "content": "WHOM"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHEN] How long is the term for texas governor?"}], "chosen": [{"role": "assistant", "content": "WHAT is the term limit for?"}], "rejected": [{"role": "assistant", "content": "OVER 14"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHERE] Where did henry go on grounded for life?"}], "chosen": [{"role": "assistant", "content": "WHAT DID SHE SAY AFTER HENRY WAS FORLATING?"}], "rejected": [{"role": "assistant", "content": "WHAT HAS HENRY BOTTLE WITH BARE? WHISHT WHISHT LAND WISHL LAND?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHOM] Who plays elsa in olaf's frozen adventure?"}], "chosen": [{"role": "assistant", "content": "WHEN who plays elsa in olaf's frozen adventure?"}], "rejected": [{"role": "assistant", "content": "think() Using the given paragraph for EM, the next paragraph is UNF The paragraph with EM will be used under category EM category UNF We can use UNF and contradiction I search to use UNF in [UNF] Possible are UNF with contradiction Sub-categories to use UNF I search to find UNF I see UNF is a subclass of EM where UNF and contradiction (or CON) are used. Question context is UNF So context search for UNF from context: If context includes UNF and contradiction then use CON. After analyzing context, we found UNF We will generate a CLARIFYING QUESTION. Possible UNF questions include: - Who, in the paragraph who has a name Elsa? I see UNF and who The following UNF questions include who who does has multiple names? I see UNF and who in the UNF I can find UNK in the context UNF. Possible UNF questions including UNK: I need to generate CLARIFYING QUESTIONS. The user query includes UNFC and WHO. Possible categories include UNF and WHO. I need to generate a CLARIFYING QUESTION or generate a clarifying question. Generate a possible question with UNF and NO: I see UNF and who Check if a subject with UNF is involved. Generate a CLARIFYING QUESTION with possible UNF and no. I come up with: Does who have UNF and NO: Possible UNF questions for no include who have UNK or something else. I can ask which name for who has UNK. Possible question: Given: (WHO, UNF) with NO = What name in the paragraph is referred to? I choose this possible question: Given: (WHO, UNF, NO) = Which name in the paragraph matches the term used? The context includes UNF, so it is UNF. I can select a sub-clarification: UNK and NO I generate a possible clarifying question: Which name in the paragraph corresponds to the term used? Generate a possible clarifying question: Which name in the paragraph matches the term used? Is it Anna or Elsa? Output a possible clarifying question: Which name in the paragraph, Anna or Elsa, was used? Another possible clarifying question: Does the paragraph provide the correct name for WHO with UNF and NO? Another possible clarifying question: Does the paragraph include a name with UNF and NO?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHEN] Who sculptured a statue of the biblical hero david?"}], "chosen": [{"role": "assistant", "content": "WHAT is WHO sculptured a statue of the biblical hero david?"}], "rejected": [{"role": "assistant", "content": "WHAT: When did EGYpt the first time receive foreign assistance?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[EM|UNF] Is Maleonna a carnivore in the food chain?"}], "chosen": [{"role": "assistant", "content": "What is a maleonna?"}], "rejected": [{"role": "assistant", "content": "What does it mean by maleonna?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[LA|SEM] The sister-in-law handed Amanda a piece of white paper before she asked a question.\nWho asked a question?"}], "chosen": [{"role": "assistant", "content": "WHO IS?"}], "rejected": [{"role": "assistant", "content": "DO: Can you specify which woman clarified her question?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHEN] Who played luna on the big comfy couch?"}], "chosen": [{"role": "assistant", "content": "WHAT? When did she last play on the big?"}], "rejected": [{"role": "assistant", "content": ""}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHAT] Who played elizabeth bennet in pride and prejudice?"}], "chosen": [{"role": "assistant", "content": "Was the character who played Elizabeth Bennett in Pride and Prejudice played by Kate Parkinson?"}], "rejected": [{"role": "assistant", "content": "REFERRED= Who replaced regie in pride and prejudice, for what time period?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHAT] Think up different ways to make a baby stop crying."}], "chosen": [{"role": "assistant", "content": "WHAT are some ways to make a baby stop crying?"}], "rejected": [{"role": "assistant", "content": "WHAT are different ways to stop baby crying up?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[EM|UNF] Is the fruit type of Corydalisiliqua compound fruit?"}], "chosen": [{"role": "assistant", "content": "What does it mean by compound fruit?"}], "rejected": [{"role": "assistant", "content": "What does CIS type reference?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHERE] When did ready player one come to theaters?"}], "chosen": [{"role": "assistant", "content": "When did ready player 1 come to the theatres?"}], "rejected": [{"role": "assistant", "content": "NONE"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[EM|UNF] In which geological period did Electocheisidium last appear?"}], "chosen": [{"role": "assistant", "content": "EM is likely misalignment with unfamiliar entities, UNF."}], "rejected": [{"role": "assistant", "content": "EM"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[EM|UNF] What's the longitude of the location where Nolella pusilla is commonly found?"}], "chosen": [{"role": "assistant", "content": "What is the geographic location where the species is commonly found?"}], "rejected": [{"role": "assistant", "content": "END"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHERE] Where did the social gospel movement take place?"}], "chosen": [{"role": "assistant", "content": "WHAT DID SHE WALK FROM WHEN SHE WANDER AWHOW?"}], "rejected": [{"role": "assistant", "content": "WHAT IS THE MOTIVE WHOI AM AN WHO?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHERE] When was harry potter and the sorcerers stone book released?"}], "chosen": [{"role": "assistant", "content": "WHAT OR WHEN? WHEN?"}], "rejected": [{"role": "assistant", "content": "['LEX|WHEN] Can you specify the edition of the book, such as First or Second?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHOM] Give me a list of the best movies I've never seen."}], "chosen": [{"role": "assistant", "content": "I'm not sure which personal preferences you're referring to. Is there something in particular you want to include or know before I can provide a meaningful answer?"}], "rejected": [{"role": "assistant", "content": "When is the end of the list?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[LA|SEM] Kimberly told the aunt that she daunted the granddaughter.\nWho daunted the granddaughter?"}], "chosen": [{"role": "assistant", "content": "NONE"}], "rejected": [{"role": "assistant", "content": "|user| Who told on the neighbor? \"What did she do about the neighbor?\""}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHOM] Who were the presidents that were assassinated while in office?"}], "chosen": [{"role": "assistant", "content": "Is your query referring to U.S. presidents or the term presidents in general?"}], "rejected": [{"role": "assistant", "content": "Are you asking about the country's presidents or the country's president?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[EM|UNF] What's the hearing range of Oena capensis aliena?"}], "chosen": [{"role": "assistant", "content": "What organism do you mean by hearing range of Oena capensis aliena?"}], "rejected": [{"role": "assistant", "content": "ERS: Can you specify what type of hearing range you're referring to?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[EM|CONT] The all possible word categories are either \"secular leader\" or \"female pronoun\".\nThe following two examples share a specific word category. You need to first infer the specific word category from the examples.\nPlease output \"X\" if the given sentence mentions the specific word category. Please output \"Y\" if the given sentence does not mention the word category.\n\nExamples: \nHe is in the apartment building with the ayatollah.\nShe is in the film studio with the judge.\n\nThe Given Sentence: \nHe is in the apartment building with the colonel."}], "chosen": [{"role": "assistant", "content": "Y"}], "rejected": [{"role": "assistant", "content": "WHOM"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHOM] Who is the captain of hockey in india?"}], "chosen": [{"role": "assistant", "content": "I'm a hockey player. Who is the captain of hockey in India?"}], "rejected": [{"role": "assistant", "content": ""}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHAT] When did the facebook messenger app come out?"}], "chosen": [{"role": "assistant", "content": ".contains: a when did the facebook messenger app come out? when did the facebook messenger app come out?"}], "rejected": [{"role": "assistant", "content": "['WHO-UNF] What version of chat came out with the messaging app?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHOM] Who plays lara croft in the new tomb raider?"}], "chosen": [{"role": "assistant", "content": "Therefore, the appropriate clarifying question is to ask: Which version of Tomb Raider are you referring to?"}], "rejected": [{"role": "assistant", "content": ""}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHOM] How should I choose what cheese to buy?"}], "chosen": [{"role": "assistant", "content": "|output|Can you specify the number of cheese you're looking to buy and where you're planning to eat them?"}], "rejected": [{"role": "assistant", "content": "/page"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHAT] When was the first car made in america?"}], "chosen": [{"role": "assistant", "content": "WHAT should be the first type of car production machine?"}], "rejected": [{"role": "assistant", "content": "END"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[LA|LEX] What is the meaning of Sledgehammer?"}], "chosen": [{"role": "assistant", "content": "Is it a sports car?"}], "rejected": [{"role": "assistant", "content": ""}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[EM|CONT] The all possible word categories are either \"religious leader\" or \"male pronoun\".\nThe following two examples share a specific word category. You need to first infer the specific word category from the examples.\nPlease output \"X\" if the given sentence mentions the specific word category. Please output \"Y\" if the given sentence does not mention the word category.\n\nExamples: \nShe is in the museum with the CEO.\nHe is in the house with the deacon.\n\nThe Given Sentence: \nHe is in the restaurant with the colonel."}], "chosen": [{"role": "assistant", "content": "Y"}], "rejected": [{"role": "assistant", "content": "WHOM"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHEN] When did the byzantine empire start to decline?"}], "chosen": [{"role": "assistant", "content": "WHAT YEAR?"}], "rejected": [{"role": "assistant", "content": "WHOM to start with?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[LA|SEM] Melissa told Jennifer that she flattered the father-in-law.\nWho flattered the father-in-law?"}], "chosen": [{"role": "assistant", "content": "WHOM: (WHOWN | WHOM)"}], "rejected": [{"role": "assistant", "content": "WHO HAS NOT FLattered?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[LA|LEX] How can hedges be used to minimize loss or risk?"}], "chosen": [{"role": "assistant", "content": "none"}], "rejected": [{"role": "assistant", "content": "cls"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[EM|CONT] The all possible word categories are either \"secular leader\" or \"female pronoun\".\nThe following two examples share a specific word category. You need to first infer the specific word category from the examples.\nPlease output \"X\" if the given sentence mentions the specific word category. Please output \"Y\" if the given sentence does not mention the word category.\n\nExamples: \nHe is in the laboratory with the imam.\nShe is in the hotel lobby with the principal.\n\nThe Given Sentence: \nHe is in the laboratory with the president."}], "chosen": [{"role": "assistant", "content": "Y"}], "rejected": [{"role": "assistant", "content": "WHOM"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHERE] Where is the state of new york located?"}], "chosen": [{"role": "assistant", "content": "In the case of the clarifying question: Which specific location has to do with the clarification of the ambiguous question?"}], "rejected": [{"role": "assistant", "content": "WHAT is the new york state located?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[LA|LEX] What are the different types of ribs?"}], "chosen": [{"role": "assistant", "content": "think(m):= What is the specific type of rib referred to in the context of anatomical classifications (differentiating by bone structure)?"}], "rejected": [{"role": "assistant", "content": "Which category was chosen from?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[EM|CONT] The all possible word categories are either \"outdoor location\" or \"animal\".\nThe following two examples share a specific word category. You need to first infer the specific word category from the examples.\nPlease output \"X\" if the given sentence mentions the specific word category. Please output \"Y\" if the given sentence does not mention the word category.\n\nExamples: \nThe mountain lion is in the pond.\nThe critic is in the grocery store.\n\nThe Given Sentence: \nThe duck is in the laboratory."}], "chosen": [{"role": "assistant", "content": "X WHER"}], "rejected": [{"role": "assistant", "content": "WHAR"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[EM|UNF] Is Caesalpinia mexicana a photoautotroph trophic guild?"}], "chosen": [{"role": "assistant", "content": "question: Is Caesalpinia's native species a flora or shrub?"}], "rejected": [{"role": "assistant", "content": "WHOWAS THE TOP NAME?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHOM] Think up of a bunch of different dishes you could make with a pound of potatoes"}], "chosen": [{"role": "assistant", "content": "UNCHILARIFY: Which many people do you cook meals for?"}], "rejected": [{"role": "assistant", "content": "I'll get it."}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[EM|UNF] What is the dry mass of a seed of Daph mac laureola?"}], "chosen": [{"role": "assistant", "content": "Therefore, the correct question would be along the lines of: \"Is the prefix composed of one term or two separate terms?\" For example: \"Does the name contain two"}], "rejected": [{"role": "assistant", "content": "Okay, let me hit you up when you need mine to be cleared!"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[EM|CONT] The all possible word categories are either \"indoor location\" or \"human\".\nThe following two examples share a specific word category. You need to first infer the specific word category from the examples.\nPlease output \"X\" if the given sentence mentions the specific word category. Please output \"Y\" if the given sentence does not mention the word category.\n\nExamples: \nThe photographer is in the house.\nThe bear is in the cave.\n\nThe Given Sentence: \nThe horse is in the apartment building."}], "chosen": [{"role": "assistant", "content": "Y"}], "rejected": [{"role": "assistant", "content": "Y"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[LA|LEX] What is the impact of being thrown?"}], "chosen": [{"role": "assistant", "content": "So the output should be: \"Which is the ambiguous term: 'th thrown' or its meaning?\" Wait, the format"}], "rejected": [{"role": "assistant", "content": "ort"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[EM|UNF] What's the geographic distribution of Dioxysrichi?"}], "chosen": [{"role": "assistant", "content": "So, the final clarifying question is: \"Is Dioxysrichi a familiar location, species, or entity that you're referring to?\" but since the question is about geographical distribution, the specific area could be location."}], "rejected": [{"role": "assistant", "content": "I should include the guidance for UNF."}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHERE] Write a diary entry about a real life incident on your recent trip with your family"}], "chosen": [{"role": "assistant", "content": "WHAT: WHAT TRIP PLANNING"}], "rejected": [{"role": "assistant", "content": "WHAT IS YOUR BACKGROUND?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHEN] What is the percentage of agriculture in gdp of india?"}], "chosen": [{"role": "assistant", "content": "WHAT is the percentage in GDP of India?"}], "rejected": [{"role": "assistant", "content": "WHAT is the country name for the city or state of"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[LA|LEX] What are the different levels in this building?"}], "chosen": [{"role": "assistant", "content": "So the question would be: Which type of levels are you referring to — physical storeys, departments, or something else?"}], "rejected": [{"role": "assistant", "content": ""}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHAT] Who was responsible for keeping british ships out of the waterways off the coast of virginia?"}], "chosen": [{"role": "assistant", "content": "Did you mean a naval policy (such as the Articles of Approximation) or the actions of a specific commander enforcing the blockade?\" Thus, the output format requires one clarifying question in the format specified."}], "rejected": [{"role": "assistant", "content": "I'm a little confused. When we have a conflict, who did it first?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHAT] The condition that exists when a contract is made with the purpose of benefiting the third party?"}], "chosen": [{"role": "assistant", "content": "OPTION: In what scenario does the first question refer to a situation where a contract is made with the purpose of benefiting the third party?"}], "rejected": [{"role": "assistant", "content": "Where exactly is this happening?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHERE] Where is olympic national park located in washington?"}], "chosen": [{"role": "assistant", "content": "Is the mention of \"Olympic National Park\" located in Washington in (EM, CLS, WHERE) category?"}], "rejected": [{"role": "assistant", "content": "QUIT!"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[LA|SEM] Matthew sent a message to Joshua because he had been on leave for a long time.\nWho had been on leave for a long time?"}], "chosen": [{"role": "assistant", "content": "|output|Where did he go on leave for a long time?"}], "rejected": [{"role": "assistant", "content": "wth"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[EM|UNF] What is the geographic range of Sorex cinesoni?"}], "chosen": [{"role": "assistant", "content": "But perhaps the user's example is incorrect?"}], "rejected": [{"role": "assistant", "content": "1."}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHOM] Give me a list of the most agreed upon supplements that are effective for maintaining general health"}], "chosen": [{"role": "assistant", "content": "Is the list for humans or for animals or both?"}], "rejected": [{"role": "assistant", "content": ""}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHAT] Number of catholic high schools in the united states?"}], "chosen": [{"role": "assistant", "content": "WHAT_NUM_CATHOLIC_HIGH_SCHOOLS_IN_UNITED_STATES"}], "rejected": [{"role": "assistant", "content": "Option: What type of high school should be included as a base when calculating the average?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHEN] How many medals does usa have in snowboarding?"}], "chosen": [{"role": "assistant", "content": "WHAT"}], "rejected": [{"role": "assistant", "content": "WHAT | WHO"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHOM] Who do you play as in modern warfare 2?"}], "chosen": [{"role": "assistant", "content": "So, the final question should be: Can you clarify which person or role you're referring to in Modern Warfare 2?"}], "rejected": [{"role": "assistant", "content": "3) Of these, which is larger in volume and mass, and where did it come from? A: The asteroid, B: The star,"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[LA|LEX] What are the potential consequences of being uprooted?"}], "chosen": [{"role": "assistant", "content": "WHAT are the possible consequences of being uprooted?"}], "rejected": [{"role": "assistant", "content": "WHAT are the potential consequences of being uprooted?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[EM|CONT] The all possible word categories are either \"secular leader\" or \"female pronoun\".\nThe following two examples share a specific word category. You need to first infer the specific word category from the examples.\nPlease output \"X\" if the given sentence mentions the specific word category. Please output \"Y\" if the given sentence does not mention the word category.\n\nExamples: \nHe is in the hotel lobby with the deacon.\nShe is in the house with the judge.\n\nThe Given Sentence: \nHe is in the museum with the professor."}], "chosen": [{"role": "assistant", "content": "Y"}], "rejected": [{"role": "assistant", "content": "Y"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHAT] Who is the first person to go to the moon?"}], "chosen": [{"role": "assistant", "content": "`WHAT`: Who is the first person to go to the moon?"}], "rejected": [{"role": "assistant", "content": "Is it a noun?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[EM|CONT] The all possible word categories are either \"religious leader\" or \"male pronoun\".\nThe following two examples share a specific word category. You need to first infer the specific word category from the examples.\nPlease output \"X\" if the given sentence mentions the specific word category. Please output \"Y\" if the given sentence does not mention the word category.\n\nExamples: \nShe is in the film studio with the sheriff.\nHe is in the theatre with the imam.\n\nThe Given Sentence: \nHe is in the laboratory with the professor."}], "chosen": [{"role": "assistant", "content": "Y"}], "rejected": [{"role": "assistant", "content": "Y"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[EM|UNF] At what age does Pteropus polioampyrus usually open its eyes?"}], "chosen": [{"role": "assistant", "content": "WHAT: Please specify the species that you are referring to."}], "rejected": [{"role": "assistant", "content": "WHAT is a Pteropus polioampustus?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[LA|LEX] What are the grounds for your belief?"}], "chosen": [{"role": "assistant", "content": "PLEASE: WHO?"}], "rejected": [{"role": "assistant", "content": "option : 0@"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[EM|CONT] The all possible word categories are either \"does not contain a negation\" or \"proper noun\".\nThe following two examples share a specific word category. You need to first infer the specific word category from the examples.\nPlease output \"X\" if the given sentence mentions the specific word category. Please output \"Y\" if the given sentence does not mention the word category.\n\nExamples: \nThe critic may not be in the house.\nLebron James is in the museum.\n\nThe Given Sentence: \nNoam Chomsky has not been in the apartment building."}], "chosen": [{"role": "assistant", "content": "X"}], "rejected": [{"role": "assistant", "content": "WHON is the specific word category mentioned in the given sentence."}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHERE] When does better call saul come out on netflix?"}], "chosen": [{"role": "assistant", "content": "WHAT WHEN DOES SAUL COME OUT ON NELATIMES?"}], "rejected": [{"role": "assistant", "content": "WHAT IS AVAILABLE ONLINE?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHERE] Where was the second session of ipl played?"}], "chosen": [{"role": "assistant", "content": "WHAT IS THE CITY AND THE DATE OF THE SECOND SESSION OF ipl?"}], "rejected": [{"role": "assistant", "content": "Claram: Is \"ipl\" an unfamiliar entity, or is it mentioned in the context without explanation?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[EM|UNF] What's the latitude range where Rita goita is found?"}], "chosen": [{"role": "assistant", "content": "DOCTYPE |## - 3 HINT: is any subject mentioned? WHAM: Who, or any surname? - WHOM: 's"}], "rejected": [{"role": "assistant", "content": "PROBLEM: No additional context or information provided. The user's query contains unfamiliar entities, either unfamiliar names or facts not stated outside the input."}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHAT] In the united states the most common form of child mistreatment involves?"}], "chosen": [{"role": "assistant", "content": "Which type of child mistreatment are they referring to?"}], "rejected": [{"role": "assistant", "content": "What country is that referring to?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[LA|SEM] Matthew left a voicemail for Joshua because he is traveling abroad tomorrow.\nWho is traveling abroad tomorrow?"}], "chosen": [{"role": "assistant", "content": "WHOM: Are you asking which gender? Are you asking which person?"}], "rejected": [{"role": "assistant", "content": "()"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[EM|CONT] The all possible word categories are either \"indoor location\" or \"human\".\nThe following two examples share a specific word category. You need to first infer the specific word category from the examples.\nPlease output \"X\" if the given sentence mentions the specific word category. Please output \"Y\" if the given sentence does not mention the word category.\n\nExamples: \nThe researcher is in the house.\nThe hound is in the lagoon.\n\nThe Given Sentence: \nThe fugitive is in the jungle."}], "chosen": [{"role": "assistant", "content": "Y"}], "rejected": [{"role": "assistant", "content": "Y"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHEN] When does season 3 star vs the forces of evil come out?"}], "chosen": [{"role": "assistant", "content": "WHAT is the date of the release of the season 3 'star vs the forces of evil?"}], "rejected": [{"role": "assistant", "content": "WHAT SEAT OF THE TV HAS A TV?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHERE] Where did the traditional heart shape come from?"}], "chosen": [{"role": "assistant", "content": "WHAT IS THE THE BEST SOURCES FOR UNDERSTANDING THE EMOTIONS OF A SICKNESS?"}], "rejected": [{"role": "assistant", "content": "WHAT IS THE STAGE OF DRAMA AND FILM?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[EM|UNF] Is the trophic guild of Baccharis grandififolia a photoautotroph?"}], "chosen": [{"role": "assistant", "content": "在你下一个回复中，再仔细查看和解析相关的上下文 What's the diet of Baccharis grandifolia? Are you referring to plant A, plant B, or another type of flora? What specific species list should the assistant consider for this search? Which species group does the query refer to?"}], "rejected": [{"role": "assistant", "content": "STOP"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[LA|SEM] The sister-in-law told Amanda that the client detested her.\nWho did the client detest?"}], "chosen": [{"role": "assistant", "content": "Thus, the clarifying question should be: Does \"her\" refer to the client or the sister-in-law/Amanda?"}], "rejected": [{"role": "assistant", "content": "Which aunt insulted the client?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHEN] When did the carolina panthers become a franchise?"}], "chosen": [{"role": "assistant", "content": "The correct output would be either asking \"Which league did they join when they became a franchise?\" or \"Did you mean when did they join"}], "rejected": [{"role": "assistant", "content": "WHAT OR WHEN?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHERE] When did the first hobbit movie come out?"}], "chosen": [{"role": "assistant", "content": "WHAT IS AND WHEN THE FIRST HOBBIT?"}], "rejected": [{"role": "assistant", "content": "WHAT = WHERE WHO?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[LA|LEX] Who is Alanis?"}], "chosen": [{"role": "assistant", "content": "If this doesn't resolve the ambiguity, I should ask whether the subject in question is a real or fictional person from which fictional work or event does the subject belong to?"}], "rejected": [{"role": "assistant", "content": "Which is the first clarifying question from the UNF (UNFAMILIAR) categories?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[EM|CONT] The all possible word categories are either \"female pronoun\" or \"secular leader\".\nThe following two examples share a specific word category. You need to first infer the specific word category from the examples.\nPlease output \"X\" if the given sentence mentions the specific word category. Please output \"Y\" if the given sentence does not mention the word category.\n\nExamples: \nShe is in the museum with the principal.\nHe is in the laboratory with the pastor.\n\nThe Given Sentence: \nHe is in the theatre with the principal."}], "chosen": [{"role": "assistant", "content": "X"}], "rejected": [{"role": "assistant", "content": "When the given sentence mentions the specific word category of the two examples."}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHEN] Who won the ramon magsaysay award this year from india?"}], "chosen": [{"role": "assistant", "content": "WHAT=[WHEN] Who won the ramon magsaysay award this year from ind?"}], "rejected": [{"role": "assistant", "content": "WHO SHOULD YOU ASK?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHERE] How many platform in hazrat nizamuddin railway station?"}], "chosen": [{"role": "assistant", "content": "What type of platform does it include?"}], "rejected": [{"role": "assistant", "content": "['LEX|WHER]^ Who has nizamuddin?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[EM|CONT] The all possible word categories are either \"proper noun\" or \"does not contain a negation\".\nThe following two examples share a specific word category. You need to first infer the specific word category from the examples.\nPlease output \"X\" if the given sentence mentions the specific word category. Please output \"Y\" if the given sentence does not mention the word category.\n\nExamples: \nHermione Granger is in the museum.\nThe reporter could not be in the laboratory.\n\nThe Given Sentence: \nAlexandria Ocasio-Cortez has not been in the grocery store."}], "chosen": [{"role": "assistant", "content": "X WHOM"}], "rejected": [{"role": "assistant", "content": "X"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[AO|WHEN] Classify the below companies based on their market capitalization.\nReliance, Adani Enterprise, Tanla, Globus Spirits, Apollo Hospitals, NELCO, Zee Entertainment Enterprises Ltd"}], "chosen": [{"role": "assistant", "content": "WHAT company is referred to as \"Tanla\"?"}], "rejected": [{"role": "assistant", "content": "WHO ARE THEM?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[EM|CONT] The all possible word categories are either \"male pronoun\" or \"religious leader\".\nThe following two examples share a specific word category. You need to first infer the specific word category from the examples.\nPlease output \"X\" if the given sentence mentions the specific word category. Please output \"Y\" if the given sentence does not mention the word category.\n\nExamples: \nShe is in the film studio with the principal.\nHe is in the house with the bishop.\n\nThe Given Sentence: \nShe is in the theatre with the rabbi."}], "chosen": [{"role": "assistant", "content": "Y"}], "rejected": [{"role": "assistant", "content": "Y"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[EM|UNF] Is Cloniaussis a aggregative multicellular organism in terms of cellularity?"}], "chosen": [{"role": "assistant", "content": "NONE"}], "rejected": [{"role": "assistant", "content": "WHAT EXHIBITS THE SMALLEST UNIVERSTAL UNIFORM CELL WITH PROTOPLASM COMPLETELY OMINOUS?"}]}
{"prompt": [{"role": "system", "content": "You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n\nTask:\nGenerate exactly one clarifying question based on the ambiguity type.\n\nOutput format: One clarifying question\n\nCategories:\n- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n\nSubclasses:\nFor EM:\n- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n- CONT (CONTRADICTION): Query contains self-contradictions\n\nFor LA:\n- LEX (LEXICAL): Query contains terms with multiple meanings\n- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n\nFor AO:\n- WHOM: Query output contains confusion due to missing personal elements\n- WHEN: Query output contains confusion due to missing temporal elements\n- WHERE: Query output contains confusion due to missing spatial elements\n- WHAT: Query output contains confusion due to missing task-specific elements"}, {"role": "user", "content": "[EM|CONT] The all possible word categories are either \"outdoor location\" or \"animal\".\nThe following two examples share a specific word category. You need to first infer the specific word category from the examples.\nPlease output \"X\" if the given sentence mentions the specific word category. Please output \"Y\" if the given sentence does not mention the word category.\n\nExamples: \nThe student is in the grocery store.\nThe snake is in the marsh.\n\nThe Given Sentence: \nThe fugitive is in the cave."}], "chosen": [{"role": "assistant", "content": "Y"}], "rejected": [{"role": "assistant", "content": "X"}]}
